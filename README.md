# Table of Contents
1. [Large Language Models Papers](#large-language-models-papers)
2. [Other Research Topics](#other-research-topics)
3. [Large Language Models Papers with Code](#large-language-models-papers-with-code)
4. [Data Sources](#data-sources)
5. [Contributing](#contributing)
6. [Support](#support)

## Large Language Models Papers
This GitHub repository contains an updated list of Large Language Models papers as of **October 21, 2025**. 

### Overview
- **Total Papers**: Updated regularly with latest publications
- **Coverage**: Papers from 2016 to present
- **Sources**: Collected from arXiv, NeurIPS, ICML, ICLR, ACL, EMNLP, AAAI, IJCAI, KDD, CVPR, ICCV, ECCV, IEEE, ACM, Springer, ScienceDirect, Nature, and other top AI/ML conferences and journals
- **Interactive Search**: For a better reading experience, visit the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/)

### Key Features
- üìä **Comprehensive Coverage**: Papers from major AI/ML venues
- üîç **Advanced Search**: Filter by title, author, venue, year
- üìÖ **Regular Updates**: Automated collection of new papers
- üíª **Code Availability**: Identifies papers with available code
- üìà **Trending Research**: Focus on cutting-edge developments

---

## Other Research Topics
Explore additional research papers on the following topics:

### Machine Learning & AI
- **[Large Language Models](https://github.com/mtuann/llm-updated-papers)** - LLM research and applications
- **[Federated Learning](https://github.com/mtuann/federated-learning-updated-papers)** - Distributed machine learning
- **[Backdoor Learning](https://github.com/mtuann/backdoor-ai-resources)** - Adversarial machine learning
- **[Machine Unlearning](https://github.com/mtuann/machine-unlearning-papers)** - Data removal and privacy

### Computing & Systems
- **[Serverless Computing](https://mtuann.shinyapps.io/research-papers/)** - Cloud computing architectures
- **[Multi-Modal Learning](https://mtuann.shinyapps.io/research-papers/)** - Multi-modal AI systems

### Interactive Platforms
- **[Research Papers App](https://mtuann.shinyapps.io/research-papers/)** - Search and explore all papers
- **[Paper Collections](https://github.com/mtuann/research-papers)** - Main repository with all datasets

---

## Data Sources
The papers are collected from the following sources:

### Academic Databases
- **arXiv** (1991-present) - Preprints and published papers
- **OpenReview** - Conference submissions and peer reviews
- **ACM Digital Library** - Computer science publications
- **Springer** - Academic journals and conferences
- **ScienceDirect** - Elsevier publications
- **Nature** - High-impact research papers
- **DBLP** - Computer science bibliography
- **Google Scholar** - Academic search engine
- **CrossRef** - DOI registration agency
- **OpenAlex** - Open scholarly data

### Major Conferences & Journals
- **Machine Learning**: NeurIPS, ICML, ICLR, JMLR, TMLR
- **Natural Language Processing**: ACL, EMNLP, NAACL, COLING
- **Computer Vision**: CVPR, ICCV, ECCV, PAMI, IJCV
- **Artificial Intelligence**: AAAI, IJCAI, AAMAS
- **Data Mining**: KDD, ICDM, SDM, TKDD
- **Security & Privacy**: CCS, USENIX Security, NDSS
- **And many more...**

---

## Large Language Models Papers with Code
Due to GitHub repository limitations, this section includes only those papers that provide accompanying code, sorted by publication date. For access to the full list of papers, please visit the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/).

<!-- 
### Summary Statistics
- **Total Papers in Dataset**: 33,324
- **Papers with Available Code**: 1,335
- **Code Availability Rate**: 4.0%
- **Last Updated**: October 21, 2025

### Paper Statistics
- **Total Papers**: 33324
- **Papers with Code**: 33324
- **Latest Update**: 33324
- **Coverage Period**: 2016 - Present -->

---

## Contributing
We welcome contributions to improve this paper collection:

### How to Contribute
1. **Add Missing Papers**: Submit papers that should be included
2. **Improve Metadata**: Help enhance paper information
3. **Report Issues**: Identify bugs or missing features
4. **Suggest Improvements**: Propose new features or enhancements

### Contact Information
- **Email**: [tuannm0312@gmail.com](mailto:tuannm0312@gmail.com)
- **GitHub Issues**: [Create an issue](https://github.com/mtuann/research-papers/issues)
- **Discussions**: [Join the discussion](https://github.com/mtuann/research-papers/discussions)

---

## Support
If you find this application helpful and would like to support its development, you can buy me a coffee using one of the following methods:

### Payment Methods
- **Techcombank (Vietnam)**: 5877 5555 55 (Nguyen Thi Lan Phuong)
- **PayPal or Credit/Debit Card**: [https://ko-fi.com/miutheladycat](https://ko-fi.com/miutheladycat)

### Why Support?
Your support helps maintain and improve:
- ü§ñ Automated paper collection pipeline
- üåê Interactive web application
- üìä Regular data updates
- üîß System maintenance and improvements
- üìö New research area coverage

---

**Note**: This repository is regularly updated with new papers. For the most current data, check the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/) or the individual topic repositories linked above.


|No.|Title|Authors|Publish Date|Venue|Code|URL|
|---|---|---|---|---|---|---|
|1|In BLOOM: Creativity and Affinity in Artificial Lyrics and Art|Evan Crothers, Herna L. Viktor, Nathalie Japkowicz||creativeAI|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/in-bloom-creativity-and-affinity-in/code)|https://openreview.net/pdf/3d502829f7e86330802059674fac7b55dfb63091.pdf|
|2|A Simple, Yet Effective Approach to Finding Biases in Code Generation|Spyridon Mouselinos, Mateusz Malinowski, Henryk Michalewski||OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/a-simple-yet-effective-approach-to-finding/code)|https://openreview.net/pdf/dc913e6b5396ddf78d74195871197392db78fa41.pdf|
|3|CIViC MCP: Integrating Large Language Models with the Clinical Interpretations of Variants in Cancer|Lars E Schimmelpfennig, Quentin Cody, Joshua McMichael, Adam Coffman, Jason Saliba, Arpad Danos, Susanna Kiwala, Alex H....|2025-10-16|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/griffithlab/civic-mcp-server|https://doi.org/10.1101/2025.10.13.682185|
|4|Hierarchical Frequency Tagging Probe (HFTP): A Unified Approach to Investigate Syntactic Structure Representations in Large Language Models and the Human Brain|Jingmin An, Y. J. Song, Ruolin Yang, Nai Ding, Lingxi Lu, Yuxuan Wang, Wei Wang, Chu Zhuang, Wang Qian, Fang Fang|2025-10-15|arXiv (Cornell University)|https://github.com/LilTiger/HFTP.|http://arxiv.org/abs/2510.13255|
|5|ICCTax: A Hierarchical Taxonomic Classifier for Metagenomic Sequences on a Large Language Model|Yansheng Gao, Jiaxing Bai, Feng Zhou, Yushuang He, Ying Wang, Xiaobing Huang|2025-10-15|Bioinformatics Advances|https://github.com/Ying-Lab/ICCTax.|https://doi.org/10.1093/bioadv/vbaf257|
|6|Do Large Language Models Respect Contracts? Evaluating and Enforcing Contract-Adherence in Code Generation|Soohan Lim, Joonghyuk Hahn, Hyunwoo Park, Sang‚ÄêKi Ko, Yo-Sub Han|2025-10-14|arXiv (Cornell University)|https://github.com/suhanmen/PACT.|http://arxiv.org/abs/2510.12047|
|7|From Knowledge to Treatment: Large Language Model Assisted Biomedical Concept Representation for Drug Repurposing|Cathie Xiang, Tengfei Ma, Xiangxiang Zeng, Yiping Liu, Bosheng Song, Xiangzheng Fu|2025-10-14|arXiv (Cornell University)|https://github.com/xiaomingaaa/LLaDR.|http://arxiv.org/abs/2510.12181|
|8|Precise Attribute Intensity Control in Large Language Models via Targeted Representation Editing|Rongzhi Zhang, Liqin Ye, Yuzhao Heng, Xiang Guang Chen, Tong Yu, Lingkai Kong, Sudheer Chava, Chao Zhang|2025-10-14|arXiv (Cornell University)|https://github.com/Pre-Control/pre-control|http://arxiv.org/abs/2510.12121|
|9|Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models|Nianyi Lin, Jiajie Zhang, Lei Hou, Juanzi Li|2025-10-13|arXiv (Cornell University)|https://github.com/THU-KEG/BGPO|http://arxiv.org/abs/2510.11683|
|10|FlexAC: Towards Flexible Control of Associative Reasoning in Multimodal Large Language Models|Shengming Yuan, Xinyu Lyu, Shawn Wang, Beitao Chen, Jingkuan Song, Liyan Gao|2025-10-13|arXiv (Cornell University)|https://github.com/ylhz/FlexAC.|http://arxiv.org/abs/2510.11190|
|11|Automating Candidate Gene Prioritization with Large Language Models: From Naive Scoring to Literature-Grounded Validation|Taushif Khan, Mohammed Toufiq, Marina Yurieva, Nitaya Indrawattana, Akanitt Jittmittraphap, Nathamon Kosoltanapiwat, Por...|2025-10-10|Bioinformatics|https://github.com/taushifkhan/llm-geneprioritization-framework|https://doi.org/10.1093/bioinformatics/btaf541|
|12|Pattern Enhanced Multi-Turn Jailbreaking: Exploiting Structural Vulnerabilities in Large Language Models|Ragib Amin Nihal, Rui Wen, Kazuhiro Nakadai, Jun Sakuma|2025-10-09|arXiv (Cornell University)|https://github.com/Ragib-Amin-Nihal/PE-CoA|http://arxiv.org/abs/2510.08859|
|13|When Benchmarks Age: Temporal Misalignment through Large Language Model Factuality Evaluation|Xunyi Jiang, Deng-Lin Chang, Julian McAuley, Xin Xu|2025-10-08|arXiv (Cornell University)|https://github.com/JiangXunyi/BenchAge.|http://arxiv.org/abs/2510.07238|
|14|Aligning Large Language Models via Fully Self-Synthetic Data|Shangjian Yin, Zhepei Wei, Xinyu Zhu, Wei-Lin Chen, Yu Meng|2025-10-08|arXiv (Cornell University)|https://github.com/SJY8460/SAO.|http://arxiv.org/abs/2510.06652|
|15|AWM: Accurate Weight-Matrix Fingerprint for Large Language Models|Boyi Zeng, Lin Chen, Ziwei He, Xinbing Wang, Zhouhan Lin|2025-10-08|arXiv (Cornell University)|https://github.com/LUMIA-Group/AWM.|http://arxiv.org/abs/2510.06738|
|16|Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models|Yuntao Gui, James Cheng|2025-10-08|arXiv (Cornell University)|https://github.com/ytgui/Search-R3|http://arxiv.org/abs/2510.07048|
|17|Exploring Brazil's LLM Fauna: Investigating the Generative Performance of Large Language Models in Portuguese|Gabriel Assis, Cl√°udia Freitas, Aline Paes|2025-10-08|Journal of the Brazilian Computer Society|https://github.com/MeLLL-UFF/brfauna-gen-eval.|https://doi.org/10.5753/jbcs.2025.5814|
|18|GOFlowLLM - Curating miRNA literature with Large Language Models and flowcharts|Andrew Green, Nancy Ontiveros‚ÄêPalacios, Isaac Jandalala, Simona Panni, Valerie Wood, Giulia Antonazzo, Helen Attrill, Al...|2025-10-08|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/RNAcentral/GO_Flow_LLM.|https://doi.org/10.1101/2025.10.07.680945|
|19|Pok√©LLMon: A Grounding and Reasoning Benchmark for Large Language Models in Pok√©mon Battles|Sihao Hu, Tiansheng Huang, Guishan Liu, Ramana Rao Kompella, Ling Liu|2025-10-07|ACM Transactions on Internet Technology|https://github.com/git-disl/PokeLLMon.|https://doi.org/10.1145/3771095|
|20|HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection|Junwen Chen, Peilin Xiong, ‚Ä™Keiji Yanai‚Ä¨|2025-10-07|arXiv (Cornell University)|https://github.com/cjw2021/HOI-R1.|http://arxiv.org/abs/2510.05609|
|21|Reproducibility Study of "XRec: Large Language Models for Explainable Recommendation"|Rasendu Mishra, Julian I. Bibo, Quinten van Engelen, Henk Schaapman|2025-10-06|arXiv (Cornell University)|https://github.com/julianbibo/xrec-reproducibility.|http://arxiv.org/abs/2510.06275|
|22|Imperceptible Jailbreaking against Large Language Models|Kuofeng Gao, Yiming Li, Chao‚ÄêHai Du, Xin Wang, Xingjun Ma, Shu‚ÄêTao Xia, Tianyu Pang|2025-10-06|arXiv (Cornell University)|https://github.com/sail-sg/imperceptible-jailbreaks.|http://arxiv.org/abs/2510.05025|
|23|Microscaling Floating Point Formats for Large Language Models|Marco Cococcioni, Dario Pagani, Federico Rossi|2025-10-02|arXiv (Cornell University)|https://github.com/unipi-dii-compressedarith/llm.c-sve|http://arxiv.org/abs/2510.01863|
|24|Guiding Multimodal Large Language Models with Blind and Low Vision People Visual Questions for Proactive Visual Interpretations|Ricardo E. Gonzalez Penuela, Felipe Arias-Russi, Victor Capriles|2025-10-02|arXiv (Cornell University)|https://github.com/rgonzalezp/guiding-multimodal-large-language-models-with-blind-and-low-vision-people-visual-questions|http://arxiv.org/abs/2510.01576|
|25|Copy-Paste to Mitigate Large Language Model Hallucinations|Yao Long, Xianrui Wu, Yingying Zhang, Xianbin Wen, Yuxi Zhou, Shenda Hong|2025-10-01|arXiv (Cornell University)|https://github.com/longyongchao/CopyPasteLLM|http://arxiv.org/abs/2510.00508|
|26|DeepJSONEval: Benchmarking Complex Nested JSON Data Mining for Large Language Models|Zhicheng Zhou, Liqiang Jing, Shudi Qiu, Junjie Huang, Lin Qiu, Zhijie Sun|2025-09-30|arXiv (Cornell University)|https://github.com/GTS-AI-Infra-Lab-SotaS/DeepJSONEval|http://arxiv.org/abs/2509.25922|
|27|Multimodal Large Language Models Meet Multimodal Emotion Recognition and Reasoning: A Survey|Yuntao Shou, Tao Meng, Wei Ai, Keqin Li|2025-09-29|arXiv (Cornell University)|https://github.com/yuntaoshou/Awesome-Emotion-Reasoning|http://arxiv.org/abs/2509.24322|
|28|Sanitize Your Responses: Mitigating Privacy Leakage in Large Language Models|Wenjie Fu, Huandong Wang, Junyao Gao, Guoan Wan, Tao Jiang|2025-09-29|arXiv (Cornell University)|https://github.com/wjfu99/LLM_Self_Sanitize|http://arxiv.org/abs/2509.24488|
|29|Tequila: Trapping-free Ternary Quantization for Large Language Models|Hong Huang, Decheng Wu, Rui Cen, Guopan Yu, Zonghang Li, Kai Liu, Jianchen Zhu, Peng Chen, Ke Liu, Dapeng Wu|2025-09-28|arXiv (Cornell University)|https://github.com/Tencent/AngelSlim.|http://arxiv.org/abs/2509.23809|
|30|How to Make Large Language Models Generate 100% Valid Molecules?|Tao Wen, Jing Tang, Alvin Chan, Bryan Hooi, Baolong Bi, Nanyun Peng, Yuansheng Liu, Yiwei Wang|2025-09-27|arXiv (Cornell University)|https://github.com/wentao228/SmiSelf.|http://arxiv.org/abs/2509.23099|
|31|PT$^2$-LLM: Post-Training Ternarization for Large Language Models|Xianglong Yan, C. L. Bao, Zhiteng Li, Tianao Zhang, Kaicheng Yang, Haotong Qin, Ruobing Xie, Xian‚ÄêHe Sun, Yulun Zhang|2025-09-27|arXiv (Cornell University)|https://github.com/XIANGLONGYAN/PT2-LLM.|http://arxiv.org/abs/2510.03267|
|32|Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models|Xin Zhang, Zhiteng Li, Xianglong Yan, Haotong Qin, Yong‚ÄêXin Guo, Yulun Zhang|2025-09-27|arXiv (Cornell University)|https://github.com/ZTA2785/Quant-dLLM.|http://arxiv.org/abs/2510.03274|
|33|StyleBench: Evaluating thinking styles in Large Language Models|Junyi Guo, Shangding Gu, Ming Jin, Costas J. Spanos, Javad Lavaei|2025-09-25|arXiv|https://github.com/JamesJunyuGuo/Style_Bench.|https://doi.org/10.48550/arXiv.2509.20868|
|34|Embedding Domain Knowledge for Large Language Models via Reinforcement Learning from Augmented Generation|Chaojun Nie, Jun Zhou, Guanxiang Wang, Shisong Wu, Zichen Wang|2025-09-24|arXiv|https://github.com/ChaojunNie/RLAG.|https://doi.org/10.48550/arXiv.2509.20162|
|35|Automated Knowledge Graph Construction using Large Language Models and Sentence Complexity Modelling|Sydney Anuyah, Mehedi Mahmud Kaushik, Sri Rama Krishna Reddy Dwarampudi, Rakesh Shiradkar, Arjan Durresi, Sunandan Chakr...|2025-09-22|arXiv|https://github.com/KaushikMahmud/CoDe-KG_EMNLP_2025|https://doi.org/10.48550/arXiv.2509.17289|
|36|CogAtom: From Cognitive Atoms to Olympiad-level Mathematical Reasoning in Large Language Models|Zhuofan Chen, Jiyuan He, Yichi Zhang, Xing Hu, Haoxing Wen, Jun Bai, Wenge Rong|2025-09-22|arXiv|https://github.com/Icarus-1111/CogAtom.|https://doi.org/10.48550/arXiv.2509.17318|
|37|EngiBench: A Benchmark for Evaluating Large Language Models on Engineering Problem Solving|Xiyuan Zhou, Xinlei Wang, Yaoyao He, Yang Wu, Rui Zou, Yuheng Cheng, Yiteng Xie, Wenxuan Liu, Huan Zhao, Yan Xu, Jinjin ...|2025-09-22|arXiv|https://github.com/EngiBench/EngiBench.|https://doi.org/10.48550/arXiv.2509.17677|
|38|QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models|Hyesung Jeon, Seojune Lee, Beomseok Kang, Yulhwa Kim, Jae-Joon Kim|2025-09-22|arXiv|https://github.com/vantaa89/qwha.|https://doi.org/10.48550/arXiv.2509.17428|
|39|A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness|Fali Wang, Zhiwei Zhang, Xianren Zhang, Zongyu Wu, Tzuhao Mo, Qiuhao Lu, W.K. Wang, Rui Li, Junjie Xu, Xianfeng Tang, Qi...|2025-09-18|ACM Transactions on Intelligent Systems and Technology|https://github.com/FairyFali/SLMs-Survey|https://doi.org/10.48550/arXiv.2411.03350|
|40|TurnBack: A Geospatial Route Cognition Benchmark for Large Language Models through Reverse Route|Hongyi Luo, Qing Chen, Dihogo Gama de Matos, Hari Krishna Gadi, Yanfeng Zhang, Li Liu, Yongliang Wang, Niclas Zeller, Da...|2025-09-17|arXiv|https://github.com/bghjmn32/EMNLP2025_Turnback|https://doi.org/10.48550/arXiv.2509.18173|
|41|Enhancing Base Large Language Models Using Knowledge Graphs for Genomic Annotation|Pranav N. Desai, S. Padhi, Kavya Panicker, Kallakunta Ravi Kumar, Divyaprabha KN|2025-09-16|Advances in transdisciplinary engineering|https://github.com/cubed-guy/capstone-kg-llm.|https://doi.org/10.3233/atde250737|
|42|AMQ: Enabling AutoML for Mixed-precision Weight-Only Quantization of Large Language Models|Sangjun Lee, Seung-taek Woo, Jungyu Jin, Changhun Lee, Eunhyeok Park|2025-09-15|arXiv|https://github.com/dlwns147/amq.|https://doi.org/10.48550/arXiv.2509.12019|
|43|Phi: Preference Hijacking in Multi-modal Large Language Models at Inference Time|Yifan Lan, Yuanpu Cao, Weitong Zhang, Lu Lin, Jinghui Chen|2025-09-15|arXiv|https://github.com/Yifan-Lan/Phi.|https://doi.org/10.48550/arXiv.2509.12521|
|44|PLiCat: Decoding protein-lipid interactions by large language model|Feitong Dong, Jingrou Wu|2025-09-14|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/Noora68/PLiCat.|https://doi.org/10.1101/2025.09.09.675043|
|45|EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language Models|Mohammad Reza Mirbagheri, Mohammad Mahdi Mirkamali, Zahra Motoshaker Arani, Ali Javeri, Amir Mahdi Sadeghzadeh, Rasool J...|2025-09-08|arXiv|https://github.com/Rezamirbagheri110/EPT-Benchmark.|https://doi.org/10.48550/arXiv.2509.06838|
|46|Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models|Yinjie Wang, Ling Yang, Bowen Li, Ye Tian, Ke Shen, Mengdi Wang|2025-09-08|arXiv|https://github.com/Gen-Verse/dLLM-RL|https://doi.org/10.48550/arXiv.2509.06949|
|47|CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor|Zhenhua Xu, Xixiang Zhao, Xubin Yue, Shengwei Tian, Changting Lin, Meng Han|2025-09-05|arXiv|https://github.com/Xuzhenhua55/CTCC|https://doi.org/10.48550/arXiv.2509.09703|
|48|Behavioral Fingerprinting of Large Language Models|Zehua Pei, Hui-Ling Zhen, Yingchun Zhang, Zhiyuan Yang, Xing Li, Xianzhi Yu, Mingxuan Yuan, Bei Yu|2025-09-02|arXiv|https://github.com/JarvisPei/Behavioral-Fingerprinting|https://doi.org/10.48550/arXiv.2509.04504|
|49|Good Advisor for Source Localization: Using Large Language Model to Guide the Source Inference Process|Dongpeng Hou, Weifeng Wei, Chao Gao, Xianghua Li, Zhen Wang|2025-09-01|OpenAlex|https://github.com/cgao-comp/CRSLL.|https://doi.org/10.24963/ijcai.2025/326|
|50|Token-Level Accept or Reject: A Micro Alignment Approach for Large Language Models|Yang Zhang, Yu Yu, Bo Tang, Limin Zhu, Chuxiong Sun, Wenqiang Wei, Jie Hu, Zheng Xie, Zhiyu Li, Feiyu Xiong, Edward Chun...|2025-09-01|OpenAlex|https://github.com/IAAR-Shanghai/MARA|https://doi.org/10.48550/arXiv.2505.19743|
|51|Exploring homology detection via k-means clustering of proteins embedded with a large language model|Thomas Minotto, Antoine Claessens, Thomas D. Otto|2025-08-26|Bioinformatics|https://github.com/ThomasGTHB/OrthoLM|https://doi.org/10.1093/bioinformatics/btaf472|
|52|LLM4DSR: Leveraing Large Language Model for Denoising Sequential   Recommendation|Bohao Wang, Feng Liu, Changwang Zhang, Jiawei Chen, Yudi Wu, Sheng Zhou, Xingyu Lou, Jun Wang, Yan Feng, Chun Chen, Can ...|2025-08-25|ACM transactions on office information systems|https://github.com/WANGBohaO-jpg/LLM4DSR|https://doi.org/10.1145/3762182|
|53|E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model|Ronghao Lin, Shali Shen, Weipeng Hu, Qiaolin He, Aolin Xiong, Li Huang, Huosheng Hu, Yap‚ÄêPeng Tan|2025-08-18|arXiv|https://github.com/RH-Lin/E3RG.|https://doi.org/10.48550/arXiv.2508.12854|
|54|Mitigating Hallucinations in Large Language Models via Causal Reasoning|Yuangang Li, Yiqing Shen, Yi Nian, Jiechao Gao, Ziyi Wang, Chenxiao Yu, Shawn Li, Jie Wang, Xiyang Hu, Yue Zhao|2025-08-17|arXiv|https://github.com/MrLYG/CDCR-SFT.|https://doi.org/10.48550/arXiv.2508.12495|
|55|GS-DTI: A Graph-Structure-Aware Framework Leveraging Large Language Models for Drug‚ÄìTarget Interaction Prediction|Qinze Yu, Chang Zhou, Jiyue Jiang, Xiangyu Shi, Yu Li|2025-08-09|Bioinformatics|https://github.com/purvavideha/GSDTI.|https://doi.org/10.1093/bioinformatics/btaf445|
|56|Enhancing Interpretability of Ocular Disease Diagnosis: A Zero-Shot Study of Multimodal Large Language Models|Yating Pan, Janna Hastings|2025-08-07|Studies in health technology and informatics|https://github.com/YatingPan/ocular-llm-explainability.|https://doi.org/10.3233/shti250910|
|57|CityGPT: Empowering Urban Spatial Cognition of Large Language Models|Jie Feng, Yuwei Du, Tianhui Liu, Siqi Guo, Yuming Lin, Li Yong|2025-08-01|OpenAlex|https://github.com/tsinghua-fib-lab/CityGPT.|https://doi.org/10.48550/arXiv.2406.13948|
|58|A large language model for predicting neurotoxic peptides and neurotoxins|Anand Singh Rathore, Saloni Jain, Shubham Choudhury, Gajendra P. S. Raghava|2025-08-01|PubMed|https://github.com/raghavagps/ntxpred2|https://pubmed.ncbi.nlm.nih.gov/40671295|
|59|SKiM-GPT: Combining Biomedical Literature-Based Discovery with Large Language Model Hypothesis Evaluation|Jack Freeman, Robert J. Millikin, Liang Xu, Indu Sharma, Bethany M. Moore, Cannon Lock, Kevin W. George, Antonin Bal, Ro...|2025-07-31|OpenAlex|https://github.com/stewart-lab/skimgpt|https://doi.org/10.1101/2025.07.28.664797|
|60|BRAVE: a highly accurate method for predicting HIV-1 antibody resistance using large language models for proteins|Mohammed El Anbari, Tatsiana Bylund, Sijy O‚ÄôDell, Emily Tourtellott, Krisha McKee, Stephen D. Schmidt, Nonhlanhla N. Mkh...|2025-07-31|OpenAlex|https://github.com/kiryst/BRAVE|https://doi.org/10.1101/2025.07.28.667234|
|61|Reading papers: Extraction of molecular interaction networks with large language models|Enio Gjerga, Philipp Wiesenbach, Christoph Dieterich|2025-07-25|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/dieterich-lab/LLM_Relations.|https://doi.org/10.1101/2025.07.21.665999|
|62|A Survey on AI Search with Large Language Models|Jian Li, Xiaoxi Li, Yan Zheng, Yizhang Jin, Shuo Wang, Jian Wu, Yabiao Wang, Chengjie Wang, X. Q. Yuan|2025-07-24|OpenAlex|https://github.com/swordlidev/Awesome-AI-Search.|https://doi.org/10.20944/preprints202507.2024.v1|
|63|BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining|Baqer M. Merzah, Tania Taami, Salman Asoudeh, Amir reza Hossein pour, Saeed Mirzaee, Amir Ali Bengari|2025-07-21|OpenAlex|https://github.com/amirap80/BioPars|https://doi.org/10.21203/rs.3.rs-6823379/v1|
|64|textToKnowledgeGraph: Generation of Molecular Interaction Knowledge Graphs Using Large Language Models for Exploration in Cytoscape|Favour James, Christopher Churas, Dexter Pratt, Augustin Luna|2025-07-21|OpenAlex|https://github.com/ndexbio/llm-text-to-knowledge-graph|https://doi.org/10.1101/2025.07.17.664328|
|65|Empowering Universal Robot Programming with Fine-Tuned Large Language Models|Tien Dat Le, Minhhuy Le|2025-07-15|EAI Endorsed Transactions on AI and Robotics|https://github.com/t1end4t/llm-robotics|https://doi.org/10.4108/airo.8983|
|66|A Survey on the Memory Mechanism of Large Language Model based Agents|Zeyu Zhang, Quanyu Dai, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Jieming Zhu, Zhenhua Dong, Ji-Rong Wen|2025-07-11|ACM transactions on office information systems|https://github.com/nuster1128/LLM_Agent_Memory_Survey|https://doi.org/10.48550/arXiv.2404.13501|
|67|Conversational health agents: a personalized large language model-powered agent framework|Mahyar Abbasian, Iman Azimi, Amir M. Rahmani, Ramesh Jain|2025-07-03|JAMIA Open|https://github.com/Institute4FutureHealth/CHA|https://doi.org/10.1093/jamiaopen/ooaf067|
|68|Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal   Large Language Models|Gen Luo, Wenhan Dou, Wenhao Li, Zhaokai Wang, Xue Yang, Changyao Tian, Hao Li, Weiyun Wang, Wenhai Wang, Xizhou Zhu, Yu ...|2025-07-01|arXiv|https://github.com/OpenGVLab/Mono-InternVL.|https://doi.org/10.48550/arXiv.2507.12566|
|69|spaLLM: enhancing spatial domain analysis in multi-omics data through large language model integration|Longyi Li, Liyan Dong, Hao Zhang, Dong Xu, Yongli Li|2025-07-01|Briefings in Bioinformatics|https://github.com/liiilongyi/spaLLM.|https://doi.org/10.1093/bib/bbaf304|
|70|Warehouse Spatial Question Answering with LLM Agent|Hsiang-Wei Huang, Jen-Hao Cheng, Kuang-Ming Chen, Cheng-Yen Yang, Bahaa Alattar, Yi-Ru Lin, Pyongkun Kim, Sangwon Kim, K...|2025-07-01|arXiv|https://github.com/hsiangwei0903/SpatialAgent|http://arxiv.org/abs/2507.10778v1|
|71|The benefits of query-based KGQA systems for complex and temporal   questions in LLM era|Artem Alekseev, Mikhail Chaichuk, Miron Butko, Alexander Panchenko, Elena Tutubalina, Oleg Somov|2025-07-01||https://github.com/ar2max/NLDB-KGQA-System|http://arxiv.org/abs/2507.11954v1|
|72|The Evolving Role of Large Language Models in Scientific Innovation:   Evaluator, Collaborator, and Scientist|Haoxuan Zhang, Ruochi Li, Yang Zhang, Ting Xiao, Jiangping Chen, Junhua Ding, Haihua Chen|2025-07-01|arXiv|https://github.com/haoxuan-unt2024/llm4innovation.|https://doi.org/10.48550/arXiv.2507.11810|
|73|Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding|Feng Xiao, Jicong Fan|2025-07-01|arXiv|https://github.com/jicongfan/Text-Anomaly-Detection-Benchmark|http://arxiv.org/abs/2507.12295v1|
|74|The Devil behind the mask: An emergent safety vulnerability of Diffusion   LLMs|Zichen Wen, Jiashu Qu, Dongrui Liu, Zhiyuan Liu, Ruixi Wu, Yicun Yang, Xiangqi Jin, Haoyun Xu, Xuyang Liu, Weijia Li, Ch...|2025-07-01|arXiv|https://github.com/ZichenWen1/DIJA.|http://arxiv.org/abs/2507.11097v1|
|75|Marco-Bench-MIF: On Multilingual Instruction-Following Capability of   Large Language Models|Bo Zeng, Chenyang Lyu, Sinuo Liu, Mingyan Zeng, Minghao Wu, Xuanfan Ni, Tianqi Shi, Yu Zhao, Yefeng Liu, Chenyu Zhu, Rui...|2025-07-01|arXiv|https://github.com/AIDC-AI/Marco-Bench-MIF.|https://doi.org/10.48550/arXiv.2507.11882|
|76|DrafterBench: Benchmarking Large Language Models for Tasks Automation in   Civil Engineering|Yinsheng Li, Zhen Dong, Yi Shao|2025-07-01|arXiv|https://github.com/Eason-Li-AIS/DrafterBench|https://doi.org/10.48550/arXiv.2507.11527|
|77|Analysis of Image-and-Text Uncertainty Propagation in Multimodal Large   Language Models with Cardiac MR-Based Applications|Yucheng Tang, Yunguan Fu, Weixi Yi, Yipei Wang, Daniel C. Alexander, Rhodri H. Davies, Yipeng Hu|2025-07-01|Lecture notes in computer science|https://github.com/yucheng722/MUPM.|https://doi.org/10.1007/978-3-032-04965-0_4|
|78|Leveraging large language models to predict antibiotic resistance in <i>Mycobacterium tuberculosis</i>|Conrad Testagrose, Sakshi Pandey, Mohammadali Serajian, Simone Marini, Mattia Prosperi, Christina Boucher|2025-07-01|Bioinformatics|https://github.com/ctestagrose/LLMTB.|https://doi.org/10.1093/bioinformatics/btaf232|
|79|DSSD: Efficient Edge-Device LLM Deployment and Collaborative Inference   via Distributed Split Speculative Decoding|Jiahong Ning, Ce Zheng, Tingting Yang|2025-07-01|arXiv|https://github.com/JasonNing96/DSSD-Efficient-Edge-Computing|http://arxiv.org/abs/2507.12000v2|
|80|ParaStudent: Generating and Evaluating Realistic Student Code by   Teaching LLMs to Struggle|Mihran Miroyan, Rose Niousha, Joseph E. Gonzalez, Gireeja Ranade, Narges Norouzi|2025-07-01|arXiv|https://github.com/mmiroyan/ParaStudent|http://arxiv.org/abs/2507.12674v1|
|81|Exploring the potential of lightweight large language models for AI-based mental health counselling task: a novel comparative study|Ritesh Maurya, Nikhil Kumar Rajput, M G Diviit, Satyajit Mahapatra, Manish Kumar Ojha|2025-07-01|Scientific Reports|https://github.com/diviitmg03/Comparative-analysis-of-LLMs-.git|https://doi.org/10.1038/s41598-025-05012-1|
|82|First-Order Error Matters: Accurate Compensation for Quantized Large   Language Models|Xingyu Zheng, Haotong Qin, Yuye Li, Jiakai Wang, Jinyang Guo, Michele Magno, Xianglong Liu|2025-07-01|arXiv|https://github.com/Xingyu-Zheng/FOEM.|https://doi.org/10.48550/arXiv.2507.11017|
|83|Internal Value Alignment in Large Language Models through Controlled   Value Vector Activation|Haoran Jin, Meng Li, Xiting Wang, Zhihao Xu, Minlie Huang, Yantao Jia, Defu Lian|2025-07-01|OpenAlex|https://github.com/hr-jin/ConVA.|https://doi.org/10.18653/v1/2025.acl-long.1326|
|84|DrugTar Improves Druggability Prediction by Integrating Large Language Models and Gene Ontologies|Niloofar Borhani, Iman Izadi, Ali Motahharynia, Mahsa Sheikholeslami, Yousof Gheisari|2025-06-24|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/NBorhani/DrugTar.|https://doi.org/10.1093/bioinformatics/btaf360|
|85|Finding the Dark Matter: Large Language Model-based Enzyme Kinetic Data Extractor and Its Validation|G. Wei, Xinchun Ran, Runeem Al-Abssi, Zhongyue Yang|2025-06-20|OpenAlex|https://github.com/ChemBioHTP/EnzyExtract|https://doi.org/10.26434/chemrxiv-2025-pb73x-v2|
|86|LANG: A Lesson Plan Generation Framework via Multi-Form Interaction with Large Language Models|Yong Ouyang, Jinhao Quan, Huan-Wen Wang, Yawen Zeng, Lingyu Chen|2025-06-17|Research Square (Research Square)|https://github.com/ssakana/LANG.|https://doi.org/10.21203/rs.3.rs-6808103/v1|
|87|Prime the search: Using large language models for guiding geometric task and motion planning by warm-starting tree search|Dongryung Lee, Se June Joo, Kimin Lee, Beomjoon Kim|2025-06-06|The International Journal of Robotics Research|https://github.com/iMSquared/prime-the-search|https://doi.org/10.1177/02783649251347307|
|88|Improving drug-drug interaction prediction via in-context learning and judging with large language models|He Qi, Xiaoqiang Li, Chengcheng Zhang, Tianyi Zhao|2025-06-02|Frontiers in Pharmacology|https://github.com/zcc1203/ddi-judge.|https://doi.org/10.3389/fphar.2025.1589788|
|89|Survey on Factuality in Large Language Models|Cunxiang Wang, Xiaoze Liu, Yuanhao Yue, Qipeng Guo, Xiangkun Hu, Xiangru Tang, Tianhang Zhang, Cheng Jiayang, Yunzhi Yao...|2025-06-02|ACM Computing Surveys|https://github.com/wangcunxiang/LLM-Factuality-Survey.|https://doi.org/10.1145/3742420|
|90|SummArIzeR: Simplifying cross-database enrichment result clustering and annotation via large language models|Marie Brinkmann, Michael Bonelli, Anela Tosevska|2025-06-01|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/bonellilab/SummArIzeR.|https://doi.org/10.1101/2025.05.28.656331|
|91|The accuracy and efficiency of large language models for chart review in cancer genetics|James Dickerson, Margaret Shaw, Mina Satoyoshi, Sonia Rios‚ÄêVentura, Kerry Kingham, Allison W. Kurian, Jennifer L. Caswel...|2025-05-28|Journal of Clinical Oncology|https://github.com/MrJimb0/ASCO2025|https://doi.org/10.1200/jco.2025.43.16_suppl.e22603|
|92|Mitigating Age-Related Bias in Large Language Models: Strategies for Responsible Artificial Intelligence Development|Zhuang Liu, S. Qian, Shuirong Cao, Tianyu Shi|2025-05-21|INFORMS journal on computing|https://github.com/INFORMSJoC/2024.0645|https://doi.org/10.1287/ijoc.2024.0645|
|93|Social determinants of health extraction from clinical notes across institutions using large language models|Vipina K. Keloth, Salih Selek, Qingyu Chen, Christopher Gilman, Sunyang Fu, Yifang Dang, Xinghan Chen, Xinyue Hu, Yujia ...|2025-05-17|npj Digital Medicine|https://github.com/BIDS-Xu-Lab/LLMs4SDoH|https://doi.org/10.1038/s41746-025-01645-8|
|94|ProtFun: A Protein Function Prediction Model Using Graph Attention Networks with a Protein Large Language Model|Muhammed Talo, Serdar Bozdag|2025-05-17|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/bozdaglab/ProtFun|https://doi.org/10.1101/2025.05.13.653854|
|95|Leveraging Large Language Models for Literature-Driven Prioritization of Protein Binding Pockets|Roman Stratiichuk, Mykola Melnychenko, Ihor Koleiev, Taras Voitsitskyi, Husak Vladyslav, –ù–∞—Ç–∞–ª—ñ—è –ê–Ω–∞—Ç–æ–ª—ñ—ó–≤–Ω–∞ –®–µ–≤—á—É–∫, Zak...|2025-05-15|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/MelnychenkoM/LLM-benchmark-dataset.|https://doi.org/10.1093/bioinformatics/btaf449|
|96|Exploring Zero-Shot Cross-Lingual Biomedical Concept Normalization via Large Language Models|Hossein Rouhizadeh, Anthony Yazdani, Boya Zhang, Douglas Teodoro|2025-05-15|Studies in health technology and informatics|https://github.com/hrouhizadeh/zsh_cl_bcn.|https://doi.org/10.1101/2025.02.27.25323007|
|97|UrbanPlanBench: A Comprehensive Urban Planning Benchmark for Evaluating Large Language Models|Yu Zheng, Longyi Liu, Yuming Lin, Jie Feng, Guozhen Zhang, Depeng Jin, Yong Li|2025-04-30|Research Square (Research Square)|https://github.com/tsinghua-fib-lab/PlanBench|https://doi.org/10.21203/rs.3.rs-6551071/v1|
|98|Evaluating Personality Traits of Large Language Models Through Scenario-based Interpretive Benchmarking|Alessandro Berti|2025-04-09|OpenAlex|https://github.com/fit-alessandro-berti/llm-dreams-benchmark.|https://doi.org/10.20944/preprints202504.0435.v1|
|99|Improving Text-to-Sql Conversion for Low-Resource Languages Using Large Language Models|Emƒ±r √ñzt√ºrk|2025-03-26|Bitlis Eren √úniversitesi Fen Bilimleri Dergisi|https://github.com/emirozturk/TT2SQL.|https://doi.org/10.17798/bitlisfen.1561298|
|100|Prompting and Fine-Tuning Open-Sourced Large Language Models for Stance Classification|Iain J. Cruickshank, Lynnette Hui Xian Ng|2025-03-25|ACM Transactions on Intelligent Systems and Technology|https://github.com/ijcruic/LLM-Stance-Labeling|https://doi.org/10.1145/3725816|
|101|Enhancing Gene Set Overrepresentation Analysis with Large Language Models|Jianjun Zhu, Rebecca Y. Wang, Xiaoting Wang, Ricardo B. R. Azevedo, Alexander Moreno, Julia Kuhn, Zia Khan|2025-03-13|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/Alector-BIO/llm2geneset|https://doi.org/10.1101/2024.11.11.621189|
|102|NTxPred2: A large language model for predicting neurotoxic peptides and neurotoxins|Anand Singh Rathore, Saloni Jain, Shubham Choudhury, Gajendra P. S. Raghava|2025-03-07|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/raghavagps/ntxpred2|https://doi.org/10.1101/2025.03.01.640936|
|103|Automatic recognition of cross-language classic entities based on large language models|Qiankun Xu, Yutong Liu, Dongbo Wang, Huang Shuiqing|2025-03-03|OpenAlex|https://github.com/Xunzi-LLM-of-Chinese-classics/XunziALLM|https://doi.org/10.1038/s40494-025-01624-y|
|104|SensitiveCancerGPT: Leveraging Generative Large Language Model on Structured Omics Data to Optimize Drug Sensitivity Prediction|Shaika Chowdhury, Sivaraman Rajaganapathy, Lichao Sun, Liewei Wang, Ping Yang, James R. Cerhan, Nansu Zong|2025-02-28|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/bioIKEA/SensitiveCancerGPT.|https://doi.org/10.1101/2025.02.27.640661|
|105|TritonBench: Benchmarking Large Language Model Capabilities for   Generating Triton Operators|Jianling Li, Shaohui Li, Zhihao Gao, Qi Shi, Yuxuan Li, Zefan Wang, Jie Huang, Haojie Wang, Jianrong Wang, Xu Han, Zhiyu...|2025-02-20|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/thunlp/TritonBench.|https://doi.org/10.18653/v1/2025.findings-acl.1183|
|106|Dynamic Low-Rank Sparse Adaptation for Large Language Models|Weizhong Huang, Yuxin Zhang, Xiawu Zheng, Yang Liu, Jing Lin, Yiwu Yao, Rongrong Ji|2025-02-20|ICLR|https://github.com/wzhuang-xmu/LoSA.|https://openreview.net/forum?id=oXh0939Zzq|
|107|CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems   Based on Large Language Models|Zhenhong Zhou, Zherui Li, Jie Zhang, Yuanhe Zhang, Kun Wang, Yang Liu, Qing Guo|2025-02-20|arXiv|https://github.com/zhrli324/Corba.|https://doi.org/10.48550/arXiv.2502.14529|
|108|AI-Empowered Catalyst Discovery: A Survey from Classical Machine   Learning Approaches to Large Language Models|Yuanyuan Xu, Hanchen Wang, Wenjie Zhang, Lexing Xie, Yin Chen, Flora D. Salim, Ying Zhang, J. Justin Gooding, Toby Walsh|2025-02-19|arXiv|https://github.com/LuckyGirl-XU/Awesome-Artificial-Intelligence-Empowered-Catalyst-Discovery.|https://doi.org/10.48550/arXiv.2502.13626|
|109|Collaborative Retrieval for Large Language Model-based Conversational   Recommender Systems|Yaochen Zhu, Chao Wan, Harald Steck, Dawen Liang, Yesu Feng, Nathan Kallus, Jundong Li|2025-02-19|OpenAlex|https://github.com/yaochenzhu/CRAG.|https://doi.org/10.48550/arXiv.2502.14137|
|110|Lost in Sequence: Do Large Language Models Understand Sequential   Recommendation?|Sein Kim, Hongseok Kang, Kibum Kim, Jiwan Kim, Donghyun Kim, Minchul Yang, Kwangjin Oh, Julian J. McAuley, Chanyoung Par...|2025-02-19|OpenAlex|https://github.com/Sein-Kim/LLM-SRec.|https://doi.org/10.48550/arXiv.2502.13909|
|111|On the logical skills of large language models: evaluations using   arbitrarily complex first-order logic problems|Shokhrukh Ibragimov, Arnulf Jentzen, Benno Kuckuck|2025-02-19|arXiv|https://github.com/bkuckuck/logical-skills-of-llms.|https://doi.org/10.48550/arXiv.2502.14180|
|112|Evaluation of ChatGPT and Gemini large language models for pharmacometrics with NONMEM|Euibeom Shin, Yifan Yu, Robert R. Bies, Murali Ramanathan|2025-02-18|Journal of Pharmacokinetics and Pharmacodynamics|https://github.com/metrumresearchgroup/mrgsolve20.|https://doi.org/10.21203/rs.3.rs-4189234/v1|
|113|Evaluation of Large Language Models for an AI Chat Assistant Focused on Pumas and Pharmacometrics|Juan Javier Gonz√°lez Barbosa, Agastya Vinchhi, Vijay Ivaturi|2025-02-18|OpenAlex|https://github.com/explodinggradients/ragas|https://doi.org/10.70534/jnza2834|
|114|G-Refer: Graph Retrieval-Augmented Large Language Model for Explainable   Recommendation|Yuhan Li, Xinni Zhang, Linhao Luo, Heng Chang, Yuxiang Ren, Irwin King, Jia Li|2025-02-18|OpenAlex|https://github.com/Yuhan1i/G-Refer.|https://doi.org/10.48550/arXiv.2502.12586|
|115|PTQ1.61: Push the Real Limit of Extremely Low-Bit Post-Training   Quantization Methods for Large Language Models|Jiaqi Zhao, Miao Zhang, Ming Wang, Yuzhang Shang, Kaihao Zhang, Weili Guan, Yaowei Wang, Danshi Wang|2025-02-18|OpenAlex|https://github.com/zjq0455/PTQ1.61.|https://doi.org/10.18653/v1/2025.acl-long.225|
|116|SEA: Low-Resource Safety Alignment for Multimodal Large Language Models   via Synthetic Embeddings|Weikai Lu, Hao Peng, Huiping Zhuang, Cen Chen, Ziqian Zeng|2025-02-18|OpenAlex|https://github.com/ZeroNLP/SEA.|https://doi.org/10.18653/v1/2025.acl-long.1212|
|117|$\mathttGeLLM^3O$: Generalizing Large Language Models for   Multi-property Molecule Optimization|Vishal Dey, Xiao Hu, Xia Ning|2025-02-18|arXiv (Cornell University)|https://github.com/ninglab/GeLLMO.|http://arxiv.org/abs/2502.13398|
|118|VRoPE: Rotary Position Embedding for Video Large Language Models|Zikang Liu, Longteng Guo, Yepeng Tang, Junxian Cai, Kai Ma, Xi Chen, Jing Liu|2025-02-17|arXiv|https://github.com/johncaged/VRoPE|https://doi.org/10.48550/arXiv.2502.11664|
|119|RIDE: Enhancing Large Language Model Alignment through Restyled   In-Context Learning Demonstration Exemplars|Yuncheng Hua, Lizhen Qu, Zhuang Li, Hao Xue, Flora D. Salim, Gholamreza Haffari|2025-02-17|arXiv|https://github.com/AnonymousCode-ComputerScience/RIDE.|https://doi.org/10.48550/arXiv.2502.11681|
|120|A Survey of Personalized Large Language Models: Progress and Future   Directions|Jiahong Liu, Zexuan Qiu, Zhongyang Li, Quanyu Dai, Jieming Zhu, Minda Hu, Menglin Yang, Irwin King|2025-02-17|arXiv|https://github.com/JiahongLiu21/Awesome-Personalized-Large-Language-Models.|https://doi.org/10.48550/arXiv.2502.11528|
|121|Idiosyncrasies in Large Language Models|Ming-Jie Sun, Yue Yin, Zeshui Xu, J. Zico Kolter, Zhuang Liu|2025-02-17|arXiv|https://github.com/locuslab/llm-idiosyncrasies.|https://doi.org/10.48550/arXiv.2502.12150|
|122|BoT: Breaking Long Thought Processes of o1-like Large Language Models   through Backdoor Attack|Zihao Zhu, Hongbao Zhang, Mingda Zhang, Ruotong Wang, Guanzong Wu, Ke Xu, Baoyuan Wu|2025-02-16|arXiv|https://github.com/zihao-ai/BoT|https://doi.org/10.48550/arXiv.2502.12202|
|123|CORDIAL: Can Multimodal Large Language Models Effectively Understand   Coherence Relationships?|Aashish Anantha Ramakrishnan, Aadarsh Anantha Ramakrishnan, Dongwon Lee|2025-02-16|OpenAlex|https://github.com/aashish2000/CORDIAL.|https://doi.org/10.18653/v1/2025.acl-long.1033|
|124|Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical   Abilities in Large Language Models|Haoyang Li, Xuejia Chen, Zhanchao Xu, Darian Li, Nicole Hu, Fei Teng, Yiming Li, Luyu Qiu, Chen Jason Zhang, Qing Li, Le...|2025-02-16|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/TreeAI-Lab/NumericBench.|https://doi.org/10.18653/v1/2025.findings-acl.1026|
|125|Reasoning-Augmented Conversation for Multi-Turn Jailbreak Attacks on   Large Language Models|Zonghao Ying, Deyue Zhang, Zonglei Jing, Yisong Xiao, Quanchen Zou, Aishan Liu, Siyuan Liang, Xiangzheng Zhang, Xianglon...|2025-02-16|arXiv|https://github.com/NY1024/RACE|https://doi.org/10.48550/arXiv.2502.11054|
|126|SURGE: On the Potential of Large Language Models as General-Purpose   Surrogate Code Executors|Bo Lyu, Susan S. Huang, Zhengzhao Liang|2025-02-16|arXiv|https://github.com/Imbernoulli/SURGE.|https://doi.org/10.48550/arXiv.2502.11167|
|127|Utilizing Pretrained Vision Transformers and Large Language Models for Epileptic Seizure Prediction|Paras Parani, Umair Mohammad, Fahad Saeed|2025-02-16|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/pcdslab/UtilLLM_EPS|https://doi.org/10.1109/cdma61895.2025.00028|
|128|Injecting Domain-Specific Knowledge into Large Language Models: A   Comprehensive Survey|Zhihua Song, Bin Yan, Yuhan Liu, Miao Fang, Mingzhe Li, Rui Yan, Xiuying Chen|2025-02-15|arXiv|https://github.com/abilliyb/Knowledge_Injection_Survey_Papers|https://doi.org/10.48550/arXiv.2502.10708|
|129|LANTERN: Leveraging Large Language Models and Transformers for Enhanced Molecular Interactions|Cong Nga Ha, Phuong Viet Pham, Truong Son Hy|2025-02-15|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/HySonLab/LANTERN|https://doi.org/10.1101/2025.02.10.637522|
|130|SQuARE: Sequential Question Answering Reasoning Engine for Enhanced   Chain-of-Thought in Large Language Models|Daniel Fleischer, Moshe Berchansky, George Markovits, Moshe Wasserblat|2025-02-13|arXiv|https://github.com/IntelLabs/RAG-FiT|https://doi.org/10.48550/arXiv.2502.09390|
|131|Data Augmentation to Improve Large Language Models in Food Hazard and   Product Detection|Areeg Fahad Rasheed, Mahdi Zarkoosh, Shimam Amer Chasib, Safa F. Abbas|2025-02-12|arXiv|https://github.com/AREEG94FAHAD/food-hazard-prdouct-cls|https://doi.org/10.48550/arXiv.2502.08687|
|132|Do Large Language Models have Spatial Cognitive Abilities?|Ruoling Wu, Danhuai Guo|2025-02-11|ACM Transactions on Intelligent Systems and Technology|https://github.com/LLING000/SCABenchmark|https://doi.org/10.1145/3716855|
|133|DrugImproverGPT: A Large Language Model for Drug Optimization with   Fine-Tuning via Structured Policy Optimization|Xuefeng Liu, Songhao Jiang, Siyu Chen, Zhuoran Yang, Yuxin Chen, Ian T. Foster, Rick Stevens|2025-02-10|arXiv|https://github.com/xuefeng-cs/DrugImproverGPT.|https://doi.org/10.48550/arXiv.2502.07237|
|134|Large Language Models Meet Symbolic Provers for Logical Reasoning   Evaluation|Chengwen Qi, Ren Ma, Bowen Li, He Du, Binyuan Hui, Jinwang Wu, Yuanjun Laili, Conghui He|2025-02-10|ICLR|https://github.com/opendatalab/ProverGen|https://openreview.net/forum?id=C25SgeXWjE|
|135|Large Language Models in Software Security: A Survey of Vulnerability   Detection Techniques and Insights|Ze Sheng, Zhicheng Chen, Shanqiang Gu, Heqing Huang, Guofei Gu, Jeff Huang|2025-02-10|arXiv (Cornell University)|https://github.com/OwenSanzas/LLM-For-Vulnerability-Detection|http://arxiv.org/abs/2502.07049|
|136|RALLRec: Improving Retrieval Augmented Large Language Model   Recommendation with Representation Learning|Jian Xu, Sichun Luo, Xiangyu Chen, Haifeng Huang, Hanxu Hou, Linqi Song|2025-02-09|OpenAlex|https://github.com/JianXu95/RALLRec.|https://doi.org/10.48550/arXiv.2502.06101|
|137|XiHeFusion: Harnessing Large Language Models for Science Communication   in Nuclear Fusion|Xiao Wang, Qingquan Yang, Fuling Wang, Qiang Chen, Wann‚ÄêYih Wu, Yu Jin, Jun Jiang, Liang Jin, Bo Jiang, Dengdi Sun, Wenz...|2025-02-08|arXiv|https://github.com/Event-AHU/XiHeFusion.|https://doi.org/10.48550/arXiv.2502.05615|
|138|Top-DTI: Integrating Topological Deep Learning and Large Language Models for Drug Target Interaction Prediction|Muhammed Talo, Serdar Bozdag|2025-02-08|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/bozdaglab/Top_DTI|https://doi.org/10.1093/bioinformatics/btaf183|
|139|Predicting Large Language Model Capabilities on Closed-Book QA Tasks   Using Only Information Available Prior to Training|Changhao Jiang, Ming Zhang, Junjie Ye, Xiaoran Fan, Yifei Cao, Jiajun Sun, Zhiheng Xi, Shihan Dou, Yi Dong, Yujiong Shen...|2025-02-06|arXiv|https://github.com/yuhui1038/SMI.|https://doi.org/10.48550/arXiv.2502.04066|
|140|Knowledge Distillation from Large Language Models for Household Energy   Modeling|Mohannad Takrouri, Nicolas Mauricio Cuadrado, Martin Tak√°ƒç|2025-02-05|arXiv|https://github.com/Singularity-AI-Lab/LLM-Energy-Knowledge-Distillation|https://doi.org/10.48550/arXiv.2502.03034|
|141|Intent Representation Learning with Large Language Model for   Recommendation|Yu Wang, Lei Sang, Yi Zhang, Yiwen Zhang|2025-02-05|Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval|https://github.com/wangyu0627/IRLLRec.|https://doi.org/10.1145/3726302.3730011|
|142|Risk-Aware Driving Scenario Analysis with Large Language Models|Y. S. Gao, Mattia Piccinini, Johannes Betz|2025-02-04|arXiv|https://github.com/yuangao-tum/Riskaware-Scenario-analyse|https://doi.org/10.48550/arXiv.2502.02145|
|143|Reinforced Prompt Personalization for Recommendation with Large Language Models|Wenyu Mao, Jiancan Wu, Weijian Chen, Chongming Gao, Xiang Wang, Xiangnan He|2025-02-04|ACM transactions on office information systems|https://github.com/maowenyu-11/RPP|https://doi.org/10.48550/arXiv.2407.17115|
|144|SAISA: Towards Multimodal Large Language Models with Both Training and   Inference Efficiency|Qianhao Yuan, Yanjiang Liu, Yaojie Lu, Hongyu Lin, Ben He, Xianpei Han, Le Sun|2025-02-04|arXiv|https://github.com/icip-cas/SAISA.|https://doi.org/10.48550/arXiv.2502.02458|
|145|AtmosSci-Bench: Evaluating the Recent Advance of Large Language Model   for Atmospheric Science|Chenyue Li, Wen Deng, Mengqian Lu, Binhang Yuan|2025-02-03|arXiv|https://github.com/Relaxed-System-Lab/AtmosSci-Bench.|https://doi.org/10.48550/arXiv.2502.01159|
|146|Breaking Focus: Contextual Distraction Curse in Large Language Models|Yue Huang, Yanbo Wang, Zixiang Xu, Chujie Gao, Siyuan Wu, Jiayi Ye, Xiuying Chen, Pin-Yu Chen, Xiangliang Zhang|2025-02-03|arXiv|https://github.com/wyf23187/LLM_CDV.|https://doi.org/10.48550/arXiv.2502.01609|
|147|Robust-LLaVA: On the Effectiveness of Large-Scale Robust Image Encoders   for Multi-modal Large Language Models|Hashmat Shadab Malik, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar, Fahad Shahbaz Khan, Salman Khan|2025-02-03|arXiv|https://github.com/HashmatShadab/Robust-LLaVA.|https://doi.org/10.48550/arXiv.2502.01576|
|148|sciLaMA: A Single-Cell Representation Learning Framework to Leverage Prior Knowledge from Large Language Models|Hongru Hu, Shuwen Zhang, Yongin Choi, Venkat S. Malladi, Gerald Quon|2025-02-03|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/microsoft/sciLaMA.|https://doi.org/10.1101/2025.01.28.635153|
|149|AdaSVD: Adaptive Singular Value Decomposition for Large Language Models|Zhiteng Li, Mingyuan Xia, Jingyuan Zhang, Hui Zheng, Linghe Kong, Yulun Zhang, Xiaokang Yang|2025-02-03|arXiv|https://github.com/ZHITENGLI/AdaSVD.|https://doi.org/10.48550/arXiv.2502.01403|
|150|MetaOpenFOAM 2.0: Large Language Model Driven Chain of Thought for   Automating CFD Simulation and Post-Processing|Yuxuan Chen, Xu Zhu, Hua Zhou, Zhuyin Ren|2025-02-01|arXiv|https://github.com/Terry-cyx/MetaOpenFOAM|https://doi.org/10.48550/arXiv.2502.00498|
|151|Speculative Ensemble: Fast Large Language Model Ensemble via Speculation|Jiale Fu, Yuchu Jiang, Junkai Chen, Jiaming Fan, Peng Geng, Yang Xu|2025-02-01|arXiv|https://github.com/Kamichanw/Speculative-Ensemble|https://doi.org/10.48550/arXiv.2502.01662|
|152|LIBRA: Measuring Bias of Large Language Model from a Local Context|B. Y. Pang, Tingrui Qiao, Caroline Walker, Chris Cunningham, Yun Sing Koh|2025-02-01|Lecture notes in computer science|https://github.com/ipangbo/LIBRA.|https://doi.org/10.1007/978-3-031-88708-6_1|
|153|LLMDet: Learning Strong Open-Vocabulary Object Detectors under the   Supervision of Large Language Models|Shenghao Fu, Qize Yang, Qijie Mo, Junkai Yan, Xihan Wei, Jingke Meng, Xiaohua Xie, Wei-Shi Zheng|2025-01-31|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/iSEE-Laboratory/LLMDet.|https://openaccess.thecvf.com/content/CVPR2025/html/Fu_LLMDet_Learning_Strong_Open-Vocabulary_Object_Detectors_under_the_Supervision_of_CVPR_2025_paper.html|
|154|Panacea: Mitigating Harmful Fine-tuning for Large Language Models via   Post-fine-tuning Perturbation|Yibo Wang, Tiansheng Huang, Li Shen, Huanjin Yao, Haotian Luo, Rui Liu, Naiqiang Tan, Jiaxing Huang, Dacheng Tao|2025-01-29|arXiv|https://github.com/w-yibo/Panacea|https://doi.org/10.48550/arXiv.2501.18100|
|155|Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing   Guardrail Moderation|Tiansheng Huang, Sihao Hu, Fatih ƒ∞lhan, Selim Furkan Tekin, Ling Liu|2025-01-29|arXiv|https://github.com/git-disl/Virus|https://doi.org/10.48550/arXiv.2501.17433|
|156|SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of   Large Language Model|Xun Liang, Simin Niu, Zhiyu Li, Sensen Zhang, Hanyu Wang, Feiyu Xiong, Jianqing Fan, Bo Tang, Shichao Song, Mengwei Wang...|2025-01-28|OpenAlex|https://github.com/IAAR-Shanghai/SafeRAG.|https://doi.org/10.18653/v1/2025.acl-long.230|
|157|Large Language Model Critics for Execution-Free Evaluation of Code   Changes|Aashish Yadavally, Hoan Anh Nguyen, Laurent Callot, Gauthier Guinet|2025-01-27|arXiv|https://github.com/amazon-science/code-agent-eval.|https://doi.org/10.48550/arXiv.2501.16655|
|158|Analyzing and Boosting the Power of Fine-Grained Visual Recognition for   Multi-modal Large Language Models|Hulingxiao He, Geng Li, Zengmin Geng, Jinglin Xu, Yuxin Peng|2025-01-25|ICLR|https://github.com/PKU-ICST-MIPL/Finedefics_ICLR2025.|https://openreview.net/forum?id=p3NKpom1VL|
|159|JustLogic: A Comprehensive Benchmark for Evaluating Deductive Reasoning   in Large Language Models|Michael K. Chen, Xikun Zhang, Dacheng Tao|2025-01-24|arXiv|https://github.com/michaelchen-lab/JustLogic|https://doi.org/10.48550/arXiv.2501.14851|
|160|Can Large Language Models Understand Preferences in Personalized   Recommendation?|Zhaoxuan Tan, Zinan Zeng, Qingkai Zeng, Zhenyu Wu, Zheyuan Liu, Fengran Mo, Meng Jiang|2025-01-23|arXiv|https://github.com/TamSiuhin/PerRecBench|https://doi.org/10.48550/arXiv.2501.13391|
|161|OstQuant: Refining Large Language Model Quantization with Orthogonal and   Scaling Transformations for Better Distribution Fitting|Xing Hu, Yuan Cheng, Dawei Yang, Zhixuan Chen, Zukang Xu, Jiangyong Yu, Chen Xu, Zhihang Yuan, Zhe Jiang, Sifan Zhou|2025-01-23|ICLR|https://github.com/BrotherHappy/OSTQuant|https://openreview.net/forum?id=rAcgDBdKnP|
|162|Softplus Attention with Re-weighting Boosts Length Extrapolation in   Large Language Models|Bo Gao, Michael W. Spratling|2025-01-23|arXiv|https://github.com/iminfine/freeatten.|https://doi.org/10.48550/arXiv.2501.13428|
|163|An Empirical Characterization of Outages and Incidents in Public   Services for Large Language Models|Xiaoyu Chu, Sacheendra Talluri, Qingxian Lu, Alexandru Iosup|2025-01-21|OpenAlex|https://github.com/atlarge-research/llm-service-analysis.|https://doi.org/10.48550/arXiv.2501.12469|
|164|Can open source large language models be used for tumor documentation in Germany? - An evaluation on urological doctors&apos; notes|Stefan Lenz, Arsenij Ustjanzew, Marco Jeray, Meike Ressing, Torsten Panholzer|2025-01-21|BioData Mining|https://github.com/stefan-m-lenz/UroLlmEval.|https://doi.org/10.1186/s13040-025-00463-8|
|165|Distillation Quantification for Large Language Models|Sunbowen Lee, Junting Zhou, Chang Ao, Kaige Li, Xinrun Du, Sirui He, Jiaheng Liu, Min Yang, Zhoufutu Wen, Shiwen Ni|2025-01-21|arXiv|https://github.com/Aegis1863/LLMs-Distillation-Quantification.|https://doi.org/10.48550/arXiv.2501.12619|
|166|ESCARGOT: An AI Agent Leveraging Large Language Models, Dynamic Graph of Thoughts, and Biomedical Knowledge Graphs for Enhanced Reasoning|Nicholas Matsumoto, Hyun‚ÄêJun Choi, Jay Moran, Miguel Hernandez, Mythreye Venkatesan, Xi Li, Jui-Hsuan Chang, Paul P. Wan...|2025-01-20|Bioinformatics|https://github.com/EpistasisLab/ESCARGOT.|https://doi.org/10.1093/bioinformatics/btaf031|
|167|InsQABench: Benchmarking Chinese Insurance Domain Question Answering   with Large Language Models|Jing Ding, Feng Kai, Binbin Lin, J. G. Cai, Qiushi Wang, Y. G. Xie, Xiaojin Zhang, Zhongyu Wei, Wei Chen|2025-01-18|arXiv|https://github.com/HaileyFamo/InsQABench.git.|https://doi.org/10.48550/arXiv.2501.10943|
|168|CXR-LLaVA: a multimodal large language model for interpreting chest X-ray images|Seowoo Lee, M. D., Jiwon Youn, Mansu Kim D., Soon Ho Yoon, M. D. D|2025-01-15|European Radiology|https://github.com/ECOFRI/CXR_LLAVA.|https://doi.org/10.1007/s00330-024-11339-6|
|169|PokerBench: Training Large Language Models to become Professional Poker   Players|Richard Zhuang, Akshat Gupta, Chunhui Yang, Aniket Rahane, Zhengyu Li, Gopala Anumanchipalli|2025-01-14|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/pokerllm/pokerbench|https://doi.org/10.1609/aaai.v39i24.34814|
|170|LLM4SR: A Survey on Large Language Models for Scientific Research|Zhongling Luo, Zonglin Yang, Zheng Xu, Wei Yang, Xinya Du|2025-01-08|arXiv|https://github.com/du-nlp-lab/LLM4SR|https://doi.org/10.48550/arXiv.2501.04306|
|171|Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of   Large Language Models|Qianchen Ren, Jie Zeng, Qianyu He, Jiaqing Liang, Yanghua Xiao, Weikang Zhou, Z. J. Sun, F. Richard Yu|2025-01-08|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/Rainier-rq/FollowSoftConstraints.|https://doi.org/10.18653/v1/2025.findings-acl.1004|
|172|ChronoSense: Exploring Temporal Understanding in Large Language Models   with Time Intervals of Events|Duygu Sezen Islakoglu, Jan-Christoph Kalo|2025-01-06|OpenAlex|https://github.com/duyguislakoglu/chronosense.|https://doi.org/10.18653/v1/2025.acl-short.46|
|173|Visual Large Language Models for Generalized and Specialized   Applications|Yifan Li, Zhixin Lai, Wentao Bao, Zhen Tan, Anh Dao, Kewei Sui, Jiayi Shen, Dong Liu, Huan Liu, Yu Kong|2025-01-06|arXiv|https://github.com/JackYFL/awesome-VLLMs.|https://doi.org/10.48550/arXiv.2501.02765|
|174|MIRAGE: Exploring How Large Language Models Perform in Complex Social   Interactive Environments|Cai Yin, Zhouhong Gu, Zhangxin Du, Zheyu Ye, Shaosheng Cao, Yiqian Xu, Hongwei Feng, Ping Chen|2025-01-03|OpenAlex|https://github.com/lime728/MIRAGE|https://doi.org/10.18653/v1/2025.acl-short.2|
|175|Cold-Start Recommendation towards the Era of Large Language Models   (LLMs): A Comprehensive Survey and Roadmap|Wei Zhang, Yuanchen Bei, Liangwei Yang, Henry Peng Zou, Peilin Zhou, Aiwei Liu, Yinghui Li, Liqiao Chen, Jian-Ling Wang,...|2025-01-03|arXiv|https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation.|https://doi.org/10.48550/arXiv.2501.01945|
|176|Aligning Large Language Models for Faithful Integrity Against Opposing   Argument|Yong Zhao, Yang Deng, See-Kiong Ng, Tat‚ÄêSeng Chua|2025-01-02|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/zhaoy777/AFICE.git|https://doi.org/10.1609/aaai.v39i26.34990|
|177|Neuro-Symbolic Artificial Intelligence: Towards Improving the Reasoning Abilities of Large Language Models|Xiao-Wen Yang, Jie-Jing Shao, Lan-Zhe Guo, Bo-Wen Zhang, Zhi Zhou, Lin-Han Jia, Wang-Zhou Dai, Yufeng Li|2025-01-01|OpenAlex|https://github.com/LAMDASZ-ML/Awesome-LLM-Reasoning-with-NeSy.|https://doi.org/10.48550/arXiv.2508.13678|
|178|QuickLLaMA: Query-aware Inference Acceleration for Large Language Models|Jingyao Li, Han Shi, Sitong Wu, Chuanyang Zheng, Zhenguo Li, Xin Jiang, Hong Xu, Jiaya Jia|2025-01-01|COLING|https://github.com/dvlab-research/Q-LLM.|https://aclanthology.org/2025.coling-main.34/|
|179|Predicting differentially methylated cytosines in TET and DNMT3 knockout mutants via a large language model|Stefano Lonardi, Stefano Lonardi|2025-01-01|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/ucrbioinfo/dmc_prediction.|https://doi.org/10.1101/2024.05.02.592257|
|180|PointLLM-V2: Empowering Large Language Models to Better Understand Point Clouds|Runsen Xu, Shuai Yang, Xiaolong Wang, Tai Wang, Yilun Chen, Jiangmiao Pang, Dahua Lin|2025-01-01|IEEE Transactions on Pattern Analysis and Machine Intelligence|https://github.com/OpenRobotLab/PointLLM.|https://doi.org/10.1007/978-3-031-72698-9_8|
|181|Pipeline to explore information on genome editing using large language models and genome editing meta-database|Takayuki Suzuki, Hidemasa Bono|2025-01-01|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/szktkyk/extract_geinfo|https://doi.org/10.1101/2024.10.16.617154|
|182|PIP: Perturbation-based Iterative Pruning for Large Language Models|Yi Cao, Wei-Jie Xu, Yucheng Shen, Weijie Shi, Chi-Min Chan, Jiajie Xu|2025-01-01|arXiv|https://github.com/caoyiiiiii/PIP.|https://doi.org/10.48550/arXiv.2501.15278|
|183|PAT: Pruning-Aware Tuning for Large Language Models|Yijiang Liu, Huanrui Yang, Youxin Chen, Rongyu Zhang, Miao Wang, Yuan Du, Li Du|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/kriskrisliu/PAT_Pruning-Aware-Tuning|https://doi.org/10.1609/aaai.v39i23.34649|
|184|Neuron based Personality Trait Induction in Large Language Models|Jia Deng, Tianyi Tang, Yanbin Yin, Wenhao Yang, Wayne Xin Zhao, Ji-Rong Wen|2025-01-01|ICLR|https://github.com/RUCAIBox/NPTI.|https://openreview.net/forum?id=LYHEY783Np|
|185|Multi-Agent Systems Powered by Large Language Models: Applications in Swarm Intelligence|Cristian Jimenez-Romero, Alper Yegenoglu, Christian Blum|2025-01-01|Frontiers in Artificial Intelligence|https://github.com/crjimene/swarm_gpt|https://doi.org/10.48550/arXiv.2503.03800|
|186|ReLearn: Unlearning via Learning for Large Language Models|Haoming Xu, Ningyuan Zhao, Liming Yang, Sendong Zhao, Shumin Deng, Mengru Wang, Bryan Hooi, Nay Oo, Huajun Chen, Ningyu ...|2025-01-01|OpenAlex|https://github.com/zjunlp/unlearn.|https://doi.org/10.18653/v1/2025.acl-long.297|
|187|MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large Language Model Agents|Pan Tang, Shixiang Tang, Huanqi Pu, Zhiqing Miao, Zhixing Wang|2025-01-01|arXiv|https://github.com/tangpan360/MicroRCA-Agent.|https://doi.org/10.48550/arXiv.2509.15635|
|188|Medical Graph RAG: Evidence-based Medical Large Language Model via Graph Retrieval-Augmented Generation|Junde Wu, Jiayuan Zhu, Yunli Qi, Jingkun Chen, Min Xu, Filippo Menolascina, Yueming Jin, Vicente Grau|2025-01-01|OpenAlex|https://github.com/MedicineToken/Medical-Graph-RAG|https://doi.org/10.18653/v1/2025.acl-long.1381|
|189|Mat-Instructions: A Large-Scale Inorganic Material Instruction Dataset for Large Language Models|Peng Liu, Shangde Gao, Yongqing Fu, Xiaoliang Wu, Stephen Tong, Ajitha Rajan, Hao Xu|2025-01-01|OpenAlex|https://github.com/zjuKeLiu/Mat-Instructions|https://doi.org/10.24963/ijcai.2025/1089|
|190|M4Bench: A Benchmark of Multi-domain Multi-granularity Multi-image Understanding for Multi-modal Large Language Models|Xiaojun Ye, Guanbao Liang, Chun Wang, Liangcheng Li, Pengfei Ke, Rui Wang, Bingxin Jia, Gang Huang, Qiao Sun, Sheng Zhou|2025-01-01|OpenAlex|https://github.com/eaglelab-zju/M4Bench.|https://doi.org/10.24963/ijcai.2025/762|
|191|Leveraging Large Language Models for Predictive Analysis of Human Misery|Bishanka Seal, Rahul Seetharaman, Aman Bansal, Abhilash Nandy|2025-01-01|arXiv|https://github.com/abhi1nandy2/Misery_Data_Exps_GitHub|https://doi.org/10.48550/arXiv.2508.12669|
|192|Large language models open new way of AI-assisted molecule design for chemists|Shoichi Ishida, Tomohiro Sato, Teruki Honma, Kei Terayama|2025-01-01|Journal of Cheminformatics|https://github.com/molecule-generator-collection/ChatChemTS.|https://doi.org/10.26434/chemrxiv-2024-1p82f|
|193|Large Language Models as Virtual Survey Respondents: Evaluating Sociodemographic Response Generation|Jianpeng Zhao, Chenyu Yuan, Weiming Luo, Haoling Xie, Guangwei Zhang, Steven Jige Quan, Zixuan Yuan, Pengyang Wang, Deng...|2025-01-01|arXiv|https://github.com/dart-lab-research/LLM-S-Cube-Benchmark|https://doi.org/10.48550/arXiv.2509.06337|
|194|REEF: Representation Encoding Fingerprints for Large Language Models|Jie Zhang, Dongrui Liu, Chen Qian, Linfeng Zhang, Yong Liu, Yu Qiao, Jing Shao|2025-01-01|ICLR|https://github.com/tmylla/REEF.|https://openreview.net/forum?id=SnDmPkOJ0T|
|195|Reliable Academic Conference Question Answering: A Study Based on Large Language Model|Zhiwei Huang, Long Jin, Junjie Wang, Mingchen Tu, Hua Yin, Zhiqiang Liu, Jiawei Meng, Huajun Chen, Wen Zhang|2025-01-01|Communications in computer and information science|https://github.com/zjukg/ConferenceQA.|https://doi.org/10.1007/978-981-96-1809-5_14|
|196|Labels Generated by Large Language Model Helps Measuring People&apos;s Empathy in Vitro|Md. Rakibul Hasan, Yue Yao, Md. Zakir Hossain, Aneesh Krishna, Imre J. Rudas, Shafin Rahman, Tom Gedeon|2025-01-01|arXiv|https://github.com/hasan-rakibul/LLMPathy|https://doi.org/10.48550/arXiv.2501.00691|
|197|Towards Atoms of Large Language Models|Chenhui Hu, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao|2025-01-01|arXiv|https://github.com/ChenhuiHu/towards_atoms.|https://doi.org/10.48550/arXiv.2509.20784|
|198|A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models|Ching Chang, Yidan Shi, Defu Cao, Wei Yang, Jeehyun Hwang, Haixin Wang, Jiacheng Pang, Wei Wang, Yan Liu, Wen-Chih Peng,...|2025-01-01|arXiv|https://github.com/blacksnail789521/Time-Series-Reasoning-Survey|https://doi.org/10.48550/arXiv.2509.11575|
|199|WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct|Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jian-Guang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, Yanson...|2025-01-01|ICLR|https://github.com/nlpxucan/WizardLM|https://openreview.net/forum?id=mMPMHWOdOy|
|200|VirNucPro: an identifier for the identification of viral short sequences using six-frame translation and large language models|Jing Li, Jia Mi, Wei Lin, Fengjuan Tian, Jing Wan, Jingyang Gao, Yigang Tong|2025-01-01|Briefings in Bioinformatics|https://github.com/Li-Jing-1997/VirNucPro.|https://doi.org/10.1093/bib/bbaf224|
|201|Veracity-Oriented Context-Aware Large Language Models-Based Prompting Optimization for Fake News Detection|Weiqiang Jin, Yang Gao, Tao Tao, Xiujun Wang, Ningwei Wang, Baohai Wu, Biao Zhao|2025-01-01|International Journal of Intelligent Systems|https://github.com/albert-jin/CAPE-FND|https://doi.org/10.1155/int/5920142|
|202|User Behavior Simulation with Large Language Model-based Agents for Recommender Systems|Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Hao Sun, Ruihua Song, Xin...|2025-01-01|ACM transactions on office information systems|https://github.com/RUC-GSAI/YuLan-Rec|https://doi.org/10.1145/3708985|
|203|TypedThinker: Diversify Large Language Model Reasoning with Typed Thinking|Danqing Wang, Jianxin Ma, Fei Fang, Lei Li|2025-01-01|ICLR|https://github.com/dqwang122/ThinkHub.|https://openreview.net/forum?id=VIUisLx8lQ|
|204|Tree of Agents: Improving Long-Context Capabilities of Large Language Models through Multi-Perspective Reasoning|Song Yu, Xiaofei Xu, Ke Deng, Li Li, Lin Tian|2025-01-01|arXiv|https://github.com/Aireduce952/Tree-of-Agents.|https://doi.org/10.48550/arXiv.2509.06436|
|205|Toward Reliable Biomedical Hypothesis Generation: Evaluating Truthfulness and Hallucination in Large Language Models|Guangzhi Xiong, Eric Xie, Corey Williams, Myles Kim, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhan...|2025-01-01|OpenAlex|https://github.com/Teddy-XiongGZ/TruthHypo.|https://doi.org/10.48550/arXiv.2505.14599|
|206|Rethinking Reasoning Quality in Large Language Models through Enhanced Chain-of-Thought via RL|Hongming He, Zihua Rong, Kunpeng Ji, Chenyang Li, Qing Huang, ÂÖÖÊ≠£ ÂÆÆ‰∏ã, Lan Yang, Honggang Zhang|2025-01-01|arXiv|https://github.com/Henryhe09/DRER.|https://doi.org/10.48550/arXiv.2509.06024|
|207|Taming Unleashed Large Language Models With Blockchain for Massive Personalized Reliable Healthcare|Lianshan Sun, Diandong Liu, Maoxue Wang, Yongyi Han, Yanqing Zhang, Biwei Zhou, Yi Ren, Peng zhu|2025-01-01|IEEE Journal of Biomedical and Health Informatics|https://github.com/LDDLQ/ChatCBD.|https://doi.org/10.1109/JBHI.2025.3528526|
|208|Systematic Outliers in Large Language Models|Yongqi An, Xu Zhao, Tao Yu, Ming Tang, Jinqiao Wang|2025-01-01|ICLR|https://github.com/an-yongqi/systematic-outliers.|https://openreview.net/forum?id=rLX7Vyyzus|
|209|Schema Inference for Tabular Data Repositories Using Large Language Models|Zhenyu Wu, Jiaoyan Chen, Norman W. Paton|2025-01-01|arXiv|https://github.com/PierreWoL/SILLM.|https://doi.org/10.48550/arXiv.2509.04632|
|210|STLSP: Integrating Structure and Text with Large Language Models for Link Sign Prediction of Networks|Lijia Ma, Haoyang Fu, Zhijie Cao, Xiongnan Jin, Qiuzhen Lin, Jianqiang Li|2025-01-01|OpenAlex|https://github.com/sss483/STLSP.|https://doi.org/10.24963/ijcai.2025/354|
|211|SPRI: Aligning Large Language Models with Context-Situated Principles|Hongli Zhan, Muneeza Azmat, Raya Horesh, Junyi Jessy Li, Mikhail Yurochkin|2025-01-01|arXiv|https://github.com/honglizhan/SPRI-public.|https://doi.org/10.48550/arXiv.2502.03397|
|212|SCRA-VQA: Summarized Caption-Rerank for Augmented Large Language Models in Visual Question Answering|Zhang Yan, Jiaqing Lin, Miao Zhang, Kui Xiao, Xiaoju Hou, Jing Zhao, Zhifei Li|2025-01-01|arXiv|https://github.com/HubuKG/SCRA-VQA.|https://doi.org/10.48550/arXiv.2509.20871|
|213|SCAR: Data Selection via Style Consistency-Aware Response Ranking for Efficient Instruction-Tuning of Large Language Models|Zhuang Li, Yuncheng Hua, Thuy-Trang Vu, Haolan Zhan, Lizhen Qu, Gholamreza Haffari|2025-01-01|OpenAlex|https://github.com/zhuang-li/SCAR|https://doi.org/10.18653/v1/2025.acl-long.625|
|214|Large Language Models Meet Legal Artificial Intelligence: A Survey|Zhitian Hou, Zihan Ye, Nanli Zeng, Tianyong Hao, Kun Zeng|2025-01-01|arXiv|https://github.com/ZhitianHou/LLMs4LegalAI.|https://doi.org/10.48550/arXiv.2509.09969|
|215|A Closer Look at Machine Unlearning for Large Language Models|Xiaojian Yuan, Tianyu Pang, Chao Du, Kejiang Chen, Weiming Zhang, Min Lin|2025-01-01|ICLR|https://github.com/sail-sg/closer-look-LLM-unlearning.|https://openreview.net/forum?id=Q1MHvGmhyT|
|216|LMCBert: An Automatic Academic Paper Rating Model Based on Large Language Models and Contrastive Learning|Chuanbin Liu, Xiaowu Zhang, Hongfei Zhao, Zhijie Liu, Xi Xi, Lean Yu|2025-01-01|IEEE Transactions on Cybernetics|https://github.com/iioSnail/LMCBert.|https://doi.org/10.1109/TCYB.2025.3550203|
|217|Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?|Yifan Feng, Chengwu Yang, Xingliang Hou, Shaoyi Du, Shihui Ying, Zongze Wu, Yue Gao|2025-01-01|ICLR|https://github.com/iMoonLab/LLM4Hypergraph.|https://openreview.net/forum?id=28qOQwjuma|
|218|Comparing Bad Apples to Good Oranges: Aligning Large Language Models via   Joint Preference Optimization|Hritik Bansal, Ashima Suvarna, Gantavya Bhatt, Nanyun Peng, Kai-Wei Chang, Aditya Grover|2025-01-01|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/Hritikbansal/dove.|https://doi.org/10.18653/v1/2025.findings-acl.39|
|219|Comparative Analysis of Demonstration Selection Algorithms for In-Context Learning in Large Language Models (Student Abstract)|Dong Wook Shu, Mengnan Du|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/Tizzzzy/Demonstration_Selection_Overview.|https://doi.org/10.1609/aaai.v39i28.35299|
|220|Causal Intervention Is What Large Language Models Need for Spatio-Temporal Forecasting|Shijie Li, He Li, Xiaojing Li, Yong Xu, Zhenhong Lin, Huaiguang Jiang|2025-01-01|IEEE Transactions on Cybernetics|https://github.com/lishijie15/STCInterLLM.|https://doi.org/10.1109/TCYB.2025.3569333|
|221|CFD-LLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics|Nithin Somasekharan, Ling Yue, Yadi Cao, Weichao Li, Patrick Emami, Pochinapeddi Sai Bhargav, Anurag Acharya, Xingyu Xie...|2025-01-01|arXiv|https://github.com/NREL-Theseus/cfdllmbench|https://doi.org/10.48550/arXiv.2509.20374|
|222|CFBenchmark-MM: Chinese Financial Assistant Benchmark for Multimodal Large Language Model|Lei Yang, Jiangtong Li, Ming Jiang, Junjie Hu, Dawei Cheng, Zhijun Ding, Changjun Jiang|2025-01-01|arXiv|https://github.com/TongjiFinLab/CFBenchmark.|https://doi.org/10.48550/arXiv.2506.13055|
|223|CAPE: Context-Aware Personality Evaluation Framework for Large Language Models|Jivnesh Sandhan, Fei Cheng, Tushar Sandhan, Yugo Murawaki|2025-01-01|arXiv|https://github.com/jivnesh/CAPE|https://doi.org/10.48550/arXiv.2508.20385|
|224|CALM: Curiosity-Driven Auditing for Large Language Models|Xiaoyu Zheng, Longxiang Wang, Yi Liu, Xingjun Ma, Chao Shen, Cong Wang|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/x-zheng16/CALM.git.|https://doi.org/10.1609/aaai.v39i26.34991|
|225|Beyond Autoregression: An Empirical Study of Diffusion Large Language Models for Code Generation|Chunliang Li, Yitong Zhang, Jia Li, Liyi Cai, Ge Li|2025-01-01|arXiv|https://github.com/zhangyitonggg/dllm4code.|https://doi.org/10.48550/arXiv.2509.11252|
|226|Cumulative Reasoning with Large Language Models|Yifan Zhang, Jingqin Yang, Yang Yuan, Andrew Chi-Chih Yao|2025-01-01|Trans. Mach. Learn. Res.|https://github.com/iiis-ai/cumulative-reasoning.|https://openreview.net/forum?id=grW15p4eq2|
|227|Benchmarking DNA large language models on quadruplexes|Oleksandr Cherednichenko, Alan Herbert, Maria Poptsova|2025-01-01|Computational and Structural Biotechnology Journal|https://github.com/powidla/G4s-FMs.|https://doi.org/10.1016/j.csbj.2025.03.007|
|228|An Empirical Analysis of Uncertainty in Large Language Model Evaluations|Qiujie Xie, Qingqiu Li, Zhuohao Yu, Yuejie Zhang, Yue Zhang, Linyi Yang|2025-01-01|ICLR|https://github.com/hasakiXie123/LLM-Evaluator-Uncertainty.|https://openreview.net/forum?id=J4xLuCt2kg|
|229|Aligning, Autoencoding and Prompting Large Language Models for Novel Disease Reporting|Fenglin Liu, Xian Wu, Jinfa Huang, Bang Yang, Kim Branson, Patrick Schwab, Lei Clifton, Ping Zhang, Jiebo Luo, Yefeng Zh...|2025-01-01|IEEE Transactions on Pattern Analysis and Machine Intelligence|https://github.com/ai-in-health/PromptLLM.|https://doi.org/10.1109/tpami.2025.3534586|
|230|AgentGym: Evaluating and Training Large Language Model-based Agents across Diverse Environments|Zhiheng Xi, Yiwen Ding, Wen-Xiang Chen, Boyang Hong, Honglin Guo, Junzhe Wang, Xin Guo, Dingwen Yang, Chenyang Liao, He ...|2025-01-01|OpenAlex|https://github.com/WooooDyy/AgentGym.|https://doi.org/10.18653/v1/2025.acl-long.1355|
|231|Acoustic Prompt Tuning: Empowering Large Language Models with Audition Capabilities|Jinhua Liang, Xubo Liu, Wenwu Wang, Mark D. Plumbley, Huy P. Phan, Emmanouil Benetos|2025-01-01|IEEE Transactions on Audio Speech and Language Processing|https://github.com/JinhuaLiang/APT.|https://doi.org/10.1109/taslpro.2025.3533375|
|232|APEER: Automatic Prompt Engineering Enhances Large Language Model   Reranking|Can Jin, Hongwu Peng, Shiyu Zhao, Zhenting Wang, Wujiang Xu, Ligong Han, Jiahui Zhao, Kai Zhong, Sanguthevar Rajasekaran...|2025-01-01|arXiv|https://github.com/jincan333/APEER.|https://doi.org/10.48550/arXiv.2406.14449|
|233|LLM Reading Tea Leaves: Automatically Evaluating Topic Models with Large Language Models|Xiaohao Yang, He Zhao, Dinh Q. Phung, Wray L. Buntine, Lan Du|2025-01-01|Transactions of the Association for Computational Linguistics|https://github.com/Xiaohao-Yang/Topic_Model_Evaluation.|https://doi.org/10.48550/arXiv.2406.09008|
|234|ConceptViz: A Visual Analytics Approach for Exploring Concepts in Large Language Models|Haoxuan Li, Zhen Wen, Qiqi Jiang, Chenxiao Li, Yuwei Wu, Yuchen Yang, Yiyao Wang, Xiuqi Huang, Minfeng Zhu, Wei Chen|2025-01-01|arXiv|https://github.com/Happy-Hippo209/ConceptViz.|https://doi.org/10.48550/arXiv.2509.20376|
|235|DesignQA: A Multimodal Benchmark for Evaluating Large Language Models&apos; Understanding of Engineering Do cumentation|Anna C. Doris, Daniele Grandi, Ryan Tomich, Md Ferdous Alam, Mohammadmehdi Ataei, Hyunmin Cheong, Faez Ahmed|2025-01-01|Journal of Computing and Information Science in Engineering|https://github.com/anniedoris/design_qa|https://doi.org/10.48550/arXiv.2404.07917|
|236|FreqLLM: Frequency-Aware Large Language Models for Time Series Forecasting|Shunnan Wang, Min Gao, Zongwei Wang, Yibing Bai, Feng Jiang, Guansong Pang|2025-01-01|OpenAlex|https://github.com/biya0105/FreqLLM.|https://doi.org/10.24963/ijcai.2025/377|
|237|Disentangling Memory and Reasoning Ability in Large Language Models|Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang|2025-01-01|OpenAlex|https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning.|https://doi.org/10.18653/v1/2025.acl-long.84|
|238|LLM Ethics Benchmark: A Three-Dimensional Assessment System for Evaluating Moral Reasoning in Large Language Models|Junfeng Jiao, Saleh Afroogh, Arvind R. Murali, Kevin J. Chen, David Atkinson, Amit Dhurandhar|2025-01-01|Scientific Reports|https://github.com/The-Responsible-AI-Initiative/LLM_Ethics_Benchmark.git|https://doi.org/10.1038/s41598-025-18489-7|
|239|Knowledge-Driven Feature Selection and Engineering for Genotype Data with Large Language Models|Joseph Lee, Shuhua Yang, Jae Young Baik, Xiaoxi Liu, Zhen Tan, Dawei Li, Zixuan Wen, Bojian Hou, Duy Duong‚ÄêTran, Tianlon...|2025-01-01|arXiv (Cornell University)|https://github.com/PennShenLab/FREEFORM.|http://arxiv.org/abs/2410.01795|
|240|Improving Efficiency of Answer Set Planning with Rough Solutions from Large Language Models for Robotic Task Planning|Xinrui Lin, Yangfan Wu, Huanyu Yang, Yuting Huang, Yu Zhang, Jianmin Ji, Yanyong Zhang|2025-01-01|OpenAlex|https://github.com/CLMASP/CLMASP.|https://doi.org/10.24963/ijcai.2025/509|
|241|Hyperbolic Large Language Models|Sarang Patil, Zeyong Zhang, Yiran Huang, Tengfei Ma, Mengjia Xu|2025-01-01|arXiv|https://github.com/sarangp2402/Hyperbolic-LLM-Models|https://doi.org/10.48550/arXiv.2509.05757|
|242|How Can Recommender Systems Benefit from Large Language Models: A Survey|Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Hao Zhang, Yong Liu, Chuhan Wu, Xiangyang Li, Chenxu Zhu, Huife...|2025-01-01|ACM transactions on office information systems|https://github.com/CHIANGEL/Awesome-LLM-for-RecSys|https://doi.org/10.48550/arXiv.2306.05817|
|243|Harnessing Multi-modal Large Language Models for Measuring and Interpreting Color Differences|Zhihua Wang, Long Yu, Qiuping Jiang, Chao Huang, Xiaochun Cao|2025-01-01|IEEE Transactions on Image Processing|https://github.com/LongYu-LY/CD-Reasoning.|https://doi.org/10.1109/tip.2024.3522802|
|244|GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest|Shilong Zhang, Peize Sun, Shoufa Chen, Min Xiao, Wenqi Shao, Wenwei Zhang, Yu Liu, Kai Chen, Ping Luo|2025-01-01|Lecture notes in computer science|https://github.com/jshilong/GPT4RoI.|https://doi.org/10.1007/978-3-031-91813-1_4|
|245|From continuous pre-training to alignment: A comprehensive toolkit for large language models in federated learning|Zhuo Zhang, Yukun Zhang, Guanzhong Chen, Lizhen Qu, Xun Zhou, Hui Wang, Zenglin Xu|2025-01-01|Neurocomputing|https://github.com/iezhuozhuo/f4llm.|https://doi.org/10.1016/j.neucom.2025.130572|
|246|ARB-LLM: Alternating Refined Binarizations for Large Language Models|Zhiteng Li, Xianglong Yan, Tianao Zhang, Haotong Qin, Dong Xie, Jiang Tian, Zhongchao Shi, Linghe Kong, Yulun Zhang, Xia...|2025-01-01|ICLR|https://github.com/ZHITENGLI/ARB-LLM.|https://openreview.net/forum?id=ZU8OdDLTts|
|247|Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models|Yuanchen Zhou, Shuo Jiang, Jie Zhu, Junhui Li, Lifan Guo, Feng Chen, Chi Zhang|2025-01-01|arXiv|https://github.com/aliyun/qwen-dianjin.|https://doi.org/10.48550/arXiv.2508.15202|
|248|Exploring Concept Depth: How Large Language Models Acquire Knowledge and Concept at Different Layers?|Mingyu Jin, Qinkai Yu, Jingyuan Huang, Qingcheng Zeng, Zhenting Wang, Wenyue Hua, Haiyan Zhao, Kai Mei, Yanda Meng, Kaiz...|2025-01-01|COLING|https://github.com/Luckfort/CD|https://aclanthology.org/2025.coling-main.37/|
|249|Evaluating the Prompt Steerability of Large Language Models|Erik Miehling, Michael Desmond, Karthikeyan Natesan Ramamurthy, Elizabeth Daly, Kush R. Varshney, Eitan Farchi, Pierre D...|2025-01-01|OpenAlex|https://github.com/IBM/prompt-steering.|https://doi.org/10.18653/v1/2025.naacl-long.400|
|250|Evaluating and Mitigating Linguistic Discrimination in Large Language Models: Perspectives on Safety Equity and Knowledge Equity|Guoliang Dong, Haoyu Wang, Jun Sun, Xinyu Wang|2025-01-01|OpenAlex|https://github.com/dgl-prc/ldfighter|https://doi.org/10.24963/ijcai.2025/40|
|251|Enhancing Large Language Models for Hardware Verification: A Novel SystemVerilog Assertion Dataset|Anand Menon, Samit S. Miftah, Shamik Kundu, Souvik Kundu, Amisha Srivastava, Arnab Raha, Gabriel Theodor Sonnenschein, S...|2025-01-01|ACM Transactions on Design Automation of Electronic Systems|https://github.com/AnandMenon12/VERT.|https://doi.org/10.48550/arXiv.2503.08923|
|252|Enhancing Herbal Medicine-Drug Interaction Prediction Using Large Language Models|Sisi Yuan, Zhecheng Zhou, Xinyuan Jin, Linlin Zhuo, Keqin Li|2025-01-01|IEEE Journal of Biomedical and Health Informatics|https://github.com/sisyyuan/HDI.|https://doi.org/10.1109/JBHI.2025.3558667|
|253|Dual Adapter Tuning of Vision-Language Models Using Large Language Models|Mohammad Reza Zarei, Abbas Akkasi, Majid Komeili|2025-01-01|International Journal of Computational Intelligence Systems|https://github.com/mrzarei5/DATViL.|https://doi.org/10.1007/s44196-025-00853-0|
|254|Do Large Language Model Benchmarks Test Reliability?|Joshua Vendrow, Edward Vendrow, Sara Beery, Aleksander Madry|2025-01-01|arXiv|https://github.com/MadryLab/platinum-benchmarks|https://doi.org/10.48550/arXiv.2502.03461|
|255|MentalQLM: A lightweight large language model for mental healthcare based on instruction tuning and dual LoRA modules|Jiayu Shi, Zexiao Wang, Jiandong Zhou, Chengyu Liu, Poly Z. H. Sun, Erying Zhao, Lei L√º|2024-12-30|IEEE Journal of Biomedical and Health Informatics|https://github.com/tortorish/MentalQLM.|https://doi.org/10.1101/2024.12.29.24319755|
|256|Task Preference Optimization: Improving Multimodal Large Language Models   with Vision Task Alignment|Ziang Yan, Zhilin Li, Yinan He, Chenting Wang, Kunchang Li, Xinhao Li, Xiangyu Zeng, Zhong Lin Wang, Yali Wang, Yu Qiao,...|2024-12-26|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/OpenGVLab/TPO|https://openaccess.thecvf.com/content/CVPR2025/html/Yan_Task_Preference_Optimization_Improving_Multimodal_Large_Language_Models_with_Vision_CVPR_2025_paper.html|
|257|MLLM-SUL: Multimodal Large Language Model for Semantic Scene   Understanding and Localization in Traffic Scenarios|Jiaqi Fan, Jianhua Wu, Jincheng Gao, Jianhao Yu, Yafei Wang, Hongqing Chu, Bingzhao Gao|2024-12-26|arXiv (Cornell University)|https://github.com/fjq-tongji/MLLM-SUL.|http://arxiv.org/abs/2412.19406|
|258|Survey and Improvement Strategies for Gene Prioritization with Large Language Models|Matthew B. Neeley, Guantong Qi, Guanchao Wang, Ruixiang Tang, Dongxue Mao, Chaozhong Liu, Sasidhar Pasupuleti, Bo Yuan, ...|2024-12-26|Bioinformatics Advances|https://github.com/LiuzLab/GPT-Diagnosis.|https://doi.org/10.48550/arXiv.2501.18794|
|259|A Survey on Large Language Model Acceleration based on KV Cache   Management|Haoyang Li, Yiming Li, Anxin Tian, Tianhao Tang, Zhanchao Xu, Xuejia Chen, Nicole Hu, Wei Dong, Qing Li, Lei Chen|2024-12-26|Trans. Mach. Learn. Res.|https://github.com/TreeAI-Lab/Awesome-KV-Cache-Management|https://openreview.net/forum?id=z3JZzu9EA3|
|260|An Engorgio Prompt Makes Large Language Model Babble on|Jianshuo Dong, Ziyuan Zhang, Qingjie Zhang, Hanxun Qiu, Tianwei Zhang, Hao Wang, Hewu Li, Qi Li, Chao Zhang, Ke Xu|2024-12-26|ICLR|https://github.com/jianshuod/Engorgio-prompt.|https://openreview.net/forum?id=m4eXBo0VNc|
|261|Investigating Large Language Models for Code Vulnerability Detection: An   Experimental Study|Xuefeng Jiang, L. H. Wu, Sheng Sun, Jia Li, Jingjing Xue, Yuwei Wang, Tingting Wu, Min Liu|2024-12-24|arXiv (Cornell University)|https://github.com/SakiRinn/LLM4CVD|http://arxiv.org/abs/2412.18260|
|262|3DGraphLLM: Combining Semantic Graphs and Large Language Models for 3D   Scene Understanding|Tatiana Zemskova, Dmitry Yudin|2024-12-24|arXiv (Cornell University)|https://github.com/CognitiveAISystems/3DGraphLLM.|http://arxiv.org/abs/2412.18450|
|263|ICM-Assistant: Instruction-tuning Multimodal Large Language Models for   Rule-based Explainable Image Content Moderation|Mengyang Wu, Yuzhi Zhao, Jialun Cao, Mingjie Xu, Zhongming Jiang, Xuehui Wang, Qinbin Li, Guangneng Hu, Shengchao Qin, C...|2024-12-24|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/zhaoyuzhi/ICM-Assistant.|https://doi.org/10.1609/aaai.v39i8.32908|
|264|Large Language Model Safety: A Holistic Survey|Dan Shi, Tianhao Shen, Yufei Huang, Zhigen Li, Yongqi Leng, Renren Jin, Chuang Liu, Xinwei Wu, Zishan Guo, Linhao Yu, Li...|2024-12-23|arXiv (Cornell University)|https://github.com/tjunlp-lab/Awesome-LLM-Safety-Papers.|http://arxiv.org/abs/2412.17686|
|265|Property Enhanced Instruction Tuning for Multi-task Molecule Generation   with Large Language Models|Xuan Lin, Long Chen, Yile Wang, Xiangxiang Zeng, Philip S. Yu|2024-12-23|arXiv (Cornell University)|https://github.com/chenlong164/PEIT.|http://arxiv.org/abs/2412.18084|
|266|Large Language Model Can Be a Foundation for Hidden Rationale-Based   Retrieval|Luo Ji, Fulai Guo, Teng Chen, Qing Gu, Xiaoyu Wang, Ningyuan Xi, Yihong Wang, Peng Yu, Yue Zhao, Hongyang Lei, Zhonglin ...|2024-12-21|Lecture notes in computer science|https://github.com/flyfree5/LaHoRe.|https://doi.org/10.1007/978-3-031-88714-7_27|
|267|Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models   into Assembly Code Obfuscation|Seyedreza Mohseni, Seyedali Mohammadi, Deepa Tilwani, Yash Saxena, Gerald Ketu Ndawula, Sriram Vema, Edward Raff, Manas ...|2024-12-20|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/mohammadi-ali/MetamorphASM.|https://doi.org/10.1609/aaai.v39i23.34672|
|268|PruneVid: Visual Token Pruning for Efficient Video Large Language Models|Xiaohu Huang, Hao Zhou, K. L. Han|2024-12-20|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/Visual-AI/PruneVid.|https://doi.org/10.18653/v1/2025.findings-acl.1024|
|269|Unveiling Uncertainty: A Deep Dive into Calibration and Performance of   Multimodal Large Language Models|Zijun Chen, Wenbo Hu, Guande He, Zhijie Deng, Zheng Zhang, Richang Hong|2024-12-19|COLING|https://github.com/hfutml/Calibration-MLLM|https://aclanthology.org/2025.coling-main.208/|
|270|Mitigating Social Bias in Large Language Models: A Multi-Objective   Approach within a Multi-Agent Framework|Zhenjie Xu, Wenqing Chen, Yi Tang, Xuanying Li, Cheng Hu, Zhixuan Chu, Kui Ren, Zibin Zheng, Zhichao Lu|2024-12-19|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/Cortantse/MOMA.|https://doi.org/10.1609/aaai.v39i24.34748|
|271|Sliding Windows Are Not the End: Exploring Full Ranking with   Long-Context Large Language Models|Wenhan Liu, Xinyu Ma, Yutao Zhu, Ziliang Zhao, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou|2024-12-19|OpenAlex|https://github.com/8421BCD/fullrank|https://doi.org/10.18653/v1/2025.acl-long.8|
|272|InstructSeg: Unifying Instructed Visual Segmentation with Multi-modal   Large Language Models|Cong Wei, Yujie Zhong, Haoxian Tan, Yingsen Zeng, Yong Liu, Zheng Zhao, Yujiu Yang|2024-12-18|arXiv (Cornell University)|https://github.com/congvvc/InstructSeg.|http://arxiv.org/abs/2412.14006|
|273|ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain   Adaptation with an Astronomy Case Study|Eric Modesitt, Ke Yang, Spencer Hulsey, Xin Liu, ChengXiang Zhai, Volodymyr V. Kindratenko|2024-12-18|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/ModeEric/ORBIT-Llama|https://doi.org/10.18653/v1/2025.findings-acl.51|
|274|ResQ: Mixed-Precision Quantization of Large Language Models with   Low-Rank Residuals|Utkarsh Saxena, Sayeh Sharify, Kaushik Roy, Xin Wang|2024-12-18|arXiv (Cornell University)|https://github.com/utkarsh-dmx/project-resq.|http://arxiv.org/abs/2412.14363|
|275|DateLogicQA: Benchmarking Temporal Biases in Large Language Models|Gagan Bhatia, MingZe Tang, Cristina Mahanta, Madiha Kazi|2024-12-17|OpenAlex|https://github.com/gagan3012/EAIS-Temporal-Bias|https://doi.org/10.18653/v1/2025.naacl-srw.32|
|276|RetroLLM: Empowering Large Language Models to Retrieve Fine-grained   Evidence within Generation|Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yongkang Wu, Zhonghua Li, Qi Ye, Zhicheng Dou|2024-12-16|OpenAlex|https://github.com/sunnynexus/RetroLLM|https://doi.org/10.18653/v1/2025.acl-long.819|
|277|SPaR: Self-Play with Tree-Search Refinement to Improve   Instruction-Following in Large Language Models|Jiale Cheng, Xiao Liu, Cunxiang Wang, Xiaotao Gu, Yida Lu, Dan Zhang, Yuxiao Dong, Jie Tang, Hongning Wang, Minlie Huang|2024-12-16|ICLR|https://github.com/thu-coai/SPaR.|https://openreview.net/forum?id=9chRqsPOGL|
|278|NLSR: Neuron-Level Safety Realignment of Large Language Models Against   Harmful Fine-Tuning|Xin Yi, Shunfan Zheng, Linlin Wang, Gerard de Melo, Xiaoling Wang, Liang He|2024-12-16|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/xinykou/NLSR|https://doi.org/10.1609/aaai.v39i24.34762|
|279|Can Large Language Models Understand You Better? An MBTI Personality   Detection Dataset Aligned with Population Traits|Bohan Li, J Guan, Longxu Dou, Yun‚ÄêLong Feng, Dingzirui Wang, Yang Xu, Enbo Wang, Qiguang Chen, Bichen Wang, Xiao Xu, Yim...|2024-12-16|COLING|https://github.com/Personality-NLP/MbtiBench.|https://aclanthology.org/2025.coling-main.339/|
|280|BlenderLLM: Training Large Language Models for Computer-Aided Design   with Self-improvement|Yinwei Du, Shunian Chen, Wenbo Zan, Peizhao Li, Mingxuan Wang, Dongwoon Song, Bo Li, Yan Hu, Benyou Wang|2024-12-16|arXiv (Cornell University)|https://github.com/FreedomIntelligence/BlenderLLM|http://arxiv.org/abs/2412.14203|
|281|Assessing the Limitations of Large Language Models in Clinical Fact   Decomposition|Monica Munnangi, Akshay Swaminathan, Jason Fries, Jenelle Jindal, Sanjana Narayanan, Iv√°n L√≥pez, Lucia Tu, Philip Chung,...|2024-12-16|arXiv (Cornell University)|https://github.com/som-shahlab/factehr|http://arxiv.org/abs/2412.12422|
|282|A survey on LoRA of large language models|Yuren Mao, Yuhang Ge, Yijiang Fan, Wenyi Xu, Yu Mi, Zhonghao Hu, Yunjun Gao|2024-12-14|Frontiers of Computer Science|https://github.com/ZJU-LLMs/Awesome-LoRAs.git|https://doi.org/10.1007/s11704-024-40663-9|
|283|B-VLLM: A Vision Large Language Model with Balanced Spatio-Temporal   Tokens|Zhuqiang Lu, Zhenfei Yin, Meilin He, Zhihui Wang, Zicheng Liu, Zhiyong Wang, Kun Hu|2024-12-13|arXiv (Cornell University)|https://github.com/zhuqiangLu/B-VLLM.|http://arxiv.org/abs/2412.09919|
|284|Enhancing Multimodal Large Language Models Complex Reason via Similarity   Computation|Xiaofeng Zhang, Fanshuo Zeng, Yihao Quan, Zheng Hui, Jiawei Yao|2024-12-12|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/FanshuoZeng/Simignore|https://doi.org/10.1609/aaai.v39i10.33107|
|285|Filter-then-Generate: Large Language Models with Structure-Text Adapter   for Knowledge Graph Completion|Ben Liu, Jihai Zhang, Fangquan Lin, Cheng Yang, Min Peng|2024-12-12|COLING|https://github.com/LB0828/FtG|https://aclanthology.org/2025.coling-main.740/|
|286|Simulate Scientific Reasoning with Multiple Large Language Models: An Application to Alzheimer‚Äôs Disease Combinatorial Therapy|Qidi Xu, Xiaozhong Liu, Xiaoqian Jiang, Yejin Kim|2024-12-12|medRxiv (Cold Spring Harbor Laboratory)|https://github.com/QidiXu96/Coated-LLM|https://doi.org/10.1101/2024.12.10.24318800|
|287|Towards a Multimodal Large Language Model with Pixel-Level Insight for   Biomedicine|Xiaoshuang Huang, Lingdong Shen, Jia Liu, Fangxin Shang, Hongxiang Li, Haifeng Huang, Yehui Yang|2024-12-12|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/ShawnHuang497/MedPLIB.|https://doi.org/10.1609/aaai.v39i4.32394|
|288|Exploiting the Index Gradients for Optimization-Based Jailbreaking on   Large Language Models|Jiahui Li, Yongchang Hao, Hanqiu Xu, Xing Wang, Yu Hong|2024-12-11|COLING|https://github.com/jiah-li/magic.|https://aclanthology.org/2025.coling-main.305/|
|289|Concept Bottleneck Large Language Models|Chung-En Sun, Tuomas P. Oikarinen, Berk Ustun, Tsui-Wei Weng|2024-12-10|ICLR|https://github.com/Trustworthy-ML-Lab/CB-LLMs.|https://openreview.net/forum?id=RC5FPYVQaH|
|290|IntellectSeeker: A Personalized Literature Management System with the   Probabilistic Model and Large Language Model|Weizhen Bian, Siyan Liu, Yubo Zhou, Dezhi Chen, Yijie Liao, Zhenzhen Fan, Aobo Wang|2024-12-10|Lecture notes in computer science|https://github.com/LuckyBian/ISY5001|https://doi.org/10.1007/978-981-97-5489-2_24|
|291|PediaBench: A Comprehensive Chinese Pediatric Dataset for Benchmarking   Large Language Models|Qian Zhang, Panfeng Chen, Jiali Li, Shuo Feng, Shuyu Liu, Mei Chen, Hui Li, Yanhao Wang|2024-12-09|arXiv (Cornell University)|https://github.com/ACMISLab/PediaBench.|http://arxiv.org/abs/2412.06287|
|292|KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models|Fan Wang, Jing-Jiang Jiang, C.Y. Park, Sunghun Kim, Jing Tang|2024-12-08|ICLR|https://github.com/juyongjiang/KaSA.|https://openreview.net/forum?id=OQqNieeivq|
|293|Mitigating Entity-Level Hallucination in Large Language Models|Weihang Su, Yichen Tang, Qingyao Ai, Changyue Wang, Zhijing Wu, Yiqun Liu|2024-12-08|OpenAlex|https://github.com/oneal2000/EntityHallucination.|https://doi.org/10.48550/arXiv.2407.09417|
|294|Fine-Grained Behavior Simulation with Role-Playing Large Language Model   on Social Media|Kun Li, C. H. Dai, Zhou We, Songlin Hu|2024-12-04|arXiv (Cornell University)|https://github.com/linkseed18612254945/FineRob|http://arxiv.org/abs/2412.03148|
|295|From Individual to Society: A Survey on Social Simulation Driven by   Large Language Model-based Agents|Xinyi Mou, Xuanwen Ding, Qi He, Liang Wang, Jingcong Liang, Xinnong Zhang, Libo Sun, Jiayu Lin, Jie Zhou, Xuanjing Huang...|2024-12-04|arXiv (Cornell University)|https://github.com/FudanDISC/SocialAgent|http://arxiv.org/abs/2412.03563|
|296|Improving Linguistic Diversity of Large Language Models with Possibility   Exploration Fine-Tuning|Long Mai, Julie Carson-Berndsen|2024-12-04|arXiv (Cornell University)|https://github.com/mailong25/peft_diversity|http://arxiv.org/abs/2412.03343|
|297|NJGPT: A Large Language Model-Driven, User-Friendly Solution for Phylogenetic Tree Construction|Zhixuan Wang, Haoyuan Huang, Teng Li, Allen G. Rodrigo|2024-12-04|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/ZWan622/NJGPT1.0.git|https://doi.org/10.1101/2024.12.02.626464|
|298|Beyond Labels: Aligning Large Language Models with Human-Like Reasoning|Muhammad Rafsan Kabir, Rafeed Mohammad Sultan, Ihsanul Haque Asif, Jason M. E. Ahad, Fuad Rahman, Mohammad Ruhul Amin, N...|2024-12-02|Lecture notes in computer science|https://github.com/apurba-nsu-rnd-lab/DFAR.|https://doi.org/10.1007/978-3-031-78172-8_16|
|299|Improving Automated Deep Phenotyping Through Large Language Models Using Retrieval Augmented Generation|Brandon T. Garcia, Lauren Westerfield, Priya Yelemali, Nikhita Gogate, Edgar A. Rivera‚ÄêMu√±oz, Haowei Du, Moez Dawood, An...|2024-12-02|medRxiv (Cold Spring Harbor Laboratory)|https://github.com/PoseyPod/RAG-HPO|https://doi.org/10.1101/2024.12.01.24318253|
|300|Dynamic-LLaVA: Efficient Multimodal Large Language Models via Dynamic   Vision-language Context Sparsification|Wenxuan Huang, Zijie Zhai, Yunhang Shen, Shaosheng Cao, Fei Zhao, Xiangfeng Xu, Zheyu Ye, Shaohui Lin|2024-12-01|arXiv|https://github.com/Osilly/dynamic_llava|https://openreview.net/forum?id=hzVpZDrW73|
|301|Woodpecker: hallucination correction for multimodal large language models|Shukang Yin, Chaoyou Fu, Sirui Zhao, Tong Bill Xu, Hao Wang, Dianbo Sui, Yunhang Shen, Ke Li, Xing Sun, Enhong Chen|2024-12-01|Science China Information Sciences|https://github.com/BradyFU/Woodpecker.|https://doi.org/10.1007/s11432-024-4251-x|
|302|Accelerating Multimodal Large Language Models via Dynamic Visual-Token   Exit and the Empirical Findings|Qiong Wu, Wei Lin, Weihao Ye, Yiyi Zhou, Xiaoshuai Sun, Rongrong Ji|2024-11-29|arXiv (Cornell University)|https://github.com/DoubtedSteam/DyVTE.|http://arxiv.org/abs/2411.19628|
|303|CovidLLM: A Robust Large Language Model with Missing Value Adaptation   and Multi-Objective Learning Strategy for Predicting Disease Severity and   Clinical Outcomes in COVID-19 Pa..|Shengjun Zhu, Siyu Liu, Yang Li, Qing Lei, Hongyan Hou, He‚Äêwei Jiang, Shujuan Guo, Feng Wang, Rongshang Chen, Xionglin F...|2024-11-28|Current Proteomics|https://github.com/sysll/CovidLLM|https://doi.org/10.2174/0115701646366019250304064012|
|304|AdaShield: Safeguarding Multimodal Large Language Models from   Structure-based Attack via Adaptive Shield Prompting|Yu Wang, Xiaogeng Liu, Yu Li, Muhao Chen, Chaowei Xiao|2024-11-26|Lecture notes in computer science|https://github.com/rain305f/AdaShield.|https://doi.org/10.1007/978-3-031-72661-3_5|
|305|Leveraging Large Language Models and Topic Modeling for Toxicity   Classification|Haniyeh Ehsani Oskouie, Christina Chance, Claire Huang, Margaret Capetz, Elizabeth Eyeson, Majid Sarrafzadeh|2024-11-26|2016 International Conference on Computing, Networking and Communications (ICNC)|https://github.com/aheldis/Toxicity-Classification.git.|https://doi.org/10.1109/ICNC64010.2025.10994061|
|306|VaxLLM: Leveraging Fine-tuned Large Language Model for automated annotation of Brucella Vaccines|Xingxian Li, Yuping Zheng, Jie Hu, Jie Zheng, Zhigang Wang, Yongqun He|2024-11-26|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/xingxianli/VaxLLM|https://doi.org/10.1101/2024.11.25.625209|
|307|CS-Eval: A Comprehensive Large Language Model Benchmark for   CyberSecurity|Zhengmin Yu, Jiutian Zeng, Siyi Chen, Wenhan Xu, Dandan Xu, Xiangyu Liu, Zonghao Ying, Nan Wang, Yuan Zhang, Min Yang|2024-11-25|arXiv (Cornell University)|https://github.com/CS-EVAL/CS-Eval.|http://arxiv.org/abs/2411.16239|
|308|"Moralized" Multi-Step Jailbreak Prompts: Black-Box Testing of   Guardrails in Large Language Models for Verbal Attacks|Libo Wang|2024-11-23|arXiv (Cornell University)|https://github.com/brucewang123456789/GeniusTrail.git.|http://arxiv.org/abs/2411.16730|
|309|Large Language Model with Region-guided Referring and Grounding for CT   Report Generation|Zhixuan Chen, Yequan Bie, Huanying Jin, Hao Chen|2024-11-23|IEEE Transactions on Medical Imaging|https://github.com/zhi-xuan-chen/Reg2RG.|https://doi.org/10.1109/TMI.2025.3559923|
|310|DRPruning: Efficient Large Language Model Pruning through   Distributionally Robust Optimization|Hexuan Deng, Wenxiang Jiao, Xuebo Liu, Jing Li, Min Zhang, Zhaopeng Tu|2024-11-21|OpenAlex|https://github.com/hexuandeng/DRPruning.|https://doi.org/10.18653/v1/2025.acl-long.1414|
|311|SemiKong: Curating, Training, and Evaluating A Semiconductor   Industry-Specific Large Language Model|Christopher Nguyen, William Nguyen, Atsushi Suzuki, Daisuke Oku, Hong An Phan, Dinh Viet Sang, Zooey Nguyen, Ha Cam Anh,...|2024-11-20|arXiv (Cornell University)|https://github.com/aitomatic/semikong|http://arxiv.org/abs/2411.13802|
|312|On the Consistency of Video Large Language Models in Temporal   Comprehension|Minjoon Jung, Junbin Xiao, Byoung‚ÄêTak Zhang, Angela Yao|2024-11-19|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/minjoong507/Consistency-of-Video-LLM.|https://openaccess.thecvf.com/content/CVPR2025/html/Jung_On_the_Consistency_of_Video_Large_Language_Models_in_Temporal_CVPR_2025_paper.html|
|313|FLAME: Frozen Large Language Models Enable Data-Efficient Language-Image   Pre-training|Anjia Cao, Xing Wei, Zhiheng Ma|2024-11-18|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/MIV-XJTU/FLAME|https://openaccess.thecvf.com/content/CVPR2025/html/Cao_FLAME_Frozen_Large_Language_Models_Enable_Data-Efficient_Language-Image_Pre-training_CVPR_2025_paper.html|
|314|BianCang: A Traditional Chinese Medicine Large Language Model|Sibo Wei, Xueping Peng, Yifei Wang, Jiasheng Si, Weiyu Zhang, Wenpeng L√º, Xiaoming Wu, Yinglong Wang|2024-11-17|arXiv (Cornell University)|https://github.com/QLU-NLP/BianCang.|http://arxiv.org/abs/2411.11027|
|315|Multilingual Large Language Models: A Systematic Survey|Shaolin Zhu, Supryadi, Shaoyang Xu, Haoran Sun, Leiyu Pan, Menglong Cui, Jiangcun Du, Renren Jin, Ant√≥nio Branco, Deyi X...|2024-11-17|arXiv (Cornell University)|https://github.com/tjunlp-lab/Awesome-Multilingual-LLMs-Papers.|http://arxiv.org/abs/2411.11072|
|316|TS-LLaVA: Constructing Visual Tokens through Thumbnail-and-Sampling for   Training-Free Video Large Language Models|Tingyu Qu, Mingxiao Li, Tinne Tuytelaars, Marie‚ÄêFrancine Moens|2024-11-17|arXiv (Cornell University)|https://github.com/tingyu215/TS-LLaVA.|http://arxiv.org/abs/2411.11066|
|317|Evaluating Creativity and Deception in Large Language Models: A   Simulation Framework for Multi-Agent Balderdash|Parsa Hejabi, Elnaz Rahmati, Alireza S. Ziabari, Preni Golazizian, Jesse Thomason, Morteza Dehghani|2024-11-15|arXiv (Cornell University)|https://github.com/ParsaHejabi/Simulation-Framework-for-Multi-Agent-Balderdash|http://arxiv.org/abs/2411.10422|
|318|Orca: Enhancing Role-Playing Abilities of Large Language Models by   Integrating Personality Traits|Yu-Chih Huang|2024-11-15|arXiv (Cornell University)|https://github.com/Aipura/Orca.|http://arxiv.org/abs/2411.10006|
|319|LHRS-Bot-Nova: Improved Multimodal Large Language Model for Remote   Sensing Vision-Language Interpretation|Zhenshi Li, Dilxat Muhtar, Feng Gu, Yibei He, Xueliang Zhang, Pengfeng Xiao, Guangjun He, Xiao Xiang Zhu|2024-11-14|ISPRS Journal of Photogrammetry and Remote Sensing|https://github.com/NJU-LHRS/LHRS-Bot.|https://doi.org/10.1016/j.isprsjprs.2025.06.003|
|320|DROJ: A Prompt-Driven Attack against Large Language Models|Longfei Hu, B. Wang|2024-11-13|arXiv (Cornell University)|https://github.com/Leon-Leyang/LLM-Safeguard.|http://arxiv.org/abs/2411.09125|
|321|Verbosity $\neq$ Veracity: Demystify Verbosity Compensation Behavior of   Large Language Models|Yusen Zhang, Sarkar Snigdha Sarathi Das, Rui Zhang|2024-11-12|arXiv (Cornell University)|https://github.com/psunlpgroup/VerbosityLLM.|http://arxiv.org/abs/2411.07858|
|322|Benchmarking Large Language Models for NL-to-SQL: A Comprehensive Evaluation of Accuracy, Cost and Throughput|Adithya Narasimhan, Amit Kumar Bhamboo, Abiram Devnathan, Jeyaraj Vellaisamy, Vineeth Vijayaraghavan|2024-11-10|OpenAlex|https://github.com/petavue/NL2SQL-Benchmark.|https://doi.org/10.36227/techrxiv.173121325.56335825/v1|
|323|Golden Touchstone: A Comprehensive Bilingual Benchmark for Evaluating   Financial Large Language Models|Xiaojun Wu, Junxi Liu, Hong Su, Zhouchi Lin, Yiyan Qi, Chengjin Xu, Jiajun Su, Jiajie Zhong, Fuwei Wang, Saizhuo Wang, F...|2024-11-09|arXiv (Cornell University)|https://github.com/IDEA-FinAI/Golden-Touchstone|http://arxiv.org/abs/2411.06272|
|324|TourSynbio-Search: A Large Language Model Driven Agent Framework for   Unified Search Method for Protein Engineering|Yungeng Liu, Zan Chen, Yu Guang Wang, Yiqing Shen|2024-11-08|2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)|https://github.com/tsynbio/Toursynbio-Search|https://doi.org/10.1109/bibm62325.2024.10822318|
|325|AutoProteinEngine: A Large Language Model Driven Agent Framework for   Multimodal AutoML in Protein Engineering|Yungeng Liu, Zan Chen, Yuguang Wang, Yiqing Shen|2024-11-07|COLING|https://github.com/tsynbio/AutoPE.|https://aclanthology.org/2025.coling-industry.36/|
|326|QUILL: Quotation Generation Enhancement of Large Language Models|Jin Xiao, Bowei Zhang, Qianyu He, Jiaqing Liang, Wei Feng, Jinglei Chen, Zujie Liang, Deqing Yang, Yanghua Xiao|2024-11-06|arXiv (Cornell University)|https://github.com/GraceXiaoo/QUILL.|http://arxiv.org/abs/2411.03675|
|327|Measuring short-form factuality in large language models|Jason Lee, Nguyen Karina, Hyung Won Chung, Yunxin Joy Jiao, Spencer Papay, Amelia Glaese, John Schulman, William Fedus|2024-11-06|arXiv (Cornell University)|https://github.com/openai/simple-evals.|http://arxiv.org/abs/2411.04368|
|328|Evaluating Large Language Models: A Comprehensive Survey|Zishan Guo, Renren Jin, Chuang Liu, Yufei Huang, Dan Shi, Supryadi, Linhao Yu, Yan Liu, Jiaxuan Li, Bojian Xiong, Deyi X...|2024-11-05|International Journal of Latest Engineering and Management Research (IJLEMR)|https://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers.|https://doi.org/10.56581/ijlemr.9.10.05-16|
|329|FlexCAD: Unified and Versatile Controllable CAD Generation with   Fine-tuned Large Language Models|Zhanwei Zhang, Shizhao Sun, Wenxiao Wang, Deng Cai, Jiang Bian|2024-11-05|ICLR|https://github.com/microsoft/CADGeneration|https://openreview.net/forum?id=Z0eiiV3Yyh|
|330|Leveraging Large Language Models in Code Question Answering: Baselines   and Issues|Georgy Andryushchenko, Vladimir Ivanov, Vladimir Makharev, Elizaveta Tukhtina, Aidar Valeev|2024-11-05|Communications in computer and information science|https://github.com/IU-AES-AI4Code/CodeQuestionAnswering.|https://doi.org/10.1007/978-3-031-97019-1_1|
|331|SMoA: Improving Multi-agent Large Language Models with Sparse   Mixture-of-Agents|Dawei Li, Zhen Tan, Peijia Qian, Yifan Li, Kumar Satvik Chaudhary, Lijie Hu, Jiayi Shen|2024-11-05|Lecture notes in computer science|https://github.com/David-Li0406/SMoA.|https://doi.org/10.1007/978-981-96-8180-8_5|
|332|DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for   Efficient Robot Execution|Yang Yue, Yulin Wang, Bingyi Kang, Yizeng Han, Shenzhi Wang, Shiji Song, Jiashi Feng, Gao Huang|2024-11-04|NeurIPS|https://github.com/yueyang130/DeeR-VLA.|http://papers.nips.cc/paper_files/paper/2024/hash/67b0e7c7c2a5780aeefe3b79caac106e-Abstract-Conference.html|
|333|SQL Injection Jailbreak: a structural disaster of large language models|Jiawei Zhao, Kejiang Chen, Weiming Zhang, Nenghai Yu|2024-11-03|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/weiyezhimeng/SQL-Injection-Jailbreak|https://doi.org/10.18653/v1/2025.findings-acl.358|
|334|Fish-Speech: Leveraging Large Language Models for Advanced Multilingual   Text-to-Speech Synthesis|Shijia Liao, Yuxuan Wang, Tianyu Li, Yifan Cheng, Ruoyi Zhang, Ran Zhou, Yun-Xuan Xing|2024-11-02|arXiv (Cornell University)|https://github.com/fishaudio/fish-speech|http://arxiv.org/abs/2411.01156|
|335|Rate, Explain and Cite (REC): Enhanced Explanation and Attribution in   Automatic Evaluation by Large Language Models|Aliyah R. Hsu, James Zhu, Zhichao Wang, Bin Bi, Shubham Mehrotra, Shiva Pentyala, Katherine Tan, Xiang-Bo Mao, Roshanak ...|2024-11-02|arXiv (Cornell University)|https://github.com/adelaidehsu/REC|http://arxiv.org/abs/2411.02448|
|336|MoD: A Distribution-Based Approach for Merging Large Language Models|Quy-Anh Dang, Chong‚ÄêWah Ngo|2024-11-01|arXiv (Cornell University)|https://github.com/knovel-eng/mod.|http://arxiv.org/abs/2411.00406|
|337|BitStack: Fine-Grained Size Control for Compressed Large Language Models   in Variable Memory Environments|Xinghao Wang, Pengyu Wang, Bo Wang, Dong Zhang, Yunhua Zhou, Xipeng Qiu|2024-10-31|arXiv (Cornell University)|https://github.com/xinghaow99/BitStack.|http://arxiv.org/abs/2410.23918|
|338|End-to-End Ontology Learning with Large Language Models|Andrea Lo, Albert Q. Jiang, Wenda Li, Mateja Jamnik|2024-10-30|NeurIPS|https://github.com/andylolu2/ollm.|http://papers.nips.cc/paper_files/paper/2024/hash/9e89f068a62f6858c661a8abecf5bb0a-Abstract-Conference.html|
|339|NewTerm: Benchmarking Real-Time New Terms for Large Language Models with   Annual Updates|Hexuan Deng, Wenxiang Jiao, Xuebo Liu, Zhang Min, Zhaopeng Tu|2024-10-28|NeurIPS|https://github.com/hexuandeng/NewTerm.|http://papers.nips.cc/paper_files/paper/2024/hash/3eec719ab86712d32b065c5977f94ad0-Abstract-Datasets_and_Benchmarks_Track.html|
|340|LLMCBench: Benchmarking Large Language Model Compression for Efficient   Deployment|Ge Yang, Changyi He, Jinyang Guo, Jianyu Wu, Yifu Ding, Aishan Liu, Haotong Qin, Pengliang Ji, Xianglong Liu|2024-10-28|NeurIPS|https://github.com/AboveParadise/LLMCBench.|http://papers.nips.cc/paper_files/paper/2024/hash/9f4cc62d0632911c63163ea3d9ec19bd-Abstract-Datasets_and_Benchmarks_Track.html|
|341|GCoder: Improving Large Language Model for Generalized Graph Problem   Solving|Qifan Zhang, Xiaobin Hong, Jianheng Tang, Nuo Chen, Yuhan Li, Wenzhong Li, Jing Tang, Jia Li|2024-10-24|arXiv (Cornell University)|https://github.com/Bklight999/WWW25-GCoder|http://arxiv.org/abs/2410.19084|
|342|Cross-model Control: Improving Multiple Large Language Models in   One-time Training|Jiayi Wu, Hao Sun, Hengyi Cai, Lixin Su, Shuaiqiang Wang, Dawei Yin, Xiang Li, Ming Gao|2024-10-23|NeurIPS|https://github.com/wujwyi/CMC.|http://papers.nips.cc/paper_files/paper/2024/hash/9856b5d30ac61ab744fdab6f67d874e4-Abstract-Conference.html|
|343|GraphTeam: Facilitating Large Language Model-based Graph Analysis via   Multi-Agent Collaboration|Xin Li, Qi Chu, Yubin Chen, Yang Liu, Yaoqi Liu, Zhi Yu, Weize Chen, Chen Qian, Chuan Shi, Cheng Yang|2024-10-23|arXiv (Cornell University)|https://github.com/BUPT-GAMMA/GraphTeam.|http://arxiv.org/abs/2410.18032|
|344|ETHIC: Evaluating Large Language Models on Long-Context Tasks with High   Information Coverage|Taewhoo Lee, Chanwoong Yoon, Kyochul Jang, Donghyeon Lee, Myung-Ha Song, Hyunjae Kim, Jaewoo Kang|2024-10-22|OpenAlex|https://github.com/dmis-lab/ETHIC.|https://doi.org/10.18653/v1/2025.naacl-long.283|
|345|DEAN: Deactivating the Coupled Neurons to Mitigate Fairness-Privacy   Conflicts in Large Language Models|Qian Chen, Dongrui Liu, Jie Zhang, Yong Liu, Jing Shao|2024-10-22|arXiv (Cornell University)|https://github.com/ChnQ/DEAN|http://arxiv.org/abs/2410.16672|
|346|Improving Causal Reasoning in Large Language Models: A Survey|Lu Yu, Delin Chen, Siheng Xiong, Qingyang Wu, Qingzhen Liu, Dawei Li, Zhikai Chen, Xiaoze Liu, Liangming Pan|2024-10-22|arXiv (Cornell University)|https://github.com/chendl02/Awesome-LLM-causal-reasoning.|http://arxiv.org/abs/2410.16676|
|347|Boosting Jailbreak Transferability for Large Language Models|Hanqing Liu, Lifeng Zhou, Huanqian Yan|2024-10-21|arXiv (Cornell University)|https://github.com/HqingLiu/SI-GCG.|http://arxiv.org/abs/2410.15645|
|348|Comprehensive benchmarking of large language models for RNA secondary   structure prediction|Luciano I Zablocki, Leandro A. Bugnon, M. G√©rard, Leandro E. Di Persia, Georgina Stegmayer, Diego H. Milone|2024-10-21|Briefings in Bioinformatics|https://github.com/sinc-lab/rna-llm-folding|https://doi.org/10.1093/bib/bbaf137|
|349|Benchmarking Large Language Models for Image Classification of Marine   Mammals|Yijiashun Qi, Shuzhang Cai, Zunduo Zhao, Jiaming Li, Yanbin Lin, Zhiqiang Wang|2024-10-21|OpenAlex|https://github.com/yeyimilk/LLM-Vision-Marine-Animals.git.|https://doi.org/10.1109/ICKG63256.2024.00040|
|350|LLaVA-KD: A Framework of Distilling Multimodal Large Language Models|Yuxuan Cai, Jiangning Zhang, Haoyang He, Xinwei He, Ao Tong, Zhenye Gan, Chengjie Wang, Xiang Bai|2024-10-21|arXiv (Cornell University)|https://github.com/Fantasyele/LLaVA-KD.|http://arxiv.org/abs/2410.16236|
|351|Advances in Citation Text Generation: Leveraging Multi-Source Seq2Seq Models and Large Language Models|Avinash Anand, Ashwin R. Nair, Kritarth Prasad, Vrinda Narayan, Naman Lal, Debanjan Mahata, Yaman Singla, Rajiv Ratn Sha...|2024-10-20|OpenAlex|https://github.com/midas-research/M-CTG|https://doi.org/10.1145/3627673.3679783|
|352|Explaining Graph Neural Networks with Large Language Models: A   Counterfactual Perspective for Molecular Property Prediction|Yinhan He, Zaiyi Zheng, Patrick Soga, Yuemin Zhu, Yushun Dong, Jundong Li|2024-10-19|arXiv (Cornell University)|https://github.com/YinhanHe123/new|http://arxiv.org/abs/2410.15165|
|353|Evaluating Deep Unlearning in Large Language Models|Ruihan Wu, Chhavi Yadav, Russ R. Salakhutdinov, Kamalika Chaudhuri|2024-10-19|arXiv (Cornell University)|https://github.com/wrh14/deep_unlearning.|http://arxiv.org/abs/2410.15153|
|354|GlitchMiner: Mining Glitch Tokens in Large Language Models via   Gradient-based Discrete Optimization|Zihui Wu, Haichang Gao, Ping Wang, Shudong Zhang, Zhaoxiang Liu, Shiguo Lian|2024-10-19|arXiv (Cornell University)|https://github.com/wooozihui/GlitchMiner.|http://arxiv.org/abs/2410.15052|
|355|CoMAL: Collaborative Multi-Agent Large Language Models for   Mixed-Autonomy Traffic|Huaiyuan Yao, Longchao Da, Vishnu Nandam, Justin Turnau, Zhiwei Liu, Linsey Pang, Hua Wei|2024-10-18|Society for Industrial and Applied Mathematics eBooks|https://github.com/Hyan-Yao/CoMAL.|https://doi.org/10.1137/1.9781611978520.43|
|356|Automatically Interpreting Millions of Features in Large Language Models|Gon√ßalo Paulo, Alex Mallen, C. H. Juang, Nora Belrose|2024-10-17|arXiv (Cornell University)|https://github.com/EleutherAI/sae-auto-interp|http://arxiv.org/abs/2410.13928|
|357|Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges   in Large Language Models|Yu Yuan, Lili Zhao, Kai Zhang, Guangting Zheng, Qi Liu|2024-10-17|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/yyhappier/ShortcutSuite.git.|https://doi.org/10.18653/v1/2024.emnlp-main.679|
|358|Towards Faithful Natural Language Explanations: A Study Using Activation   Patching in Large Language Models|Wei Jie Yeo, Ranjan Satapathy, Erik Cambria|2024-10-17|arXiv|https://github.com/wj210/Causal-Faithfulness|https://doi.org/10.48550/arXiv.2410.14155|
|359|Bridging the Language Gaps in Large Language Models with Inference-Time   Cross-Lingual Intervention|Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch|2024-10-16|OpenAlex|https://github.com/weixuan-wang123/INCLINE.|https://doi.org/10.18653/v1/2025.acl-long.270|
|360|Data Defenses Against Large Language Models|William S. Agnew, Harry H. Jiang, Cella Sum, Maarten Sap, Sauvik Das|2024-10-16|arXiv (Cornell University)|https://github.com/wagnew3/LLMDataDefenses|http://arxiv.org/abs/2410.13138|
|361|HerO at AVeriTeC: The Herd of Open Large Language Models for Verifying   Real-World Claims|Yejun Yoon, Jaeyoon Jung, Seunghyun Yoon, Kunwoo Park|2024-10-16|OpenAlex|https://github.com/ssu-humane/HerO.|https://doi.org/10.18653/v1/2024.fever-1.15|
|362|LLM4THP: a computing tool to identify tumor homing peptides by molecular and sequence representation of large language model based on two-layer ensemble model strategy|Sen Yang, Piao Xu|2024-10-15|Amino Acids|https://github.com/abcair/LLM4THP.|https://doi.org/10.1007/s00726-024-03422-5|
|363|Layer-wise Importance Matters: Less Memory for Better Performance in   Parameter-efficient Fine-tuning of Large Language Models|Kai Yao, Penglei Gao, Lichun Li, Yuan Zhao, Xiaofeng Wang, Wei Wang, Jianke Zhu|2024-10-15|OpenAlex|https://github.com/Kaiseem/IST.|https://doi.org/10.18653/v1/2024.findings-emnlp.109|
|364|Subspace Optimization for Large Language Models with Convergence   Guarantees|Yutong He, Peichao Li, Yinggang Hu, C.L. Philip Chen, Kun Yuan|2024-10-15|arXiv (Cornell University)|https://github.com/pkumelon/Golore.|http://arxiv.org/abs/2410.11289|
|365|Automatically Generating Visual Hallucination Test Cases for Multimodal   Large Language Models|Zhongye Liu, Hongbin Liu, Yuepeng Hu, Zedian Shao, Neil Zhenqiang Gong|2024-10-14|arXiv (Cornell University)|https://github.com/lycheeefish/VHExpansion.|http://arxiv.org/abs/2410.11242|
|366|Denial-of-Service Poisoning Attacks against Large Language Models|Kuofeng Gao, Tianyu Pang, Chao Du, Yong Yang, Shu-Tao Xia, Min Lin|2024-10-14|arXiv (Cornell University)|https://github.com/sail-sg/P-DoS.|http://arxiv.org/abs/2410.10760|
|367|Large Language Model Evaluation via Matrix Nuclear-Norm|Y. S. Li, Tingyu Xia, Yi Chang, Yuan Chieh Wu|2024-10-14|arXiv (Cornell University)|https://github.com/MLGroupJLU/MatrixNuclearNorm.|http://arxiv.org/abs/2410.10672|
|368|MentalGLM Series: Explainable Large Language Models for Mental Health   Analysis on Chinese Social Media|Wei Zhai, Nan Bai, Qing Zhao, Jianqiang Li, Fan Wang, Hongzhi Qi, Meng Jiang, Xiaoqin Wang, Bing Xiang Yang, Guanghui Fu|2024-10-14|arXiv (Cornell University)|https://github.com/zwzzzQAQ/MentalGLM.|http://arxiv.org/abs/2410.10323|
|369|One Language, Many Gaps: Evaluating Dialect Fairness and Robustness of   Large Language Models in Reasoning Tasks|Fangru Lin, Shaoguang Mao, Emanuele La Malfa, Valentin Hofmann, Adrian de Wynter, Jing Yao, Siqing Chen, Michael Wooldri...|2024-10-14|arXiv|https://github.com/fangru-lin/redial_dialect_robustness_fairness.git.|https://doi.org/10.48550/arXiv.2410.11005|
|370|Targeted Vaccine: Safety Alignment for Large Language Models against   Harmful Fine-Tuning via Layer-wise Perturbation|G. H. Liu, Weiwei Lin, Tiansheng Huang, Ruichao Mo, Qi Mu, Li Shen|2024-10-13|arXiv (Cornell University)|https://github.com/Lslland/T-Vaccine.|http://arxiv.org/abs/2410.09760|
|371|Benchmarking Cell Type Annotation by Large Language Models with AnnDictionary|George Crowley, Stephen R. Quake|2024-10-13|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/ggit12/anndictionary|https://doi.org/10.1101/2024.10.10.617605|
|372|AlphaPruning: Using Heavy-Tailed Self Regularization Theory for Improved   Layer-wise Pruning of Large Language Models|Haiquan Lu, Yefan Zhou, Shiwei Liu, Zhangyang Wang, Michael W. Mahoney, Yaoqing Yang|2024-10-13|NeurIPS|https://github.com/haiquanlu/AlphaPruning.|http://papers.nips.cc/paper_files/paper/2024/hash/10fc83943b4540a9524af6fc67a23fef-Abstract-Conference.html|
|373|Dual-AEB: Synergizing Rule-Based and Multimodal Large Language Models   for Effective Emergency Braking|Wei Zhang, Peng-Fei Li, Junli Wang, B. Sun, Jin Qian, Guozhang Bao, Shao‚ÄêShi Rui, Yu Yang, Wenchao Ding, Peng Li, Yilun ...|2024-10-11|ICRA|https://github.com/ChipsICU/Dual-AEB.|https://doi.org/10.1109/ICRA55743.2025.11128453|
|374|Extracting and Transferring Abilities For Building Multi-lingual   Ability-enhanced Large Language Models|Zhipeng Chen, Liang Song, Kun Zhou, Wayne Xin Zhao, Bingning Wang, Weipeng Chen, Ji-Rong Wen|2024-10-10|arXiv (Cornell University)|https://github.com/RUCAIBox/MAET|http://arxiv.org/abs/2410.07825|
|375|Key-Value Cache Quantization in Large Language Models: A Safety Benchmark|Timothy Liu|2024-10-10|International Journal of Computer Science and Information Technology|https://github.com/TimochiL/llm_benchmark.|https://doi.org/10.62051/ijcsit.v4n2.16|
|376|Teaching-Inspired Integrated Prompting Framework: A Novel Approach for   Enhancing Reasoning in Large Language Models|Wenting Tan, Dongxiao Chen, Jieting Xue, Zihao Wang, Tianqiao Chen|2024-10-10|COLING|https://github.com/SallyTan13/Teaching-Inspired-Prompting.|https://aclanthology.org/2025.coling-industry.69/|
|377|Understanding the Interplay between Parametric and Contextual Knowledge   for Large Language Models|Sitao Cheng, Liangming Pan, Xunjian Yin, Xinyi Wang, William Yang Wang|2024-10-10|arXiv (Cornell University)|https://github.com/sitaocheng/Knowledge_Interplay|http://arxiv.org/abs/2410.08414|
|378|Dissecting Fine-Tuning Unlearning in Large Language Models|Yihuai Hong, Yuelin Zou, Lijie Hu, Ziqian Zeng, Di Wang, Haiqin Yang|2024-10-09|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/yihuaihong/Dissecting-FT-Unlearning.|https://doi.org/10.18653/v1/2024.emnlp-main.228|
|379|Synthesizing Interpretable Control Policies through Large Language Model   Guided Search|Carlo Bosio, Mark W. Mueller|2024-10-07|2022 American Control Conference (ACC)|https://github.com/muellerlab/synthesizing_interpretable_control_policies.git|https://doi.org/10.23919/ACC63710.2025.11107729|
|380|Leveraging Large Language Models for Suicide Detection on Social Media   with Limited Labels|Vy Nguyen, Chau Pham|2024-10-06|2021 IEEE International Conference on Big Data (Big Data)|https://github.com/khanhvynguyen/Suicide_Detection_LLMs.|https://doi.org/10.1109/BigData62323.2024.10825313|
|381|MindScope: Exploring cognitive biases in large language models through   Multi-Agent Systems|Zhentao Xie, Jiabao Zhao, Yilei Wang, Jinxin Shi, Yanhong Bai, Xingjiao Wu, Liang He|2024-10-06|Frontiers in artificial intelligence and applications|https://github.com/2279072142/MindScope.|https://doi.org/10.3233/FAIA240879|
|382|On the Reliability of Large Language Models to Misinformed and   Demographically-Informed Prompts|Toluwani Aremu, Oluwakemi Akinwehinmi, Chukwuemeka Nwagu, Syed Ishtiaque Ahmed, Rita Orji, Pedro Arnau Del Amo, Abdulmot...|2024-10-06|Research Square (Research Square)|https://github.com/tolusophy/Edge|https://doi.org/10.21203/rs.3.rs-5258646/v1|
|383|CS4: Measuring the Creativity of Large Language Models Automatically by   Controlling the Number of Story-Writing Constraints|Anirudh Atmakuru, Jatin Nainani, Rohith Siddhartha Reddy Bheemreddy, Anirudh Lakkaraju, Zonghai Yao, Hamed Zamani, Haw-S...|2024-10-05|arXiv (Cornell University)|https://github.com/anirudhlakkaraju/cs4_benchmark.|http://arxiv.org/abs/2410.04197|
|384|Neuron-Level Sequential Editing for Large Language Models|Houcheng Jiang, Junfeng Fang, Tianyu Zhang, Baolong Bi, An Zhang, Ruipeng Wang, Tao Liang, Xiang Wang|2024-10-05|OpenAlex|https://github.com/jianghoucheng/NSE|https://doi.org/10.18653/v1/2025.acl-long.815|
|385|Output Scouting: Auditing Large Language Models for Catastrophic   Responses|Colin Bell, Jo√£o Eurico Fonseca|2024-10-04|arXiv (Cornell University)|https://github.com/joaopfonseca/outputscouting|http://arxiv.org/abs/2410.05305|
|386|POSIX: A Prompt Sensitivity Index For Large Language Models|Anwoy Chatterjee, H. S. V. N. S. Kowndinya Renduchintala, Sumit Bhatia, Tanmoy Chakraborty|2024-10-03|OpenAlex|https://github.com/kowndinya-renduchintala/POSIX.|https://doi.org/10.18653/v1/2024.findings-emnlp.852|
|387|CommonIT: Commonality-Aware Instruction Tuning for Large Language Models   via Data Partitions|Jun Rao, Xuebo Liu, Lian Lian, Shengjun Cheng, Yunjie Liao, Min Zhang|2024-10-03|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/raojay7/CommonIT|https://doi.org/10.18653/v1/2024.emnlp-main.561|
|388|Basis Sharing: Cross-Layer Parameter Sharing for Large Language Model   Compression|Jingcun Wang, Yu-Guang Chen, Ing-Chao Lin, Bing Li, Grace Li Zhang|2024-10-02|ICLR|https://github.com/TUDa-HWAI/Basis_Sharing|https://openreview.net/forum?id=gp32jvUquq|
|389|DLP-LoRA: Efficient Task-Specific LoRA Fusion with a Dynamic,   Lightweight Plugin for Large Language Models|Yuxuan Zhang, Ruizhe Li|2024-10-02|arXiv (Cornell University)|https://github.com/MeCuping/DLP-LoRA.|http://arxiv.org/abs/2410.01497|
|390|CodeJudge: Evaluating Code Generation with Large Language Models|Weiwei Tong, Tianyi Zhang|2024-10-02|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/VichyTong/CodeJudge.|https://doi.org/10.18653/v1/2024.emnlp-main.1118|
|391|AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge   Distillation for Large Language Models in Code Generation|Ziyang Luo, Xin Li, Hongzhan Lin, Jing Ma, Lidong Bing|2024-10-01|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/ChiYeungLaw/AMR-Evol.|https://doi.org/10.18653/v1/2024.emnlp-main.66|
|392|Do Influence Functions Work on Large Language Models?|Zhe Li, Wei Zhao, Yige Li, Jun Sun|2024-09-30|arXiv (Cornell University)|https://github.com/plumprc/Failures-of-Influence-Functions-in-LLMs.|http://arxiv.org/abs/2409.19998|
|393|Can Large Language Models Analyze Graphs like Professionals? A   Benchmark, Datasets and Models|Xin Li, Weize Chen, Qi Chu, Haopeng Li, Zhaojun Sun, Ran Li, Qian Chen, Yiwei Wei, Z. Liu, Chuan Shi, Maosong Sun, Cheng...|2024-09-29|NeurIPS|https://github.com/BUPT-GAMMA/ProGraph.|http://papers.nips.cc/paper_files/paper/2024/hash/ff417c3993894694e88ffc4d3f53d28b-Abstract-Datasets_and_Benchmarks_Track.html|
|394|Identifying Knowledge Editing Types in Large Language Models|Xiao Peng Li, Shangwen Wang, Shezheng Song, Bin Ji, Huijun Liu, Shasha Li, Jun Ma, Jie Yu|2024-09-29|OpenAlex|https://github.com/xpq-tech/KETI.|https://doi.org/10.1145/3711896.3737001|
|395|RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling   Large Language Models|Shuhao Chen, Weisen Jiang, Baijiong Lin, James T. Kwok, Yu Zhang|2024-09-29|NeurIPS|https://github.com/shuhao02/RouterDC.|http://papers.nips.cc/paper_files/paper/2024/hash/7a641b8ec86162fc875fb9f6456a542f-Abstract-Conference.html|
|396|OpenSep: Leveraging Large Language Models with Textual Inversion for   Open World Audio Separation|Tanvir Mahmud, Diana Marculescu|2024-09-28|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/tanvir-utexas/OpenSep.git|https://doi.org/10.18653/v1/2024.emnlp-main.735|
|397|Align$^2$LLaVA: Cascaded Human and Large Language Model Preference   Alignment for Multi-modal Instruction Curation|Hongzhe Huang, Zhewen Yu, Jiang Liu, Li Cai, Dian Jiao, Wenqiao Zhang, Siliang Tang, Juncheng Li, Hao Jiang, Haoyuan Li,...|2024-09-27|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/DCDmllm/Align2LLaVA.|https://doi.org/10.18653/v1/2025.findings-acl.458|
|398|Control Industrial Automation System with Large Language Models|Yuchen Xia, Nasser Jazdi, J. Zhang, C.L. Shah, Michael Weyrich|2024-09-26|arXiv (Cornell University)|https://github.com/YuchenXia/LLM4IAS|http://arxiv.org/abs/2409.18009|
|399|CurricuLLM: Automatic Task Curricula Design for Learning Complex Robot   Skills using Large Language Models|Kanghyun Ryu, Qiayuan Liao, Zhongyu Li, Payam Delgosha, Koushil Sreenath, Negar Mehr|2024-09-26|ICRA|https://github.com/labicon/CurricuLLM|https://doi.org/10.1109/ICRA55743.2025.11128783|
|400|Harmful Fine-tuning Attacks and Defenses for Large Language Models: A   Survey|Tiansheng Huang, Sihao Hu, Fatih ƒ∞lhan, Selim Furkan Tekin, Ling Liu|2024-09-26|arXiv (Cornell University)|https://github.com/git-disl/awesome_LLM-harmful-fine-tuning-papers|http://arxiv.org/abs/2409.18169|
|401|LLM-CARD: Towards a Description and Landscape of Large Language Models|Shengwei Tian, Lifeng Han, Erick Mendez Guzman, Goran Nenadiƒá|2024-09-25|arXiv (Cornell University)|https://github.com/shengwei-tian/dependency-parser-visualization|http://arxiv.org/abs/2409.17011|
|402|RED QUEEN: Safeguarding Large Language Models against Concealed   Multi-Turn Jailbreaking|Yifan Jiang, Kriti Aggarwal, Tanmay Laud, Kashif Munir, Jay Pujara, Subhabrata Mukherjee|2024-09-25|arXiv (Cornell University)|https://github.com/kriti-hippo/red_queen.|http://arxiv.org/abs/2409.17458|
