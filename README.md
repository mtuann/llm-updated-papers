# Table of Contents
1. [Large Language Models Papers](#large-language-models-papers)
2. [Other Research Topics](#other-research-topics)
3. [Large Language Models Papers with Code](#large-language-models-papers-with-code)
4. [Data Sources](#data-sources)
5. [Contributing](#contributing)
6. [Support](#support)

## Large Language Models Papers
This GitHub repository contains an updated list of Large Language Models papers as of **October 15, 2025**. 

### Overview
- **Total Papers**: Updated regularly with latest publications
- **Coverage**: Papers from 2016 to present
- **Sources**: Collected from arXiv, NeurIPS, ICML, ICLR, ACL, EMNLP, AAAI, IJCAI, KDD, CVPR, ICCV, ECCV, IEEE, ACM, Springer, ScienceDirect, Nature, and other top AI/ML conferences and journals
- **Interactive Search**: For a better reading experience, visit the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/)

### Key Features
- üìä **Comprehensive Coverage**: Papers from major AI/ML venues
- üîç **Advanced Search**: Filter by title, author, venue, year
- üìÖ **Regular Updates**: Automated collection of new papers
- üíª **Code Availability**: Identifies papers with available code
- üìà **Trending Research**: Focus on cutting-edge developments

---

## Other Research Topics
Explore additional research papers on the following topics:

### Machine Learning & AI
- **[Large Language Models](https://github.com/mtuann/llm-updated-papers)** - LLM research and applications
- **[Federated Learning](https://github.com/mtuann/federated-learning-updated-papers)** - Distributed machine learning
- **[Backdoor Learning](https://github.com/mtuann/backdoor-ai-resources)** - Adversarial machine learning
- **[Machine Unlearning](https://github.com/mtuann/machine-unlearning-papers)** - Data removal and privacy

### Computing & Systems
- **[Serverless Computing](https://mtuann.shinyapps.io/research-papers/)** - Cloud computing architectures
- **[Multi-Modal Learning](https://mtuann.shinyapps.io/research-papers/)** - Multi-modal AI systems

### Interactive Platforms
- **[Research Papers App](https://mtuann.shinyapps.io/research-papers/)** - Search and explore all papers
- **[Paper Collections](https://github.com/mtuann/research-papers)** - Main repository with all datasets

---

## Data Sources
The papers are collected from the following sources:

### Academic Databases
- **arXiv** (1991-present) - Preprints and published papers
- **OpenReview** - Conference submissions and peer reviews
- **ACM Digital Library** - Computer science publications
- **Springer** - Academic journals and conferences
- **ScienceDirect** - Elsevier publications
- **Nature** - High-impact research papers
- **DBLP** - Computer science bibliography
- **Google Scholar** - Academic search engine
- **CrossRef** - DOI registration agency
- **OpenAlex** - Open scholarly data

### Major Conferences & Journals
- **Machine Learning**: NeurIPS, ICML, ICLR, JMLR, TMLR
- **Natural Language Processing**: ACL, EMNLP, NAACL, COLING
- **Computer Vision**: CVPR, ICCV, ECCV, PAMI, IJCV
- **Artificial Intelligence**: AAAI, IJCAI, AAMAS
- **Data Mining**: KDD, ICDM, SDM, TKDD
- **Security & Privacy**: CCS, USENIX Security, NDSS
- **And many more...**

---

## Large Language Models Papers with Code
Due to GitHub repository limitations, this section includes only those papers that provide accompanying code, sorted by publication date. For access to the full list of papers, please visit the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/).

<!-- 
### Summary Statistics
- **Total Papers in Dataset**: 32,286
- **Papers with Available Code**: 1,291
- **Code Availability Rate**: 4.0%
- **Last Updated**: October 15, 2025

### Paper Statistics
- **Total Papers**: 32286
- **Papers with Code**: 32286
- **Latest Update**: 32286
- **Coverage Period**: 2016 - Present -->

---

## Contributing
We welcome contributions to improve this paper collection:

### How to Contribute
1. **Add Missing Papers**: Submit papers that should be included
2. **Improve Metadata**: Help enhance paper information
3. **Report Issues**: Identify bugs or missing features
4. **Suggest Improvements**: Propose new features or enhancements

### Contact Information
- **Email**: [tuannm0312@gmail.com](mailto:tuannm0312@gmail.com)
- **GitHub Issues**: [Create an issue](https://github.com/mtuann/research-papers/issues)
- **Discussions**: [Join the discussion](https://github.com/mtuann/research-papers/discussions)

---

## Support
If you find this application helpful and would like to support its development, you can buy me a coffee using one of the following methods:

### Payment Methods
- **Techcombank (Vietnam)**: 5877 5555 55 (Nguyen Thi Lan Phuong)
- **PayPal or Credit/Debit Card**: [https://ko-fi.com/miutheladycat](https://ko-fi.com/miutheladycat)

### Why Support?
Your support helps maintain and improve:
- ü§ñ Automated paper collection pipeline
- üåê Interactive web application
- üìä Regular data updates
- üîß System maintenance and improvements
- üìö New research area coverage

---

**Note**: This repository is regularly updated with new papers. For the most current data, check the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/) or the individual topic repositories linked above.


|No.|Title|Authors|Publish Date|Venue|Code|URL|
|---|---|---|---|---|---|---|
|1|In BLOOM: Creativity and Affinity in Artificial Lyrics and Art|Evan Crothers, Herna L. Viktor, Nathalie Japkowicz||creativeAI|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/in-bloom-creativity-and-affinity-in/code)|https://openreview.net/pdf/3d502829f7e86330802059674fac7b55dfb63091.pdf|
|2|A Simple, Yet Effective Approach to Finding Biases in Code Generation|Spyridon Mouselinos, Mateusz Malinowski, Henryk Michalewski||OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/a-simple-yet-effective-approach-to-finding/code)|https://openreview.net/pdf/dc913e6b5396ddf78d74195871197392db78fa41.pdf|
|3|Microscaling Floating Point Formats for Large Language Models|Marco Cococcioni, Dario Pagani, Federico Rossi|2025-10-02|arXiv (Cornell University)|https://github.com/unipi-dii-compressedarith/llm.c-sve|http://arxiv.org/abs/2510.01863|
|4|Guiding Multimodal Large Language Models with Blind and Low Vision People Visual Questions for Proactive Visual Interpretations|Ricardo E. Gonzalez Penuela, Felipe Arias-Russi, Victor Capriles|2025-10-02|arXiv (Cornell University)|https://github.com/rgonzalezp/guiding-multimodal-large-language-models-with-blind-and-low-vision-people-visual-questions|http://arxiv.org/abs/2510.01576|
|5|Copy-Paste to Mitigate Large Language Model Hallucinations|Yao Long, Xianrui Wu, Yingying Zhang, Xianbin Wen, Yuxi Zhou, Shenda Hong|2025-10-01|arXiv (Cornell University)|https://github.com/longyongchao/CopyPasteLLM|http://arxiv.org/abs/2510.00508|
|6|StyleBench: Evaluating thinking styles in Large Language Models|Junyi Guo, Shangding Gu, Ming Jin, Costas J. Spanos, Javad Lavaei|2025-09-25|arXiv (Cornell University)|https://github.com/JamesJunyuGuo/Style_Bench.|http://arxiv.org/abs/2509.20868|
|7|Towards Atoms of Large Language Models|Chenhui Hu, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao|2025-09-25|arXiv (Cornell University)|https://github.com/ChenhuiHu/towards_atoms.|http://arxiv.org/abs/2509.20784|
|8|SCRA-VQA: Summarized Caption-Rerank for Augmented Large Language Models in Visual Question Answering|Zhang Yan, Jiaqing Lin, Miao Zhang, Kui Xiao, Xiaoju Hou, Jing Zhao, Zhifei Li|2025-09-25|arXiv (Cornell University)|https://github.com/HubuKG/SCRA-VQA.|http://arxiv.org/abs/2509.20871|
|9|ConceptViz: A Visual Analytics Approach for Exploring Concepts in Large Language Models|Haoxuan Li, Zhen Wen, Qiqi Jiang, Chenxiao Li, Yuwei Wu, Yuchen Yang, Yiyao Wang, Xiuqi Huang, Minfeng Zhu, Wei Chen|2025-09-20|arXiv (Cornell University)|https://github.com/Happy-Hippo209/ConceptViz.|http://arxiv.org/abs/2509.20376|
|10|MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large Language Model Agents|Pan Tang, Shixiang Tang, Huayan Pu, Zhiqing Miao, Zhixing Wang|2025-09-19|arXiv (Cornell University)|https://github.com/tangpan360/MicroRCA-Agent.|http://arxiv.org/abs/2509.15635|
|11|CFD-LLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics|Nithin Somasekharan, Ling Yue, Yadi Cao, Weichao Li, Patrick Emami, Pochinapeddi Sai Bhargav, Anurag Acharya, Xingyu Xie...|2025-09-19|arXiv (Cornell University)|https://github.com/NREL-Theseus/cfdllmbench|http://arxiv.org/abs/2509.20374|
|12|A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness|Fali Wang, Zhiwei Zhang, Xianren Zhang, Zongyu Wu, Tzuhao Mo, Qiuhao Lu, W.K. Wang, Rui Li, Junjie Xu, Xianfeng Tang, Qi...|2025-09-18|ACM Transactions on Intelligent Systems and Technology|https://github.com/FairyFali/SLMs-Survey|https://doi.org/10.48550/arXiv.2411.03350|
|13|Enhancing Base Large Language Models Using Knowledge Graphs for Genomic Annotation|Pranav N. Desai, S. Padhi, Kavya Panicker, Kallakunta Ravi Kumar, Divyaprabha KN|2025-09-16|Advances in transdisciplinary engineering|https://github.com/cubed-guy/capstone-kg-llm.|https://doi.org/10.3233/atde250737|
|14|PLiCat: Decoding protein-lipid interactions by large language model|Feitong Dong, Jingrou Wu|2025-09-14|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/Noora68/PLiCat.|https://doi.org/10.1101/2025.09.09.675043|
|15|Large Language Models Meet Legal Artificial Intelligence: A Survey|Zhitian Hou, Zihan Ye, Nanli Zeng, Tianyong Hao, Kun Zeng|2025-09-12|arXiv (Cornell University)|https://github.com/ZhitianHou/LLMs4LegalAI.|http://arxiv.org/abs/2509.09969|
|16|Rethinking Reasoning Quality in Large Language Models through Enhanced Chain-of-Thought via RL|Hongming He, Zihua Rong, Kunpeng Ji, Chenyang Li, Qing Huang, ÂÖÖÊ≠£ ÂÆÆ‰∏ã, Lan Yang, Honggang Zhang|2025-09-07|arXiv (Cornell University)|https://github.com/Henryhe09/DRER.|http://arxiv.org/abs/2509.06024|
|17|CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor|Zhenhua Xu, Xin Zhao, X. Yue, Shengwei Tian, Changting Lin, Meng Han|2025-09-05|arXiv (Cornell University)|https://github.com/Xuzhenhua55/CTCC|http://arxiv.org/abs/2509.09703|
|18|Schema Inference for Tabular Data Repositories Using Large Language Models|Zhenyu Wu, Jiaoyan Chen, Norman W. Paton|2025-09-04|arXiv (Cornell University)|https://github.com/PierreWoL/SILLM.|http://arxiv.org/abs/2509.04632|
|19|Behavioral Fingerprinting of Large Language Models|Zehua Pei, H Zhen, Ying Zhang, Zhiyuan Yang, X Li, X. D. Yu, Mingxuan Yuan, Bin Yu|2025-09-02|arXiv (Cornell University)|https://github.com/JarvisPei/Behavioral-Fingerprinting|http://arxiv.org/abs/2509.04504|
|20|Token-Level Accept or Reject: A Micro Alignment Approach for Large Language Models|Yang Zhang, Yu Yu, Bo Tang, Limin Zhu, Chuxiong Sun, Wenqiang Wei, Jie Hu, Zheng Xie, Zhiyu Li, Feiyu Xiong, Edward Chun...|2025-09-01|OpenAlex|https://github.com/IAAR-Shanghai/MARA|https://doi.org/10.48550/arXiv.2505.19743|
|21|Good Advisor for Source Localization: Using Large Language Model to Guide the Source Inference Process|Dongpeng Hou, Weifeng Wei, Chao Gao, Xianghua Li, Zhen Wang|2025-09-01|OpenAlex|https://github.com/cgao-comp/CRSLL.|https://doi.org/10.24963/ijcai.2025/326|
|22|Exploring homology detection via k-means clustering of proteins embedded with a large language model|Thomas Minotto, Antoine Claessens, Thomas D. Otto|2025-08-26|Bioinformatics|https://github.com/ThomasGTHB/OrthoLM|https://doi.org/10.1093/bioinformatics/btaf472|
|23|LLM4DSR: Leveraing Large Language Model for Denoising Sequential   Recommendation|Bohao Wang, Feng Liu, Changwang Zhang, Jiawei Chen, Yudi Wu, Sheng Zhou, Xingyu Lou, Jun Wang, Yan Feng, Chun Chen, Can ...|2025-08-25|ACM transactions on office information systems|https://github.com/WANGBohaO-jpg/LLM4DSR|https://doi.org/10.1145/3762182|
|24|E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model|Ronghao Lin, Shali Shen, Weipeng Hu, Qiaolin He, Aolin Xiong, Li Huang, Huosheng Hu, Yap‚ÄêPeng Tan|2025-08-18|arXiv|https://github.com/RH-Lin/E3RG.|https://doi.org/10.48550/arXiv.2508.12854|
|25|Mitigating Hallucinations in Large Language Models via Causal Reasoning|Yuangang Li, Yiqing Shen, Yi Nian, Jiechao Gao, Ziyi Wang, Chenxiao Yu, Shawn Li, Jie Wang, Xiyang Hu, Yue Zhao|2025-08-17|arXiv|https://github.com/MrLYG/CDCR-SFT.|https://doi.org/10.48550/arXiv.2508.12495|
|26|GS-DTI: A Graph-Structure-Aware Framework Leveraging Large Language Models for Drug‚ÄìTarget Interaction Prediction|Qinze Yu, Chang Zhou, Jiyue Jiang, Xiangyu Shi, Yu Li|2025-08-09|Bioinformatics|https://github.com/purvavideha/GSDTI.|https://doi.org/10.1093/bioinformatics/btaf445|
|27|Enhancing Interpretability of Ocular Disease Diagnosis: A Zero-Shot Study of Multimodal Large Language Models|Yating Pan, Janna Hastings|2025-08-07|Studies in health technology and informatics|https://github.com/YatingPan/ocular-llm-explainability.|https://doi.org/10.3233/shti250910|
|28|CityGPT: Empowering Urban Spatial Cognition of Large Language Models|Jie Feng, Yuwei Du, Tianhui Liu, Siqi Guo, Yuming Lin, Li Yong|2025-08-01|OpenAlex|https://github.com/tsinghua-fib-lab/CityGPT.|https://doi.org/10.48550/arXiv.2406.13948|
|29|A large language model for predicting neurotoxic peptides and neurotoxins|Anand Singh Rathore, Saloni Jain, Shubham Choudhury, Gajendra P. S. Raghava|2025-08-01|PubMed|https://github.com/raghavagps/ntxpred2|https://pubmed.ncbi.nlm.nih.gov/40671295|
|30|SKiM-GPT: Combining Biomedical Literature-Based Discovery with Large Language Model Hypothesis Evaluation|Jack Freeman, Robert J. Millikin, Liang Xu, Indu Sharma, Bethany M. Moore, Cannon Lock, Kevin W. George, Antonin Bal, Ro...|2025-07-31|OpenAlex|https://github.com/stewart-lab/skimgpt|https://doi.org/10.1101/2025.07.28.664797|
|31|BRAVE: a highly accurate method for predicting HIV-1 antibody resistance using large language models for proteins|Mohammed El Anbari, Tatsiana Bylund, Sijy O‚ÄôDell, Emily Tourtellott, Krisha McKee, Stephen D. Schmidt, Nonhlanhla N. Mkh...|2025-07-31|OpenAlex|https://github.com/kiryst/BRAVE|https://doi.org/10.1101/2025.07.28.667234|
|32|Reading papers: Extraction of molecular interaction networks with large language models|Enio Gjerga, Philipp Wiesenbach, Christoph Dieterich|2025-07-25|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/dieterich-lab/LLM_Relations.|https://doi.org/10.1101/2025.07.21.665999|
|33|A Survey on AI Search with Large Language Models|Jian Li, Xiaoxi Li, Yan Zheng, Yizhang Jin, Shuo Wang, Jian Wu, Yabiao Wang, Chengjie Wang, X. Q. Yuan|2025-07-24|OpenAlex|https://github.com/swordlidev/Awesome-AI-Search.|https://doi.org/10.20944/preprints202507.2024.v1|
|34|BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining|Baqer M. Merzah, Tania Taami, Salman Asoudeh, Amir reza Hossein pour, Saeed Mirzaee, Amir Ali Bengari|2025-07-21|OpenAlex|https://github.com/amirap80/BioPars|https://doi.org/10.21203/rs.3.rs-6823379/v1|
|35|textToKnowledgeGraph: Generation of Molecular Interaction Knowledge Graphs Using Large Language Models for Exploration in Cytoscape|Favour James, Christopher Churas, Dexter Pratt, Augustin Luna|2025-07-21|OpenAlex|https://github.com/ndexbio/llm-text-to-knowledge-graph|https://doi.org/10.1101/2025.07.17.664328|
|36|Empowering Universal Robot Programming with Fine-Tuned Large Language Models|Tien Dat Le, Minhhuy Le|2025-07-15|EAI Endorsed Transactions on AI and Robotics|https://github.com/t1end4t/llm-robotics|https://doi.org/10.4108/airo.8983|
|37|A Survey on the Memory Mechanism of Large Language Model based Agents|Zeyu Zhang, Quanyu Dai, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Jieming Zhu, Zhenhua Dong, Ji-Rong Wen|2025-07-11|ACM transactions on office information systems|https://github.com/nuster1128/LLM_Agent_Memory_Survey|https://doi.org/10.48550/arXiv.2404.13501|
|38|Conversational health agents: a personalized large language model-powered agent framework|Mahyar Abbasian, Iman Azimi, Amir M. Rahmani, Ramesh Jain|2025-07-03|JAMIA Open|https://github.com/Institute4FutureHealth/CHA|https://doi.org/10.1093/jamiaopen/ooaf067|
|39|ParaStudent: Generating and Evaluating Realistic Student Code by   Teaching LLMs to Struggle|Mihran Miroyan, Rose Niousha, Joseph E. Gonzalez, Gireeja Ranade, Narges Norouzi|2025-07-01|arXiv|https://github.com/mmiroyan/ParaStudent|http://arxiv.org/abs/2507.12674v1|
|40|Warehouse Spatial Question Answering with LLM Agent|Hsiang-Wei Huang, Jen-Hao Cheng, Kuang-Ming Chen, Cheng-Yen Yang, Bahaa Alattar, Yi-Ru Lin, Pyongkun Kim, Sangwon Kim, K...|2025-07-01|arXiv|https://github.com/hsiangwei0903/SpatialAgent|http://arxiv.org/abs/2507.10778v1|
|41|The benefits of query-based KGQA systems for complex and temporal   questions in LLM era|Artem Alekseev, Mikhail Chaichuk, Miron Butko, Alexander Panchenko, Elena Tutubalina, Oleg Somov|2025-07-01||https://github.com/ar2max/NLDB-KGQA-System|http://arxiv.org/abs/2507.11954v1|
|42|The Evolving Role of Large Language Models in Scientific Innovation:   Evaluator, Collaborator, and Scientist|Haoxuan Zhang, Ruochi Li, Yang Zhang, Ting Xiao, Jiangping Chen, Junhua Ding, Haihua Chen|2025-07-01|arXiv|https://github.com/haoxuan-unt2024/llm4innovation.|https://doi.org/10.48550/arXiv.2507.11810|
|43|The Devil behind the mask: An emergent safety vulnerability of Diffusion   LLMs|Zichen Wen, Jiashu Qu, Dongrui Liu, Zhiyuan Liu, Ruixi Wu, Yicun Yang, Xiangqi Jin, Haoyun Xu, Xuyang Liu, Weijia Li, Ch...|2025-07-01|arXiv|https://github.com/ZichenWen1/DIJA.|http://arxiv.org/abs/2507.11097v1|
|44|Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding|Feng Xiao, Jicong Fan|2025-07-01|arXiv|https://github.com/jicongfan/Text-Anomaly-Detection-Benchmark|http://arxiv.org/abs/2507.12295v1|
|45|spaLLM: enhancing spatial domain analysis in multi-omics data through large language model integration|Longyi Li, Liyan Dong, Hao Zhang, Dong Xu, Yongli Li|2025-07-01|Briefings in Bioinformatics|https://github.com/liiilongyi/spaLLM.|https://doi.org/10.1093/bib/bbaf304|
|46|Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal   Large Language Models|Gen Luo, Wenhan Dou, Wenhao Li, Zhaokai Wang, Xue Yang, Changyao Tian, Hao Li, Weiyun Wang, Wenhai Wang, Xizhou Zhu, Yu ...|2025-07-01|arXiv|https://github.com/OpenGVLab/Mono-InternVL.|https://doi.org/10.48550/arXiv.2507.12566|
|47|Exploring the potential of lightweight large language models for AI-based mental health counselling task: a novel comparative study|Ritesh Maurya, Nikhil Kumar Rajput, M G Diviit, Satyajit Mahapatra, Manish Kumar Ojha|2025-07-01|Scientific Reports|https://github.com/diviitmg03/Comparative-analysis-of-LLMs-.git|https://doi.org/10.1038/s41598-025-05012-1|
|48|Marco-Bench-MIF: On Multilingual Instruction-Following Capability of   Large Language Models|Bo Zeng, Chenyang Lyu, Sinuo Liu, Mingyan Zeng, Minghao Wu, Xuanfan Ni, Tianqi Shi, Yu Zhao, Yefeng Liu, Chenyu Zhu, Rui...|2025-07-01|arXiv|https://github.com/AIDC-AI/Marco-Bench-MIF.|https://doi.org/10.48550/arXiv.2507.11882|
|49|DrafterBench: Benchmarking Large Language Models for Tasks Automation in   Civil Engineering|Yinsheng Li, Zhen Dong, Yi Shao|2025-07-01|arXiv|https://github.com/Eason-Li-AIS/DrafterBench|https://doi.org/10.48550/arXiv.2507.11527|
|50|Analysis of Image-and-Text Uncertainty Propagation in Multimodal Large   Language Models with Cardiac MR-Based Applications|Yucheng Tang, Yunguan Fu, Weixi Yi, Yipei Wang, Daniel C. Alexander, Rhodri H. Davies, Yipeng Hu|2025-07-01|Lecture notes in computer science|https://github.com/yucheng722/MUPM.|https://doi.org/10.1007/978-3-032-04965-0_4|
|51|DSSD: Efficient Edge-Device LLM Deployment and Collaborative Inference   via Distributed Split Speculative Decoding|Jiahong Ning, Ce Zheng, Tingting Yang|2025-07-01|arXiv|https://github.com/JasonNing96/DSSD-Efficient-Edge-Computing|http://arxiv.org/abs/2507.12000v2|
|52|First-Order Error Matters: Accurate Compensation for Quantized Large   Language Models|Xingyu Zheng, Haotong Qin, Yuye Li, Jiakai Wang, Jinyang Guo, Michele Magno, Xianglong Liu|2025-07-01|arXiv|https://github.com/Xingyu-Zheng/FOEM.|https://doi.org/10.48550/arXiv.2507.11017|
|53|Internal Value Alignment in Large Language Models through Controlled   Value Vector Activation|Haoran Jin, Meng Li, Xiting Wang, Zhihao Xu, Minlie Huang, Yantao Jia, Defu Lian|2025-07-01|OpenAlex|https://github.com/hr-jin/ConVA.|https://doi.org/10.18653/v1/2025.acl-long.1326|
|54|Leveraging large language models to predict antibiotic resistance in <i>Mycobacterium tuberculosis</i>|Conrad Testagrose, Sakshi Pandey, Mohammadali Serajian, Simone Marini, Mattia Prosperi, Christina Boucher|2025-07-01|Bioinformatics|https://github.com/ctestagrose/LLMTB.|https://doi.org/10.1093/bioinformatics/btaf232|
|55|DrugTar Improves Druggability Prediction by Integrating Large Language Models and Gene Ontologies|Niloofar Borhani, Iman Izadi, Ali Motahharynia, Mahsa Sheikholeslami, Yousof Gheisari|2025-06-24|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/NBorhani/DrugTar.|https://doi.org/10.1093/bioinformatics/btaf360|
|56|Finding the Dark Matter: Large Language Model-based Enzyme Kinetic Data Extractor and Its Validation|G. Wei, Xinchun Ran, Runeem Al-Abssi, Zhongyue Yang|2025-06-20|OpenAlex|https://github.com/ChemBioHTP/EnzyExtract|https://doi.org/10.26434/chemrxiv-2025-pb73x-v2|
|57|LANG: A Lesson Plan Generation Framework via Multi-Form Interaction with Large Language Models|Yong Ouyang, Jinhao Quan, Huan-Wen Wang, Yawen Zeng, Lingyu Chen|2025-06-17|Research Square (Research Square)|https://github.com/ssakana/LANG.|https://doi.org/10.21203/rs.3.rs-6808103/v1|
|58|Prime the search: Using large language models for guiding geometric task and motion planning by warm-starting tree search|Dongryung Lee, Se June Joo, Kimin Lee, Beomjoon Kim|2025-06-06|The International Journal of Robotics Research|https://github.com/iMSquared/prime-the-search|https://doi.org/10.1177/02783649251347307|
|59|Improving drug-drug interaction prediction via in-context learning and judging with large language models|He Qi, Xiaoqiang Li, Chengcheng Zhang, Tianyi Zhao|2025-06-02|Frontiers in Pharmacology|https://github.com/zcc1203/ddi-judge.|https://doi.org/10.3389/fphar.2025.1589788|
|60|Survey on Factuality in Large Language Models|Cunxiang Wang, Xiaoze Liu, Yuanhao Yue, Qipeng Guo, Xiangkun Hu, Xiangru Tang, Tianhang Zhang, Cheng Jiayang, Yunzhi Yao...|2025-06-02|ACM Computing Surveys|https://github.com/wangcunxiang/LLM-Factuality-Survey.|https://doi.org/10.1145/3742420|
|61|SummArIzeR: Simplifying cross-database enrichment result clustering and annotation via large language models|Marie Brinkmann, Michael Bonelli, Anela Tosevska|2025-06-01|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/bonellilab/SummArIzeR.|https://doi.org/10.1101/2025.05.28.656331|
|62|The accuracy and efficiency of large language models for chart review in cancer genetics|James Dickerson, Margaret Shaw, Mina Satoyoshi, Sonia Rios‚ÄêVentura, Kerry Kingham, Allison W. Kurian, Jennifer L. Caswel...|2025-05-28|Journal of Clinical Oncology|https://github.com/MrJimb0/ASCO2025|https://doi.org/10.1200/jco.2025.43.16_suppl.e22603|
|63|Mitigating Age-Related Bias in Large Language Models: Strategies for Responsible Artificial Intelligence Development|Zhuang Liu, S. Qian, Shuirong Cao, Tianyu Shi|2025-05-21|INFORMS journal on computing|https://github.com/INFORMSJoC/2024.0645|https://doi.org/10.1287/ijoc.2024.0645|
|64|Social determinants of health extraction from clinical notes across institutions using large language models|Vipina K. Keloth, Salih Selek, Qingyu Chen, Christopher Gilman, Sunyang Fu, Yifang Dang, Xinghan Chen, Xinyue Hu, Yujia ...|2025-05-17|npj Digital Medicine|https://github.com/BIDS-Xu-Lab/LLMs4SDoH|https://doi.org/10.1038/s41746-025-01645-8|
|65|ProtFun: A Protein Function Prediction Model Using Graph Attention Networks with a Protein Large Language Model|Muhammed Talo, Serdar Bozdag|2025-05-17|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/bozdaglab/ProtFun|https://doi.org/10.1101/2025.05.13.653854|
|66|Exploring Zero-Shot Cross-Lingual Biomedical Concept Normalization via Large Language Models|Hossein Rouhizadeh, Anthony Yazdani, Boya Zhang, Douglas Teodoro|2025-05-15|Studies in health technology and informatics|https://github.com/hrouhizadeh/zsh_cl_bcn.|https://doi.org/10.1101/2025.02.27.25323007|
|67|Leveraging Large Language Models for Literature-Driven Prioritization of Protein Binding Pockets|Roman Stratiichuk, Mykola Melnychenko, Ihor Koleiev, Taras Voitsitskyi, Husak Vladyslav, –ù–∞—Ç–∞–ª—ñ—è –ê–Ω–∞—Ç–æ–ª—ñ—ó–≤–Ω–∞ –®–µ–≤—á—É–∫, Zak...|2025-05-15|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/MelnychenkoM/LLM-benchmark-dataset.|https://doi.org/10.1093/bioinformatics/btaf449|
|68|UrbanPlanBench: A Comprehensive Urban Planning Benchmark for Evaluating Large Language Models|Yu Zheng, Longyi Liu, Yuming Lin, Jie Feng, Guozhen Zhang, Depeng Jin, Yong Li|2025-04-30|Research Square (Research Square)|https://github.com/tsinghua-fib-lab/PlanBench|https://doi.org/10.21203/rs.3.rs-6551071/v1|
|69|Evaluating Personality Traits of Large Language Models Through Scenario-based Interpretive Benchmarking|Alessandro Berti|2025-04-09|OpenAlex|https://github.com/fit-alessandro-berti/llm-dreams-benchmark.|https://doi.org/10.20944/preprints202504.0435.v1|
|70|Improving Text-to-Sql Conversion for Low-Resource Languages Using Large Language Models|Emƒ±r √ñzt√ºrk|2025-03-26|Bitlis Eren √úniversitesi Fen Bilimleri Dergisi|https://github.com/emirozturk/TT2SQL.|https://doi.org/10.17798/bitlisfen.1561298|
|71|Prompting and Fine-Tuning Open-Sourced Large Language Models for Stance Classification|Iain J. Cruickshank, Lynnette Hui Xian Ng|2025-03-25|ACM Transactions on Intelligent Systems and Technology|https://github.com/ijcruic/LLM-Stance-Labeling|https://doi.org/10.1145/3725816|
|72|Enhancing Gene Set Overrepresentation Analysis with Large Language Models|Jianjun Zhu, Rebecca Y. Wang, Xiaoting Wang, Ricardo B. R. Azevedo, Alexander Moreno, Julia Kuhn, Zia Khan|2025-03-13|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/Alector-BIO/llm2geneset|https://doi.org/10.1101/2024.11.11.621189|
|73|NTxPred2: A large language model for predicting neurotoxic peptides and neurotoxins|Anand Singh Rathore, Saloni Jain, Shubham Choudhury, Gajendra P. S. Raghava|2025-03-07|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/raghavagps/ntxpred2|https://doi.org/10.1101/2025.03.01.640936|
|74|Automatic recognition of cross-language classic entities based on large language models|Qiankun Xu, Yutong Liu, Dongbo Wang, Huang Shuiqing|2025-03-03|OpenAlex|https://github.com/Xunzi-LLM-of-Chinese-classics/XunziALLM|https://doi.org/10.1038/s40494-025-01624-y|
|75|SensitiveCancerGPT: Leveraging Generative Large Language Model on Structured Omics Data to Optimize Drug Sensitivity Prediction|Shaika Chowdhury, Sivaraman Rajaganapathy, Lichao Sun, Liewei Wang, Ping Yang, James R. Cerhan, Nansu Zong|2025-02-28|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/bioIKEA/SensitiveCancerGPT.|https://doi.org/10.1101/2025.02.27.640661|
|76|Dynamic Low-Rank Sparse Adaptation for Large Language Models|Weizhong Huang, Yuxin Zhang, Xiawu Zheng, Yang Liu, Jing Lin, Yiwu Yao, Rongrong Ji|2025-02-20|ICLR|https://github.com/wzhuang-xmu/LoSA.|https://openreview.net/forum?id=oXh0939Zzq|
|77|TritonBench: Benchmarking Large Language Model Capabilities for   Generating Triton Operators|Jianling Li, Shaohui Li, Zhihao Gao, Qi Shi, Yuxuan Li, Zefan Wang, Jie Huang, Haojie Wang, Jianrong Wang, Xu Han, Zhiyu...|2025-02-20|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/thunlp/TritonBench.|https://doi.org/10.18653/v1/2025.findings-acl.1183|
|78|CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems   Based on Large Language Models|Zhenhong Zhou, Zherui Li, Jie Zhang, Yuanhe Zhang, Kun Wang, Yang Liu, Qing Guo|2025-02-20|arXiv|https://github.com/zhrli324/Corba.|https://doi.org/10.48550/arXiv.2502.14529|
|79|AI-Empowered Catalyst Discovery: A Survey from Classical Machine   Learning Approaches to Large Language Models|Yuanyuan Xu, Hanchen Wang, Wenjie Zhang, Lexing Xie, Yin Chen, Flora D. Salim, Ying Zhang, J. Justin Gooding, Toby Walsh|2025-02-19|arXiv|https://github.com/LuckyGirl-XU/Awesome-Artificial-Intelligence-Empowered-Catalyst-Discovery.|https://doi.org/10.48550/arXiv.2502.13626|
|80|Collaborative Retrieval for Large Language Model-based Conversational   Recommender Systems|Yaochen Zhu, Chao Wan, Harald Steck, Dawen Liang, Yesu Feng, Nathan Kallus, Jundong Li|2025-02-19|OpenAlex|https://github.com/yaochenzhu/CRAG.|https://doi.org/10.48550/arXiv.2502.14137|
|81|Lost in Sequence: Do Large Language Models Understand Sequential   Recommendation?|Sein Kim, Hongseok Kang, Kibum Kim, Jiwan Kim, Donghyun Kim, Minchul Yang, Kwangjin Oh, Julian J. McAuley, Chanyoung Par...|2025-02-19|OpenAlex|https://github.com/Sein-Kim/LLM-SRec.|https://doi.org/10.48550/arXiv.2502.13909|
|82|On the logical skills of large language models: evaluations using   arbitrarily complex first-order logic problems|Shokhrukh Ibragimov, Arnulf Jentzen, Benno Kuckuck|2025-02-19|arXiv|https://github.com/bkuckuck/logical-skills-of-llms.|https://doi.org/10.48550/arXiv.2502.14180|
|83|PTQ1.61: Push the Real Limit of Extremely Low-Bit Post-Training   Quantization Methods for Large Language Models|Jiaqi Zhao, Miao Zhang, Ming Wang, Yuzhang Shang, Kaihao Zhang, Weili Guan, Yaowei Wang, Danshi Wang|2025-02-18|OpenAlex|https://github.com/zjq0455/PTQ1.61.|https://doi.org/10.18653/v1/2025.acl-long.225|
|84|SEA: Low-Resource Safety Alignment for Multimodal Large Language Models   via Synthetic Embeddings|Weikai Lu, Hao Peng, Huiping Zhuang, Cen Chen, Ziqian Zeng|2025-02-18|OpenAlex|https://github.com/ZeroNLP/SEA.|https://doi.org/10.18653/v1/2025.acl-long.1212|
|85|G-Refer: Graph Retrieval-Augmented Large Language Model for Explainable   Recommendation|Yuhan Li, Xinni Zhang, Linhao Luo, Heng Chang, Yuxiang Ren, Irwin King, Jia Li|2025-02-18|OpenAlex|https://github.com/Yuhan1i/G-Refer.|https://doi.org/10.48550/arXiv.2502.12586|
|86|Evaluation of Large Language Models for an AI Chat Assistant Focused on Pumas and Pharmacometrics|Juan Javier Gonz√°lez Barbosa, Agastya Vinchhi, Vijay Ivaturi|2025-02-18|OpenAlex|https://github.com/explodinggradients/ragas|https://doi.org/10.70534/jnza2834|
|87|Evaluation of ChatGPT and Gemini large language models for pharmacometrics with NONMEM|Euibeom Shin, Yifan Yu, Robert R. Bies, Murali Ramanathan|2025-02-18|Journal of Pharmacokinetics and Pharmacodynamics|https://github.com/metrumresearchgroup/mrgsolve20.|https://doi.org/10.21203/rs.3.rs-4189234/v1|
|88|$\mathttGeLLM^3O$: Generalizing Large Language Models for   Multi-property Molecule Optimization|Vishal Dey, Xiao Hu, Xia Ning|2025-02-18|arXiv (Cornell University)|https://github.com/ninglab/GeLLMO.|http://arxiv.org/abs/2502.13398|
|89|A Survey of Personalized Large Language Models: Progress and Future   Directions|Jiahong Liu, Zexuan Qiu, Zhongyang Li, Quanyu Dai, Jieming Zhu, Minda Hu, Menglin Yang, Irwin King|2025-02-17|arXiv|https://github.com/JiahongLiu21/Awesome-Personalized-Large-Language-Models.|https://doi.org/10.48550/arXiv.2502.11528|
|90|Idiosyncrasies in Large Language Models|Ming-Jie Sun, Yue Yin, Zeshui Xu, J. Zico Kolter, Zhuang Liu|2025-02-17|arXiv|https://github.com/locuslab/llm-idiosyncrasies.|https://doi.org/10.48550/arXiv.2502.12150|
|91|RIDE: Enhancing Large Language Model Alignment through Restyled   In-Context Learning Demonstration Exemplars|Yuncheng Hua, Lizhen Qu, Zhuang Li, Hao Xue, Flora D. Salim, Gholamreza Haffari|2025-02-17|arXiv|https://github.com/AnonymousCode-ComputerScience/RIDE.|https://doi.org/10.48550/arXiv.2502.11681|
|92|VRoPE: Rotary Position Embedding for Video Large Language Models|Zikang Liu, Longteng Guo, Yepeng Tang, Junxian Cai, Kai Ma, Xi Chen, Jing Liu|2025-02-17|arXiv|https://github.com/johncaged/VRoPE|https://doi.org/10.48550/arXiv.2502.11664|
|93|SURGE: On the Potential of Large Language Models as General-Purpose   Surrogate Code Executors|Bo Lyu, Susan S. Huang, Zhengzhao Liang|2025-02-16|arXiv|https://github.com/Imbernoulli/SURGE.|https://doi.org/10.48550/arXiv.2502.11167|
|94|Utilizing Pretrained Vision Transformers and Large Language Models for Epileptic Seizure Prediction|Paras Parani, Umair Mohammad, Fahad Saeed|2025-02-16|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/pcdslab/UtilLLM_EPS|https://doi.org/10.1109/cdma61895.2025.00028|
|95|Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical   Abilities in Large Language Models|Haoyang Li, Xuejia Chen, Zhanchao Xu, Darian Li, Nicole Hu, Fei Teng, Yiming Li, Luyu Qiu, Chen Jason Zhang, Qing Li, Le...|2025-02-16|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/TreeAI-Lab/NumericBench.|https://doi.org/10.18653/v1/2025.findings-acl.1026|
|96|Reasoning-Augmented Conversation for Multi-Turn Jailbreak Attacks on   Large Language Models|Zonghao Ying, Deyue Zhang, Zonglei Jing, Yisong Xiao, Quanchen Zou, Aishan Liu, Siyuan Liang, Xiangzheng Zhang, Xianglon...|2025-02-16|arXiv|https://github.com/NY1024/RACE|https://doi.org/10.48550/arXiv.2502.11054|
|97|CORDIAL: Can Multimodal Large Language Models Effectively Understand   Coherence Relationships?|Aashish Anantha Ramakrishnan, Aadarsh Anantha Ramakrishnan, Dongwon Lee|2025-02-16|OpenAlex|https://github.com/aashish2000/CORDIAL.|https://doi.org/10.18653/v1/2025.acl-long.1033|
|98|BoT: Breaking Long Thought Processes of o1-like Large Language Models   through Backdoor Attack|Zihao Zhu, Hongbao Zhang, Mingda Zhang, Ruotong Wang, Guanzong Wu, Ke Xu, Baoyuan Wu|2025-02-16|arXiv|https://github.com/zihao-ai/BoT|https://doi.org/10.48550/arXiv.2502.12202|
|99|LANTERN: Leveraging Large Language Models and Transformers for Enhanced Molecular Interactions|Cong Nga Ha, Phuong Viet Pham, Truong Son Hy|2025-02-15|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/HySonLab/LANTERN|https://doi.org/10.1101/2025.02.10.637522|
|100|Injecting Domain-Specific Knowledge into Large Language Models: A   Comprehensive Survey|Zhihua Song, Bin Yan, Yuhan Liu, Miao Fang, Mingzhe Li, Rui Yan, Xiuying Chen|2025-02-15|arXiv|https://github.com/abilliyb/Knowledge_Injection_Survey_Papers|https://doi.org/10.48550/arXiv.2502.10708|
|101|SQuARE: Sequential Question Answering Reasoning Engine for Enhanced   Chain-of-Thought in Large Language Models|Daniel Fleischer, Moshe Berchansky, George Markovits, Moshe Wasserblat|2025-02-13|arXiv|https://github.com/IntelLabs/RAG-FiT|https://doi.org/10.48550/arXiv.2502.09390|
|102|Data Augmentation to Improve Large Language Models in Food Hazard and   Product Detection|Areeg Fahad Rasheed, Mahdi Zarkoosh, Shimam Amer Chasib, Safa F. Abbas|2025-02-12|arXiv|https://github.com/AREEG94FAHAD/food-hazard-prdouct-cls|https://doi.org/10.48550/arXiv.2502.08687|
|103|Do Large Language Models have Spatial Cognitive Abilities?|Ruoling Wu, Danhuai Guo|2025-02-11|ACM Transactions on Intelligent Systems and Technology|https://github.com/LLING000/SCABenchmark|https://doi.org/10.1145/3716855|
|104|Large Language Models Meet Symbolic Provers for Logical Reasoning   Evaluation|Chengwen Qi, Ren Ma, Bowen Li, He Du, Binyuan Hui, Jinwang Wu, Yuanjun Laili, Conghui He|2025-02-10|ICLR|https://github.com/opendatalab/ProverGen|https://openreview.net/forum?id=C25SgeXWjE|
|105|Large Language Models in Software Security: A Survey of Vulnerability   Detection Techniques and Insights|Ze Sheng, Zhicheng Chen, Shanqiang Gu, Heqing Huang, Guofei Gu, Jeff Huang|2025-02-10|arXiv (Cornell University)|https://github.com/OwenSanzas/LLM-For-Vulnerability-Detection|http://arxiv.org/abs/2502.07049|
|106|DrugImproverGPT: A Large Language Model for Drug Optimization with   Fine-Tuning via Structured Policy Optimization|Xuefeng Liu, Songhao Jiang, Siyu Chen, Zhuoran Yang, Yuxin Chen, Ian T. Foster, Rick Stevens|2025-02-10|arXiv|https://github.com/xuefeng-cs/DrugImproverGPT.|https://doi.org/10.48550/arXiv.2502.07237|
|107|RALLRec: Improving Retrieval Augmented Large Language Model   Recommendation with Representation Learning|Jian Xu, Sichun Luo, Xiangyu Chen, Haifeng Huang, Hanxu Hou, Linqi Song|2025-02-09|OpenAlex|https://github.com/JianXu95/RALLRec.|https://doi.org/10.48550/arXiv.2502.06101|
|108|Top-DTI: Integrating Topological Deep Learning and Large Language Models for Drug Target Interaction Prediction|Muhammed Talo, Serdar Bozdag|2025-02-08|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/bozdaglab/Top_DTI|https://doi.org/10.1093/bioinformatics/btaf183|
|109|XiHeFusion: Harnessing Large Language Models for Science Communication   in Nuclear Fusion|Xiao Wang, Qingquan Yang, Fuling Wang, Qiang Chen, Wann‚ÄêYih Wu, Yu Jin, Jun Jiang, Liang Jin, Bo Jiang, Dengdi Sun, Wenz...|2025-02-08|arXiv|https://github.com/Event-AHU/XiHeFusion.|https://doi.org/10.48550/arXiv.2502.05615|
|110|Predicting Large Language Model Capabilities on Closed-Book QA Tasks   Using Only Information Available Prior to Training|Changhao Jiang, Ming Zhang, Junjie Ye, Xiaoran Fan, Yifei Cao, Jiajun Sun, Zhiheng Xi, Shihan Dou, Yi Dong, Yujiong Shen...|2025-02-06|arXiv|https://github.com/yuhui1038/SMI.|https://doi.org/10.48550/arXiv.2502.04066|
|111|Intent Representation Learning with Large Language Model for   Recommendation|Yu Wang, Lei Sang, Yi Zhang, Yiwen Zhang|2025-02-05|Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval|https://github.com/wangyu0627/IRLLRec.|https://doi.org/10.1145/3726302.3730011|
|112|Knowledge Distillation from Large Language Models for Household Energy   Modeling|Mohannad Takrouri, Nicolas Mauricio Cuadrado, Martin Tak√°ƒç|2025-02-05|arXiv|https://github.com/Singularity-AI-Lab/LLM-Energy-Knowledge-Distillation|https://doi.org/10.48550/arXiv.2502.03034|
|113|Reinforced Prompt Personalization for Recommendation with Large Language Models|Wenyu Mao, Jiancan Wu, Weijian Chen, Chongming Gao, Xiang Wang, Xiangnan He|2025-02-04|ACM transactions on office information systems|https://github.com/maowenyu-11/RPP|https://doi.org/10.48550/arXiv.2407.17115|
|114|Risk-Aware Driving Scenario Analysis with Large Language Models|Y. S. Gao, Mattia Piccinini, Johannes Betz|2025-02-04|arXiv|https://github.com/yuangao-tum/Riskaware-Scenario-analyse|https://doi.org/10.48550/arXiv.2502.02145|
|115|SAISA: Towards Multimodal Large Language Models with Both Training and   Inference Efficiency|Qianhao Yuan, Yanjiang Liu, Yaojie Lu, Hongyu Lin, Ben He, Xianpei Han, Le Sun|2025-02-04|arXiv|https://github.com/icip-cas/SAISA.|https://doi.org/10.48550/arXiv.2502.02458|
|116|sciLaMA: A Single-Cell Representation Learning Framework to Leverage Prior Knowledge from Large Language Models|Hongru Hu, Shuwen Zhang, Yongin Choi, Venkat S. Malladi, Gerald Quon|2025-02-03|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/microsoft/sciLaMA.|https://doi.org/10.1101/2025.01.28.635153|
|117|Breaking Focus: Contextual Distraction Curse in Large Language Models|Yue Huang, Yanbo Wang, Zixiang Xu, Chujie Gao, Siyuan Wu, Jiayi Ye, Xiuying Chen, Pin-Yu Chen, Xiangliang Zhang|2025-02-03|arXiv|https://github.com/wyf23187/LLM_CDV.|https://doi.org/10.48550/arXiv.2502.01609|
|118|AtmosSci-Bench: Evaluating the Recent Advance of Large Language Model   for Atmospheric Science|Chenyue Li, Wen Deng, Mengqian Lu, Binhang Yuan|2025-02-03|arXiv|https://github.com/Relaxed-System-Lab/AtmosSci-Bench.|https://doi.org/10.48550/arXiv.2502.01159|
|119|AdaSVD: Adaptive Singular Value Decomposition for Large Language Models|Zhiteng Li, Mingyuan Xia, Jingyuan Zhang, Hui Zheng, Linghe Kong, Yulun Zhang, Xiaokang Yang|2025-02-03|arXiv|https://github.com/ZHITENGLI/AdaSVD.|https://doi.org/10.48550/arXiv.2502.01403|
|120|Robust-LLaVA: On the Effectiveness of Large-Scale Robust Image Encoders   for Multi-modal Large Language Models|Hashmat Shadab Malik, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar, Fahad Shahbaz Khan, Salman Khan|2025-02-03|arXiv|https://github.com/HashmatShadab/Robust-LLaVA.|https://doi.org/10.48550/arXiv.2502.01576|
|121|Speculative Ensemble: Fast Large Language Model Ensemble via Speculation|Jiale Fu, Yuchu Jiang, Junkai Chen, Jiaming Fan, Peng Geng, Yang Xu|2025-02-01|arXiv|https://github.com/Kamichanw/Speculative-Ensemble|https://doi.org/10.48550/arXiv.2502.01662|
|122|MetaOpenFOAM 2.0: Large Language Model Driven Chain of Thought for   Automating CFD Simulation and Post-Processing|Yuxuan Chen, Xu Zhu, Hua Zhou, Zhuyin Ren|2025-02-01|arXiv|https://github.com/Terry-cyx/MetaOpenFOAM|https://doi.org/10.48550/arXiv.2502.00498|
|123|LIBRA: Measuring Bias of Large Language Model from a Local Context|B. Y. Pang, Tingrui Qiao, Caroline Walker, Chris Cunningham, Yun Sing Koh|2025-02-01|Lecture notes in computer science|https://github.com/ipangbo/LIBRA.|https://doi.org/10.1007/978-3-031-88708-6_1|
|124|LLMDet: Learning Strong Open-Vocabulary Object Detectors under the   Supervision of Large Language Models|Shenghao Fu, Qize Yang, Qijie Mo, Junkai Yan, Xihan Wei, Jingke Meng, Xiaohua Xie, Wei-Shi Zheng|2025-01-31|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/iSEE-Laboratory/LLMDet.|https://openaccess.thecvf.com/content/CVPR2025/html/Fu_LLMDet_Learning_Strong_Open-Vocabulary_Object_Detectors_under_the_Supervision_of_CVPR_2025_paper.html|
|125|Panacea: Mitigating Harmful Fine-tuning for Large Language Models via   Post-fine-tuning Perturbation|Yibo Wang, Tiansheng Huang, Li Shen, Huanjin Yao, Haotian Luo, Rui Liu, Naiqiang Tan, Jiaxing Huang, Dacheng Tao|2025-01-29|arXiv|https://github.com/w-yibo/Panacea|https://doi.org/10.48550/arXiv.2501.18100|
|126|Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing   Guardrail Moderation|Tiansheng Huang, Sihao Hu, Fatih ƒ∞lhan, Selim Furkan Tekin, Ling Liu|2025-01-29|arXiv|https://github.com/git-disl/Virus|https://doi.org/10.48550/arXiv.2501.17433|
|127|SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of   Large Language Model|Xun Liang, Simin Niu, Zhiyu Li, Sensen Zhang, Hanyu Wang, Feiyu Xiong, Jianqing Fan, Bo Tang, Shichao Song, Mengwei Wang...|2025-01-28|OpenAlex|https://github.com/IAAR-Shanghai/SafeRAG.|https://doi.org/10.18653/v1/2025.acl-long.230|
|128|Large Language Model Critics for Execution-Free Evaluation of Code   Changes|Aashish Yadavally, Hoan Anh Nguyen, Laurent Callot, Gauthier Guinet|2025-01-27|arXiv|https://github.com/amazon-science/code-agent-eval.|https://doi.org/10.48550/arXiv.2501.16655|
|129|Analyzing and Boosting the Power of Fine-Grained Visual Recognition for   Multi-modal Large Language Models|Hulingxiao He, Geng Li, Zengmin Geng, Jinglin Xu, Yuxin Peng|2025-01-25|ICLR|https://github.com/PKU-ICST-MIPL/Finedefics_ICLR2025.|https://openreview.net/forum?id=p3NKpom1VL|
|130|JustLogic: A Comprehensive Benchmark for Evaluating Deductive Reasoning   in Large Language Models|Michael K. Chen, Xikun Zhang, Dacheng Tao|2025-01-24|arXiv|https://github.com/michaelchen-lab/JustLogic|https://doi.org/10.48550/arXiv.2501.14851|
|131|OstQuant: Refining Large Language Model Quantization with Orthogonal and   Scaling Transformations for Better Distribution Fitting|Xing Hu, Yuan Cheng, Dawei Yang, Zhixuan Chen, Zukang Xu, Jiangyong Yu, Chen Xu, Zhihang Yuan, Zhe Jiang, Sifan Zhou|2025-01-23|ICLR|https://github.com/BrotherHappy/OSTQuant|https://openreview.net/forum?id=rAcgDBdKnP|
|132|Softplus Attention with Re-weighting Boosts Length Extrapolation in   Large Language Models|Bo Gao, Michael W. Spratling|2025-01-23|arXiv|https://github.com/iminfine/freeatten.|https://doi.org/10.48550/arXiv.2501.13428|
|133|Can Large Language Models Understand Preferences in Personalized   Recommendation?|Zhaoxuan Tan, Zinan Zeng, Qingkai Zeng, Zhenyu Wu, Zheyuan Liu, Fengran Mo, Meng Jiang|2025-01-23|arXiv|https://github.com/TamSiuhin/PerRecBench|https://doi.org/10.48550/arXiv.2501.13391|
|134|An Empirical Characterization of Outages and Incidents in Public   Services for Large Language Models|Xiaoyu Chu, Sacheendra Talluri, Qingxian Lu, Alexandru Iosup|2025-01-21|OpenAlex|https://github.com/atlarge-research/llm-service-analysis.|https://doi.org/10.48550/arXiv.2501.12469|
|135|Can open source large language models be used for tumor documentation in Germany? - An evaluation on urological doctors&apos; notes|Stefan Lenz, Arsenij Ustjanzew, Marco Jeray, Meike Ressing, Torsten Panholzer|2025-01-21|BioData Mining|https://github.com/stefan-m-lenz/UroLlmEval.|https://doi.org/10.1186/s13040-025-00463-8|
|136|Distillation Quantification for Large Language Models|Sunbowen Lee, Junting Zhou, Chang Ao, Kaige Li, Xinrun Du, Sirui He, Jiaheng Liu, Min Yang, Zhoufutu Wen, Shiwen Ni|2025-01-21|arXiv|https://github.com/Aegis1863/LLMs-Distillation-Quantification.|https://doi.org/10.48550/arXiv.2501.12619|
|137|ESCARGOT: An AI Agent Leveraging Large Language Models, Dynamic Graph of Thoughts, and Biomedical Knowledge Graphs for Enhanced Reasoning|Nicholas Matsumoto, Hyun‚ÄêJun Choi, Jay Moran, Miguel Hernandez, Mythreye Venkatesan, Xi Li, Jui-Hsuan Chang, Paul P. Wan...|2025-01-20|Bioinformatics|https://github.com/EpistasisLab/ESCARGOT.|https://doi.org/10.1093/bioinformatics/btaf031|
|138|InsQABench: Benchmarking Chinese Insurance Domain Question Answering   with Large Language Models|Jing Ding, Feng Kai, Binbin Lin, J. G. Cai, Qiushi Wang, Y. G. Xie, Xiaojin Zhang, Zhongyu Wei, Wei Chen|2025-01-18|arXiv|https://github.com/HaileyFamo/InsQABench.git.|https://doi.org/10.48550/arXiv.2501.10943|
|139|CXR-LLaVA: a multimodal large language model for interpreting chest X-ray images|Seowoo Lee, M. D., Jiwon Youn, Mansu Kim D., Soon Ho Yoon, M. D. D|2025-01-15|European Radiology|https://github.com/ECOFRI/CXR_LLAVA.|https://doi.org/10.1007/s00330-024-11339-6|
|140|PokerBench: Training Large Language Models to become Professional Poker   Players|Richard Zhuang, Akshat Gupta, Chunhui Yang, Aniket Rahane, Zhengyu Li, Gopala Anumanchipalli|2025-01-14|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/pokerllm/pokerbench|https://doi.org/10.1609/aaai.v39i24.34814|
|141|LLM4SR: A Survey on Large Language Models for Scientific Research|Zhongling Luo, Zonglin Yang, Zheng Xu, Wei Yang, Xinya Du|2025-01-08|arXiv|https://github.com/du-nlp-lab/LLM4SR|https://doi.org/10.48550/arXiv.2501.04306|
|142|Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of   Large Language Models|Qianchen Ren, Jie Zeng, Qianyu He, Jiaqing Liang, Yanghua Xiao, Weikang Zhou, Z. J. Sun, F. Richard Yu|2025-01-08|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/Rainier-rq/FollowSoftConstraints.|https://doi.org/10.18653/v1/2025.findings-acl.1004|
|143|ChronoSense: Exploring Temporal Understanding in Large Language Models   with Time Intervals of Events|Duygu Sezen Islakoglu, Jan-Christoph Kalo|2025-01-06|OpenAlex|https://github.com/duyguislakoglu/chronosense.|https://doi.org/10.18653/v1/2025.acl-short.46|
|144|Visual Large Language Models for Generalized and Specialized   Applications|Yifan Li, Zhixin Lai, Wentao Bao, Zhen Tan, Anh Dao, Kewei Sui, Jiayi Shen, Dong Liu, Huan Liu, Yu Kong|2025-01-06|arXiv|https://github.com/JackYFL/awesome-VLLMs.|https://doi.org/10.48550/arXiv.2501.02765|
|145|Cold-Start Recommendation towards the Era of Large Language Models   (LLMs): A Comprehensive Survey and Roadmap|Wei Zhang, Yuanchen Bei, Liangwei Yang, Henry Peng Zou, Peilin Zhou, Aiwei Liu, Yinghui Li, Liqiao Chen, Jian-Ling Wang,...|2025-01-03|arXiv|https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation.|https://doi.org/10.48550/arXiv.2501.01945|
|146|MIRAGE: Exploring How Large Language Models Perform in Complex Social   Interactive Environments|Cai Yin, Zhouhong Gu, Zhangxin Du, Zheyu Ye, Shaosheng Cao, Yiqian Xu, Hongwei Feng, Ping Chen|2025-01-03|OpenAlex|https://github.com/lime728/MIRAGE|https://doi.org/10.18653/v1/2025.acl-short.2|
|147|Aligning Large Language Models for Faithful Integrity Against Opposing   Argument|Yong Zhao, Yang Deng, See-Kiong Ng, Tat‚ÄêSeng Chua|2025-01-02|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/zhaoy777/AFICE.git|https://doi.org/10.1609/aaai.v39i26.34990|
|148|Neuro-Symbolic Artificial Intelligence: Towards Improving the Reasoning Abilities of Large Language Models|Xiao-Wen Yang, Jie-Jing Shao, Lan-Zhe Guo, Bo-Wen Zhang, Zhi Zhou, Lin-Han Jia, Wang-Zhou Dai, Yufeng Li|2025-01-01|OpenAlex|https://github.com/LAMDASZ-ML/Awesome-LLM-Reasoning-with-NeSy.|https://doi.org/10.48550/arXiv.2508.13678|
|149|PointLLM-V2: Empowering Large Language Models to Better Understand Point Clouds|Runsen Xu, Shuai Yang, Xiaolong Wang, Tai Wang, Yilun Chen, Jiangmiao Pang, Dahua Lin|2025-01-01|IEEE Transactions on Pattern Analysis and Machine Intelligence|https://github.com/OpenRobotLab/PointLLM.|https://doi.org/10.1007/978-3-031-72698-9_8|
|150|PIP: Perturbation-based Iterative Pruning for Large Language Models|Yi Cao, Wei-Jie Xu, Yucheng Shen, Weijie Shi, Chi-Min Chan, Jiajie Xu|2025-01-01|arXiv|https://github.com/caoyiiiiii/PIP.|https://doi.org/10.48550/arXiv.2501.15278|
|151|Neuron based Personality Trait Induction in Large Language Models|Jia Deng, Tianyi Tang, Yanbin Yin, Wenhao Yang, Wayne Xin Zhao, Ji-Rong Wen|2025-01-01|ICLR|https://github.com/RUCAIBox/NPTI.|https://openreview.net/forum?id=LYHEY783Np|
|152|Mat-Instructions: A Large-Scale Inorganic Material Instruction Dataset for Large Language Models|Peng Liu, Shangde Gao, Yongqing Fu, Xiaoliang Wu, Stephen Tong, Ajitha Rajan, Hao Xu|2025-01-01|OpenAlex|https://github.com/zjuKeLiu/Mat-Instructions|https://doi.org/10.24963/ijcai.2025/1089|
|153|Multi-Agent Systems Powered by Large Language Models: Applications in Swarm Intelligence|Cristian Jimenez-Romero, Alper Yegenoglu, Christian Blum|2025-01-01|Frontiers in Artificial Intelligence|https://github.com/crjimene/swarm_gpt|https://doi.org/10.48550/arXiv.2503.03800|
|154|Medical Graph RAG: Evidence-based Medical Large Language Model via Graph Retrieval-Augmented Generation|Junde Wu, Jiayuan Zhu, Yunli Qi, Jingkun Chen, Min Xu, Filippo Menolascina, Yueming Jin, Vicente Grau|2025-01-01|OpenAlex|https://github.com/MedicineToken/Medical-Graph-RAG|https://doi.org/10.18653/v1/2025.acl-long.1381|
|155|QuickLLaMA: Query-aware Inference Acceleration for Large Language Models|Jingyao Li, Han Shi, Sitong Wu, Chuanyang Zheng, Zhenguo Li, Xin Jiang, Hong Xu, Jiaya Jia|2025-01-01|COLING|https://github.com/dvlab-research/Q-LLM.|https://aclanthology.org/2025.coling-main.34/|
|156|M4Bench: A Benchmark of Multi-domain Multi-granularity Multi-image Understanding for Multi-modal Large Language Models|Xiaojun Ye, Guanbao Liang, Chun Wang, Liangcheng Li, Pengfei Ke, Rui Wang, Bingxin Jia, Gang Huang, Qiao Sun, Sheng Zhou|2025-01-01|OpenAlex|https://github.com/eaglelab-zju/M4Bench.|https://doi.org/10.24963/ijcai.2025/762|
|157|Leveraging Large Language Models for Predictive Analysis of Human Misery|Bishanka Seal, Rahul Seetharaman, Aman Bansal, Abhilash Nandy|2025-01-01|arXiv|https://github.com/abhi1nandy2/Misery_Data_Exps_GitHub|https://doi.org/10.48550/arXiv.2508.12669|
|158|Large language models open new way of AI-assisted molecule design for chemists|Shoichi Ishida, Tomohiro Sato, Teruki Honma, Kei Terayama|2025-01-01|Journal of Cheminformatics|https://github.com/molecule-generator-collection/ChatChemTS.|https://doi.org/10.26434/chemrxiv-2024-1p82f|
|159|Labels Generated by Large Language Model Helps Measuring People&apos;s Empathy in Vitro|Md. Rakibul Hasan, Yue Yao, Md. Zakir Hossain, Aneesh Krishna, Imre J. Rudas, Shafin Rahman, Tom Gedeon|2025-01-01|arXiv|https://github.com/hasan-rakibul/LLMPathy|https://doi.org/10.48550/arXiv.2501.00691|
|160|Predicting differentially methylated cytosines in TET and DNMT3 knockout mutants via a large language model|Stefano Lonardi, Stefano Lonardi|2025-01-01|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/ucrbioinfo/dmc_prediction.|https://doi.org/10.1101/2024.05.02.592257|
|161|Reliable Academic Conference Question Answering: A Study Based on Large Language Model|Zhiwei Huang, Long Jin, Junjie Wang, Mingchen Tu, Hua Yin, Zhiqiang Liu, Jiawei Meng, Huajun Chen, Wen Zhang|2025-01-01|Communications in computer and information science|https://github.com/zjukg/ConferenceQA.|https://doi.org/10.1007/978-981-96-1809-5_14|
|162|REEF: Representation Encoding Fingerprints for Large Language Models|Jie Zhang, Dongrui Liu, Chen Qian, Linfeng Zhang, Yong Liu, Yu Qiao, Jing Shao|2025-01-01|ICLR|https://github.com/tmylla/REEF.|https://openreview.net/forum?id=SnDmPkOJ0T|
|163|ReLearn: Unlearning via Learning for Large Language Models|Haoming Xu, Ningyuan Zhao, Liming Yang, Sendong Zhao, Shumin Deng, Mengru Wang, Bryan Hooi, Nay Oo, Huajun Chen, Ningyu ...|2025-01-01|OpenAlex|https://github.com/zjunlp/unlearn.|https://doi.org/10.18653/v1/2025.acl-long.297|
|164|SCAR: Data Selection via Style Consistency-Aware Response Ranking for Efficient Instruction-Tuning of Large Language Models|Zhuang Li, Yuncheng Hua, Thuy-Trang Vu, Haolan Zhan, Lizhen Qu, Gholamreza Haffari|2025-01-01|OpenAlex|https://github.com/zhuang-li/SCAR|https://doi.org/10.18653/v1/2025.acl-long.625|
|165|SPRI: Aligning Large Language Models with Context-Situated Principles|Hongli Zhan, Muneeza Azmat, Raya Horesh, Junyi Jessy Li, Mikhail Yurochkin|2025-01-01|arXiv|https://github.com/honglizhan/SPRI-public.|https://doi.org/10.48550/arXiv.2502.03397|
|166|STLSP: Integrating Structure and Text with Large Language Models for Link Sign Prediction of Networks|Lijia Ma, Haoyang Fu, Zhijie Cao, Xiongnan Jin, Qiuzhen Lin, Jianqiang Li|2025-01-01|OpenAlex|https://github.com/sss483/STLSP.|https://doi.org/10.24963/ijcai.2025/354|
|167|Systematic Outliers in Large Language Models|Yongqi An, Xu Zhao, Tao Yu, Ming Tang, Jinqiao Wang|2025-01-01|ICLR|https://github.com/an-yongqi/systematic-outliers.|https://openreview.net/forum?id=rLX7Vyyzus|
|168|Taming Unleashed Large Language Models With Blockchain for Massive Personalized Reliable Healthcare|Lianshan Sun, Diandong Liu, Maoxue Wang, Yongyi Han, Yanqing Zhang, Biwei Zhou, Yi Ren, Peng zhu|2025-01-01|IEEE Journal of Biomedical and Health Informatics|https://github.com/LDDLQ/ChatCBD.|https://doi.org/10.1109/JBHI.2025.3528526|
|169|Toward Reliable Biomedical Hypothesis Generation: Evaluating Truthfulness and Hallucination in Large Language Models|Guangzhi Xiong, Eric Xie, Corey Williams, Myles Kim, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhan...|2025-01-01|OpenAlex|https://github.com/Teddy-XiongGZ/TruthHypo.|https://doi.org/10.48550/arXiv.2505.14599|
|170|TypedThinker: Diversify Large Language Model Reasoning with Typed Thinking|Danqing Wang, Jianxin Ma, Fei Fang, Lei Li|2025-01-01|ICLR|https://github.com/dqwang122/ThinkHub.|https://openreview.net/forum?id=VIUisLx8lQ|
|171|User Behavior Simulation with Large Language Model-based Agents for Recommender Systems|Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Hao Sun, Ruihua Song, Xin...|2025-01-01|ACM transactions on office information systems|https://github.com/RUC-GSAI/YuLan-Rec|https://doi.org/10.1145/3708985|
|172|Veracity-Oriented Context-Aware Large Language Models-Based Prompting Optimization for Fake News Detection|Weiqiang Jin, Yang Gao, Tao Tao, Xiujun Wang, Ningwei Wang, Baohai Wu, Biao Zhao|2025-01-01|International Journal of Intelligent Systems|https://github.com/albert-jin/CAPE-FND|https://doi.org/10.1155/int/5920142|
|173|VirNucPro: an identifier for the identification of viral short sequences using six-frame translation and large language models|Jing Li, Jia Mi, Wei Lin, Fengjuan Tian, Jing Wan, Jingyang Gao, Yigang Tong|2025-01-01|Briefings in Bioinformatics|https://github.com/Li-Jing-1997/VirNucPro.|https://doi.org/10.1093/bib/bbaf224|
|174|WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct|Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jian-Guang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, Yanson...|2025-01-01|ICLR|https://github.com/nlpxucan/WizardLM|https://openreview.net/forum?id=mMPMHWOdOy|
|175|LLM Reading Tea Leaves: Automatically Evaluating Topic Models with Large Language Models|Xiaohao Yang, He Zhao, Dinh Q. Phung, Wray L. Buntine, Lan Du|2025-01-01|Transactions of the Association for Computational Linguistics|https://github.com/Xiaohao-Yang/Topic_Model_Evaluation.|https://doi.org/10.48550/arXiv.2406.09008|
|176|LMCBert: An Automatic Academic Paper Rating Model Based on Large Language Models and Contrastive Learning|Chuanbin Liu, Xiaowu Zhang, Hongfei Zhao, Zhijie Liu, Xi Xi, Lean Yu|2025-01-01|IEEE Transactions on Cybernetics|https://github.com/iioSnail/LMCBert.|https://doi.org/10.1109/TCYB.2025.3550203|
|177|Pipeline to explore information on genome editing using large language models and genome editing meta-database|Takayuki Suzuki, Hidemasa Bono|2025-01-01|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/szktkyk/extract_geinfo|https://doi.org/10.1101/2024.10.16.617154|
|178|Knowledge-Driven Feature Selection and Engineering for Genotype Data with Large Language Models|Joseph Lee, Shuhua Yang, Jae Young Baik, Xiaoxi Liu, Zhen Tan, Dawei Li, Zixuan Wen, Bojian Hou, Duy Duong‚ÄêTran, Tianlon...|2025-01-01|arXiv (Cornell University)|https://github.com/PennShenLab/FREEFORM.|http://arxiv.org/abs/2410.01795|
|179|An Empirical Analysis of Uncertainty in Large Language Model Evaluations|Qiujie Xie, Qingqiu Li, Zhuohao Yu, Yuejie Zhang, Yue Zhang, Linyi Yang|2025-01-01|ICLR|https://github.com/hasakiXie123/LLM-Evaluator-Uncertainty.|https://openreview.net/forum?id=J4xLuCt2kg|
|180|Causal Intervention Is What Large Language Models Need for Spatio-Temporal Forecasting|Shijie Li, He Li, Xiaojing Li, Yong Xu, Zhenhong Lin, Huaiguang Jiang|2025-01-01|IEEE Transactions on Cybernetics|https://github.com/lishijie15/STCInterLLM.|https://doi.org/10.1109/TCYB.2025.3569333|
|181|CFBenchmark-MM: Chinese Financial Assistant Benchmark for Multimodal Large Language Model|Lei Yang, Jiangtong Li, Ming Jiang, Junjie Hu, Dawei Cheng, Zhijun Ding, Changjun Jiang|2025-01-01|arXiv|https://github.com/TongjiFinLab/CFBenchmark.|https://doi.org/10.48550/arXiv.2506.13055|
|182|CAPE: Context-Aware Personality Evaluation Framework for Large Language Models|Jivnesh Sandhan, Fei Cheng, Tushar Sandhan, Yugo Murawaki|2025-01-01|arXiv|https://github.com/jivnesh/CAPE|https://doi.org/10.48550/arXiv.2508.20385|
|183|CALM: Curiosity-Driven Auditing for Large Language Models|Xiaoyu Zheng, Longxiang Wang, Yi Liu, Xingjun Ma, Chao Shen, Cong Wang|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/x-zheng16/CALM.git.|https://doi.org/10.1609/aaai.v39i26.34991|
|184|Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?|Yifan Feng, Chengwu Yang, Xingliang Hou, Shaoyi Du, Shihui Ying, Zongze Wu, Yue Gao|2025-01-01|ICLR|https://github.com/iMoonLab/LLM4Hypergraph.|https://openreview.net/forum?id=28qOQwjuma|
|185|Benchmarking DNA large language models on quadruplexes|Oleksandr Cherednichenko, Alan Herbert, Maria Poptsova|2025-01-01|Computational and Structural Biotechnology Journal|https://github.com/powidla/G4s-FMs.|https://doi.org/10.1016/j.csbj.2025.03.007|
|186|Aligning, Autoencoding and Prompting Large Language Models for Novel Disease Reporting|Fenglin Liu, Xian Wu, Jinfa Huang, Bang Yang, Kim Branson, Patrick Schwab, Lei Clifton, Ping Zhang, Jiebo Luo, Yefeng Zh...|2025-01-01|IEEE Transactions on Pattern Analysis and Machine Intelligence|https://github.com/ai-in-health/PromptLLM.|https://doi.org/10.1109/tpami.2025.3534586|
|187|Comparing Bad Apples to Good Oranges: Aligning Large Language Models via   Joint Preference Optimization|Hritik Bansal, Ashima Suvarna, Gantavya Bhatt, Nanyun Peng, Kai-Wei Chang, Aditya Grover|2025-01-01|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/Hritikbansal/dove.|https://doi.org/10.18653/v1/2025.findings-acl.39|
|188|AgentGym: Evaluating and Training Large Language Model-based Agents across Diverse Environments|Zhiheng Xi, Yiwen Ding, Wen-Xiang Chen, Boyang Hong, Honglin Guo, Junzhe Wang, Xin Guo, Dingwen Yang, Chenyang Liao, He ...|2025-01-01|OpenAlex|https://github.com/WooooDyy/AgentGym.|https://doi.org/10.18653/v1/2025.acl-long.1355|
|189|Acoustic Prompt Tuning: Empowering Large Language Models with Audition Capabilities|Jinhua Liang, Xubo Liu, Wenwu Wang, Mark D. Plumbley, Huy P. Phan, Emmanouil Benetos|2025-01-01|IEEE Transactions on Audio Speech and Language Processing|https://github.com/JinhuaLiang/APT.|https://doi.org/10.1109/taslpro.2025.3533375|
|190|ARB-LLM: Alternating Refined Binarizations for Large Language Models|Zhiteng Li, Xianglong Yan, Tianao Zhang, Haotong Qin, Dong Xie, Jiang Tian, Zhongchao Shi, Linghe Kong, Yulun Zhang, Xia...|2025-01-01|ICLR|https://github.com/ZHITENGLI/ARB-LLM.|https://openreview.net/forum?id=ZU8OdDLTts|
|191|APEER: Automatic Prompt Engineering Enhances Large Language Model   Reranking|Can Jin, Hongwu Peng, Shiyu Zhao, Zhenting Wang, Wujiang Xu, Ligong Han, Jiahui Zhao, Kai Zhong, Sanguthevar Rajasekaran...|2025-01-01|arXiv|https://github.com/jincan333/APEER.|https://doi.org/10.48550/arXiv.2406.14449|
|192|Improving Efficiency of Answer Set Planning with Rough Solutions from Large Language Models for Robotic Task Planning|Xinrui Lin, Yangfan Wu, Huanyu Yang, Yuting Huang, Yu Zhang, Jianmin Ji, Yanyong Zhang|2025-01-01|OpenAlex|https://github.com/CLMASP/CLMASP.|https://doi.org/10.24963/ijcai.2025/509|
|193|A Closer Look at Machine Unlearning for Large Language Models|Xiaojian Yuan, Tianyu Pang, Chao Du, Kejiang Chen, Weiming Zhang, Min Lin|2025-01-01|ICLR|https://github.com/sail-sg/closer-look-LLM-unlearning.|https://openreview.net/forum?id=Q1MHvGmhyT|
|194|Comparative Analysis of Demonstration Selection Algorithms for In-Context Learning in Large Language Models (Student Abstract)|Dong Wook Shu, Mengnan Du|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/Tizzzzy/Demonstration_Selection_Overview.|https://doi.org/10.1609/aaai.v39i28.35299|
|195|PAT: Pruning-Aware Tuning for Large Language Models|Yijiang Liu, Huanrui Yang, Youxin Chen, Rongyu Zhang, Miao Wang, Yuan Du, Li Du|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/kriskrisliu/PAT_Pruning-Aware-Tuning|https://doi.org/10.1609/aaai.v39i23.34649|
|196|Cumulative Reasoning with Large Language Models|Yifan Zhang, Jingqin Yang, Yang Yuan, Andrew Chi-Chih Yao|2025-01-01|Trans. Mach. Learn. Res.|https://github.com/iiis-ai/cumulative-reasoning.|https://openreview.net/forum?id=grW15p4eq2|
|197|Evaluating the Prompt Steerability of Large Language Models|Erik Miehling, Michael Desmond, Karthikeyan Natesan Ramamurthy, Elizabeth Daly, Kush R. Varshney, Eitan Farchi, Pierre D...|2025-01-01|OpenAlex|https://github.com/IBM/prompt-steering.|https://doi.org/10.18653/v1/2025.naacl-long.400|
|198|Harnessing Multi-modal Large Language Models for Measuring and Interpreting Color Differences|Zhihua Wang, Long Yu, Qiuping Jiang, Chao Huang, Xiaochun Cao|2025-01-01|IEEE Transactions on Image Processing|https://github.com/LongYu-LY/CD-Reasoning.|https://doi.org/10.1109/tip.2024.3522802|
|199|DesignQA: A Multimodal Benchmark for Evaluating Large Language Models&apos; Understanding of Engineering Do cumentation|Anna C. Doris, Daniele Grandi, Ryan Tomich, Md Ferdous Alam, Mohammadmehdi Ataei, Hyunmin Cheong, Faez Ahmed|2025-01-01|Journal of Computing and Information Science in Engineering|https://github.com/anniedoris/design_qa|https://doi.org/10.48550/arXiv.2404.07917|
|200|GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest|Shilong Zhang, Peize Sun, Shoufa Chen, Min Xiao, Wenqi Shao, Wenwei Zhang, Yu Liu, Kai Chen, Ping Luo|2025-01-01|Lecture notes in computer science|https://github.com/jshilong/GPT4RoI.|https://doi.org/10.1007/978-3-031-91813-1_4|
|201|From continuous pre-training to alignment: A comprehensive toolkit for large language models in federated learning|Zhuo Zhang, Yukun Zhang, Guanzhong Chen, Lizhen Qu, Xun Zhou, Hui Wang, Zenglin Xu|2025-01-01|Neurocomputing|https://github.com/iezhuozhuo/f4llm.|https://doi.org/10.1016/j.neucom.2025.130572|
|202|FreqLLM: Frequency-Aware Large Language Models for Time Series Forecasting|Shunnan Wang, Min Gao, Zongwei Wang, Yibing Bai, Feng Jiang, Guansong Pang|2025-01-01|OpenAlex|https://github.com/biya0105/FreqLLM.|https://doi.org/10.24963/ijcai.2025/377|
|203|Exploring Concept Depth: How Large Language Models Acquire Knowledge and Concept at Different Layers?|Mingyu Jin, Qinkai Yu, Jingyuan Huang, Qingcheng Zeng, Zhenting Wang, Wenyue Hua, Haiyan Zhao, Kai Mei, Yanda Meng, Kaiz...|2025-01-01|COLING|https://github.com/Luckfort/CD|https://aclanthology.org/2025.coling-main.37/|
|204|How Can Recommender Systems Benefit from Large Language Models: A Survey|Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Hao Zhang, Yong Liu, Chuhan Wu, Xiangyang Li, Chenxu Zhu, Huife...|2025-01-01|ACM transactions on office information systems|https://github.com/CHIANGEL/Awesome-LLM-for-RecSys|https://doi.org/10.48550/arXiv.2306.05817|
|205|Evaluating and Mitigating Linguistic Discrimination in Large Language Models: Perspectives on Safety Equity and Knowledge Equity|Guoliang Dong, Haoyu Wang, Jun Sun, Xinyu Wang|2025-01-01|OpenAlex|https://github.com/dgl-prc/ldfighter|https://doi.org/10.24963/ijcai.2025/40|
|206|Enhancing Large Language Models for Hardware Verification: A Novel SystemVerilog Assertion Dataset|Anand Menon, Samit S. Miftah, Shamik Kundu, Souvik Kundu, Amisha Srivastava, Arnab Raha, Gabriel Theodor Sonnenschein, S...|2025-01-01|ACM Transactions on Design Automation of Electronic Systems|https://github.com/AnandMenon12/VERT.|https://doi.org/10.48550/arXiv.2503.08923|
|207|Do Large Language Model Benchmarks Test Reliability?|Joshua Vendrow, Edward Vendrow, Sara Beery, Aleksander Madry|2025-01-01|arXiv|https://github.com/MadryLab/platinum-benchmarks|https://doi.org/10.48550/arXiv.2502.03461|
|208|Disentangling Memory and Reasoning Ability in Large Language Models|Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang|2025-01-01|OpenAlex|https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning.|https://doi.org/10.18653/v1/2025.acl-long.84|
|209|Enhancing Herbal Medicine-Drug Interaction Prediction Using Large Language Models|Sisi Yuan, Zhecheng Zhou, Xinyuan Jin, Linlin Zhuo, Keqin Li|2025-01-01|IEEE Journal of Biomedical and Health Informatics|https://github.com/sisyyuan/HDI.|https://doi.org/10.1109/jbhi.2025.3558667|
|210|Dual Adapter Tuning of Vision-Language Models Using Large Language Models|Mohammad Reza Zarei, Abbas Akkasi, Majid Komeili|2025-01-01|International Journal of Computational Intelligence Systems|https://github.com/mrzarei5/DATViL.|https://doi.org/10.1007/s44196-025-00853-0|
|211|MentalQLM: A lightweight large language model for mental healthcare based on instruction tuning and dual LoRA modules|Jiayu Shi, Zexiao Wang, Jiandong Zhou, Chengyu Liu, Poly Z. H. Sun, Erying Zhao, Lei L√º|2024-12-30|IEEE Journal of Biomedical and Health Informatics|https://github.com/tortorish/MentalQLM.|https://doi.org/10.1101/2024.12.29.24319755|
|212|A Survey on Large Language Model Acceleration based on KV Cache   Management|Haoyang Li, Yiming Li, Anxin Tian, Tianhao Tang, Zhanchao Xu, Xuejia Chen, Nicole Hu, Wei Dong, Qing Li, Lei Chen|2024-12-26|Trans. Mach. Learn. Res.|https://github.com/TreeAI-Lab/Awesome-KV-Cache-Management|https://openreview.net/forum?id=z3JZzu9EA3|
|213|An Engorgio Prompt Makes Large Language Model Babble on|Jianshuo Dong, Ziyuan Zhang, Qingjie Zhang, Hanxun Qiu, Tianwei Zhang, Hao Wang, Hewu Li, Qi Li, Chao Zhang, Ke Xu|2024-12-26|ICLR|https://github.com/jianshuod/Engorgio-prompt.|https://openreview.net/forum?id=m4eXBo0VNc|
|214|MLLM-SUL: Multimodal Large Language Model for Semantic Scene   Understanding and Localization in Traffic Scenarios|Jiaqi Fan, Jianhua Wu, Jincheng Gao, Jianhao Yu, Yafei Wang, Hongqing Chu, Bingzhao Gao|2024-12-26|arXiv (Cornell University)|https://github.com/fjq-tongji/MLLM-SUL.|http://arxiv.org/abs/2412.19406|
|215|Survey and Improvement Strategies for Gene Prioritization with Large Language Models|Matthew B. Neeley, Guantong Qi, Guanchao Wang, Ruixiang Tang, Dongxue Mao, Chaozhong Liu, Sasidhar Pasupuleti, Bo Yuan, ...|2024-12-26|Bioinformatics Advances|https://github.com/LiuzLab/GPT-Diagnosis.|https://doi.org/10.48550/arXiv.2501.18794|
|216|Task Preference Optimization: Improving Multimodal Large Language Models   with Vision Task Alignment|Ziang Yan, Zhilin Li, Yinan He, Chenting Wang, Kunchang Li, Xinhao Li, Xiangyu Zeng, Zhong Lin Wang, Yali Wang, Yu Qiao,...|2024-12-26|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/OpenGVLab/TPO|https://openaccess.thecvf.com/content/CVPR2025/html/Yan_Task_Preference_Optimization_Improving_Multimodal_Large_Language_Models_with_Vision_CVPR_2025_paper.html|
|217|3DGraphLLM: Combining Semantic Graphs and Large Language Models for 3D   Scene Understanding|Tatiana Zemskova, Dmitry Yudin|2024-12-24|arXiv (Cornell University)|https://github.com/CognitiveAISystems/3DGraphLLM.|http://arxiv.org/abs/2412.18450|
|218|ICM-Assistant: Instruction-tuning Multimodal Large Language Models for   Rule-based Explainable Image Content Moderation|Mengyang Wu, Yuzhi Zhao, Jialun Cao, Mingjie Xu, Zhongming Jiang, Xuehui Wang, Qinbin Li, Guangneng Hu, Shengchao Qin, C...|2024-12-24|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/zhaoyuzhi/ICM-Assistant.|https://doi.org/10.1609/aaai.v39i8.32908|
|219|Investigating Large Language Models for Code Vulnerability Detection: An   Experimental Study|Xuefeng Jiang, L. H. Wu, Sheng Sun, Jia Li, Jingjing Xue, Yuwei Wang, Tingting Wu, Min Liu|2024-12-24|arXiv (Cornell University)|https://github.com/SakiRinn/LLM4CVD|http://arxiv.org/abs/2412.18260|
|220|Large Language Model Safety: A Holistic Survey|Dan Shi, Tianhao Shen, Yufei Huang, Zhigen Li, Yongqi Leng, Renren Jin, Chuang Liu, Xinwei Wu, Zishan Guo, Linhao Yu, Li...|2024-12-23|arXiv (Cornell University)|https://github.com/tjunlp-lab/Awesome-LLM-Safety-Papers.|http://arxiv.org/abs/2412.17686|
|221|Property Enhanced Instruction Tuning for Multi-task Molecule Generation   with Large Language Models|Xuan Lin, Long Chen, Yile Wang, Xiangxiang Zeng, Philip S. Yu|2024-12-23|arXiv (Cornell University)|https://github.com/chenlong164/PEIT.|http://arxiv.org/abs/2412.18084|
|222|Large Language Model Can Be a Foundation for Hidden Rationale-Based   Retrieval|Luo Ji, Fulai Guo, Teng Chen, Qing Gu, Xiaoyu Wang, Ningyuan Xi, Yihong Wang, Peng Yu, Yue Zhao, Hongyang Lei, Zhonglin ...|2024-12-21|Lecture notes in computer science|https://github.com/flyfree5/LaHoRe.|https://doi.org/10.1007/978-3-031-88714-7_27|
|223|PruneVid: Visual Token Pruning for Efficient Video Large Language Models|Xiaohu Huang, Hao Zhou, K. L. Han|2024-12-20|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/Visual-AI/PruneVid.|https://doi.org/10.18653/v1/2025.findings-acl.1024|
|224|Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models   into Assembly Code Obfuscation|Seyedreza Mohseni, Seyedali Mohammadi, Deepa Tilwani, Yash Saxena, Gerald Ketu Ndawula, Sriram Vema, Edward Raff, Manas ...|2024-12-20|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/mohammadi-ali/MetamorphASM.|https://doi.org/10.1609/aaai.v39i23.34672|
|225|Mitigating Social Bias in Large Language Models: A Multi-Objective   Approach within a Multi-Agent Framework|Zhenjie Xu, Wenqing Chen, Yi Tang, Xuanying Li, Cheng Hu, Zhixuan Chu, Kui Ren, Zibin Zheng, Zhichao Lu|2024-12-19|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/Cortantse/MOMA.|https://doi.org/10.1609/aaai.v39i24.34748|
|226|Unveiling Uncertainty: A Deep Dive into Calibration and Performance of   Multimodal Large Language Models|Zijun Chen, Wenbo Hu, Guande He, Zhijie Deng, Zheng Zhang, Richang Hong|2024-12-19|COLING|https://github.com/hfutml/Calibration-MLLM|https://aclanthology.org/2025.coling-main.208/|
|227|Sliding Windows Are Not the End: Exploring Full Ranking with   Long-Context Large Language Models|Wenhan Liu, Xinyu Ma, Yutao Zhu, Ziliang Zhao, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou|2024-12-19|OpenAlex|https://github.com/8421BCD/fullrank|https://doi.org/10.18653/v1/2025.acl-long.8|
|228|InstructSeg: Unifying Instructed Visual Segmentation with Multi-modal   Large Language Models|Cong Wei, Yujie Zhong, Haoxian Tan, Yingsen Zeng, Yong Liu, Zheng Zhao, Yujiu Yang|2024-12-18|arXiv (Cornell University)|https://github.com/congvvc/InstructSeg.|http://arxiv.org/abs/2412.14006|
|229|ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain   Adaptation with an Astronomy Case Study|Eric Modesitt, Ke Yang, Spencer Hulsey, Xin Liu, ChengXiang Zhai, Volodymyr V. Kindratenko|2024-12-18|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/ModeEric/ORBIT-Llama|https://doi.org/10.18653/v1/2025.findings-acl.51|
|230|ResQ: Mixed-Precision Quantization of Large Language Models with   Low-Rank Residuals|Utkarsh Saxena, Sayeh Sharify, Kaushik Roy, Xin Wang|2024-12-18|arXiv (Cornell University)|https://github.com/utkarsh-dmx/project-resq.|http://arxiv.org/abs/2412.14363|
|231|DateLogicQA: Benchmarking Temporal Biases in Large Language Models|Gagan Bhatia, MingZe Tang, Cristina Mahanta, Madiha Kazi|2024-12-17|OpenAlex|https://github.com/gagan3012/EAIS-Temporal-Bias|https://doi.org/10.18653/v1/2025.naacl-srw.32|
|232|Assessing the Limitations of Large Language Models in Clinical Fact   Decomposition|Monica Munnangi, Akshay Swaminathan, Jason Fries, Jenelle Jindal, Sanjana Narayanan, Iv√°n L√≥pez, Lucia Tu, Philip Chung,...|2024-12-16|arXiv (Cornell University)|https://github.com/som-shahlab/factehr|http://arxiv.org/abs/2412.12422|
|233|BlenderLLM: Training Large Language Models for Computer-Aided Design   with Self-improvement|Yinwei Du, Shunian Chen, Wenbo Zan, Peizhao Li, Mingxuan Wang, Dongwoon Song, Bo Li, Yan Hu, Benyou Wang|2024-12-16|arXiv (Cornell University)|https://github.com/FreedomIntelligence/BlenderLLM|http://arxiv.org/abs/2412.14203|
|234|Can Large Language Models Understand You Better? An MBTI Personality   Detection Dataset Aligned with Population Traits|Bohan Li, J Guan, Longxu Dou, Yun‚ÄêLong Feng, Dingzirui Wang, Yang Xu, Enbo Wang, Qiguang Chen, Bichen Wang, Xiao Xu, Yim...|2024-12-16|COLING|https://github.com/Personality-NLP/MbtiBench.|https://aclanthology.org/2025.coling-main.339/|
|235|NLSR: Neuron-Level Safety Realignment of Large Language Models Against   Harmful Fine-Tuning|Xin Yi, Shunfan Zheng, Linlin Wang, Gerard de Melo, Xiaoling Wang, Liang He|2024-12-16|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/xinykou/NLSR|https://doi.org/10.1609/aaai.v39i24.34762|
|236|RetroLLM: Empowering Large Language Models to Retrieve Fine-grained   Evidence within Generation|Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yongkang Wu, Zhonghua Li, Qi Ye, Zhicheng Dou|2024-12-16|OpenAlex|https://github.com/sunnynexus/RetroLLM|https://doi.org/10.18653/v1/2025.acl-long.819|
|237|SPaR: Self-Play with Tree-Search Refinement to Improve   Instruction-Following in Large Language Models|Jiale Cheng, Xiao Liu, Cunxiang Wang, Xiaotao Gu, Yida Lu, Dan Zhang, Yuxiao Dong, Jie Tang, Hongning Wang, Minlie Huang|2024-12-16|ICLR|https://github.com/thu-coai/SPaR.|https://openreview.net/forum?id=9chRqsPOGL|
|238|A survey on LoRA of large language models|Yuren Mao, Yuhang Ge, Yijiang Fan, Wenyi Xu, Yu Mi, Zhonghao Hu, Yunjun Gao|2024-12-14|Frontiers of Computer Science|https://github.com/ZJU-LLMs/Awesome-LoRAs.git|https://doi.org/10.1007/s11704-024-40663-9|
|239|B-VLLM: A Vision Large Language Model with Balanced Spatio-Temporal   Tokens|Zhuqiang Lu, Zhenfei Yin, Meilin He, Zhihui Wang, Zicheng Liu, Zhiyong Wang, Kun Hu|2024-12-13|arXiv (Cornell University)|https://github.com/zhuqiangLu/B-VLLM.|http://arxiv.org/abs/2412.09919|
|240|Simulate Scientific Reasoning with Multiple Large Language Models: An Application to Alzheimer‚Äôs Disease Combinatorial Therapy|Qidi Xu, Xiaozhong Liu, Xiaoqian Jiang, Yejin Kim|2024-12-12|medRxiv (Cold Spring Harbor Laboratory)|https://github.com/QidiXu96/Coated-LLM|https://doi.org/10.1101/2024.12.10.24318800|
|241|Filter-then-Generate: Large Language Models with Structure-Text Adapter   for Knowledge Graph Completion|Ben Liu, Jihai Zhang, Fangquan Lin, Cheng Yang, Min Peng|2024-12-12|COLING|https://github.com/LB0828/FtG|https://aclanthology.org/2025.coling-main.740/|
|242|Enhancing Multimodal Large Language Models Complex Reason via Similarity   Computation|Xiaofeng Zhang, Fanshuo Zeng, Yihao Quan, Zheng Hui, Jiawei Yao|2024-12-12|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/FanshuoZeng/Simignore|https://doi.org/10.1609/aaai.v39i10.33107|
|243|Towards a Multimodal Large Language Model with Pixel-Level Insight for   Biomedicine|Xiaoshuang Huang, Lingdong Shen, Jia Liu, Fangxin Shang, Hongxiang Li, Haifeng Huang, Yehui Yang|2024-12-12|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/ShawnHuang497/MedPLIB.|https://doi.org/10.1609/aaai.v39i4.32394|
|244|Exploiting the Index Gradients for Optimization-Based Jailbreaking on   Large Language Models|Jiahui Li, Yongchang Hao, Hanqiu Xu, Xing Wang, Yu Hong|2024-12-11|COLING|https://github.com/jiah-li/magic.|https://aclanthology.org/2025.coling-main.305/|
|245|IntellectSeeker: A Personalized Literature Management System with the   Probabilistic Model and Large Language Model|Weizhen Bian, Siyan Liu, Yubo Zhou, Dezhi Chen, Yijie Liao, Zhenzhen Fan, Aobo Wang|2024-12-10|Lecture notes in computer science|https://github.com/LuckyBian/ISY5001|https://doi.org/10.1007/978-981-97-5489-2_24|
|246|Concept Bottleneck Large Language Models|Chung-En Sun, Tuomas P. Oikarinen, Berk Ustun, Tsui-Wei Weng|2024-12-10|ICLR|https://github.com/Trustworthy-ML-Lab/CB-LLMs.|https://openreview.net/forum?id=RC5FPYVQaH|
|247|PediaBench: A Comprehensive Chinese Pediatric Dataset for Benchmarking   Large Language Models|Qian Zhang, Panfeng Chen, Jiali Li, Shuo Feng, Shuyu Liu, Mei Chen, Hui Li, Yanhao Wang|2024-12-09|arXiv (Cornell University)|https://github.com/ACMISLab/PediaBench.|http://arxiv.org/abs/2412.06287|
|248|KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models|Fan Wang, Jing-Jiang Jiang, C.Y. Park, Sunghun Kim, Jing Tang|2024-12-08|ICLR|https://github.com/juyongjiang/KaSA.|https://openreview.net/forum?id=OQqNieeivq|
|249|Mitigating Entity-Level Hallucination in Large Language Models|Weihang Su, Yichen Tang, Qingyao Ai, Changyue Wang, Zhijing Wu, Yiqun Liu|2024-12-08|OpenAlex|https://github.com/oneal2000/EntityHallucination.|https://doi.org/10.48550/arXiv.2407.09417|
|250|Fine-Grained Behavior Simulation with Role-Playing Large Language Model   on Social Media|Kun Li, C. H. Dai, Zhou We, Songlin Hu|2024-12-04|arXiv (Cornell University)|https://github.com/linkseed18612254945/FineRob|http://arxiv.org/abs/2412.03148|
|251|From Individual to Society: A Survey on Social Simulation Driven by   Large Language Model-based Agents|Xinyi Mou, Xuanwen Ding, Qi He, Liang Wang, Jingcong Liang, Xinnong Zhang, Libo Sun, Jiayu Lin, Jie Zhou, Xuanjing Huang...|2024-12-04|arXiv (Cornell University)|https://github.com/FudanDISC/SocialAgent|http://arxiv.org/abs/2412.03563|
|252|Improving Linguistic Diversity of Large Language Models with Possibility   Exploration Fine-Tuning|Long Mai, Julie Carson-Berndsen|2024-12-04|arXiv (Cornell University)|https://github.com/mailong25/peft_diversity|http://arxiv.org/abs/2412.03343|
|253|NJGPT: A Large Language Model-Driven, User-Friendly Solution for Phylogenetic Tree Construction|Zhixuan Wang, Haoyuan Huang, Teng Li, Allen G. Rodrigo|2024-12-04|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/ZWan622/NJGPT1.0.git|https://doi.org/10.1101/2024.12.02.626464|
|254|Beyond Labels: Aligning Large Language Models with Human-Like Reasoning|Muhammad Rafsan Kabir, Rafeed Mohammad Sultan, Ihsanul Haque Asif, Jason M. E. Ahad, Fuad Rahman, Mohammad Ruhul Amin, N...|2024-12-02|Lecture notes in computer science|https://github.com/apurba-nsu-rnd-lab/DFAR.|https://doi.org/10.1007/978-3-031-78172-8_16|
|255|Improving Automated Deep Phenotyping Through Large Language Models Using Retrieval Augmented Generation|Brandon T. Garcia, Lauren Westerfield, Priya Yelemali, Nikhita Gogate, Edgar A. Rivera‚ÄêMu√±oz, Haowei Du, Moez Dawood, An...|2024-12-02|medRxiv (Cold Spring Harbor Laboratory)|https://github.com/PoseyPod/RAG-HPO|https://doi.org/10.1101/2024.12.01.24318253|
|256|Dynamic-LLaVA: Efficient Multimodal Large Language Models via Dynamic   Vision-language Context Sparsification|Wenxuan Huang, Zijie Zhai, Yunhang Shen, Shaosheng Cao, Fei Zhao, Xiangfeng Xu, Zheyu Ye, Shaohui Lin|2024-12-01|arXiv|https://github.com/Osilly/dynamic_llava|https://openreview.net/forum?id=hzVpZDrW73|
|257|Woodpecker: hallucination correction for multimodal large language models|Shukang Yin, Chaoyou Fu, Sirui Zhao, Tong Bill Xu, Hao Wang, Dianbo Sui, Yunhang Shen, Ke Li, Xing Sun, Enhong Chen|2024-12-01|Science China Information Sciences|https://github.com/BradyFU/Woodpecker.|https://doi.org/10.1007/s11432-024-4251-x|
|258|Accelerating Multimodal Large Language Models via Dynamic Visual-Token   Exit and the Empirical Findings|Qiong Wu, Wei Lin, Weihao Ye, Yiyi Zhou, Xiaoshuai Sun, Rongrong Ji|2024-11-29|arXiv (Cornell University)|https://github.com/DoubtedSteam/DyVTE.|http://arxiv.org/abs/2411.19628|
|259|CovidLLM: A Robust Large Language Model with Missing Value Adaptation   and Multi-Objective Learning Strategy for Predicting Disease Severity and   Clinical Outcomes in COVID-19 Pa..|Shengjun Zhu, Siyu Liu, Yang Li, Qing Lei, Hongyan Hou, He‚Äêwei Jiang, Shujuan Guo, Feng Wang, Rongshang Chen, Xionglin F...|2024-11-28|Current Proteomics|https://github.com/sysll/CovidLLM|https://doi.org/10.2174/0115701646366019250304064012|
|260|Leveraging Large Language Models and Topic Modeling for Toxicity   Classification|Haniyeh Ehsani Oskouie, Christina Chance, Claire Huang, Margaret Capetz, Elizabeth Eyeson, Majid Sarrafzadeh|2024-11-26|2016 International Conference on Computing, Networking and Communications (ICNC)|https://github.com/aheldis/Toxicity-Classification.git.|https://doi.org/10.1109/ICNC64010.2025.10994061|
|261|VaxLLM: Leveraging Fine-tuned Large Language Model for automated annotation of Brucella Vaccines|Xingxian Li, Yuping Zheng, Jie Hu, Jie Zheng, Zhigang Wang, Yongqun He|2024-11-26|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/xingxianli/VaxLLM|https://doi.org/10.1101/2024.11.25.625209|
|262|AdaShield: Safeguarding Multimodal Large Language Models from   Structure-based Attack via Adaptive Shield Prompting|Yu Wang, Xiaogeng Liu, Yu Li, Muhao Chen, Chaowei Xiao|2024-11-26|Lecture notes in computer science|https://github.com/rain305f/AdaShield.|https://doi.org/10.1007/978-3-031-72661-3_5|
|263|CS-Eval: A Comprehensive Large Language Model Benchmark for   CyberSecurity|Zhengmin Yu, Jiutian Zeng, Siyi Chen, Wenhan Xu, Dandan Xu, Xiangyu Liu, Zonghao Ying, Nan Wang, Yuan Zhang, Min Yang|2024-11-25|arXiv (Cornell University)|https://github.com/CS-EVAL/CS-Eval.|http://arxiv.org/abs/2411.16239|
|264|"Moralized" Multi-Step Jailbreak Prompts: Black-Box Testing of   Guardrails in Large Language Models for Verbal Attacks|Libo Wang|2024-11-23|arXiv (Cornell University)|https://github.com/brucewang123456789/GeniusTrail.git.|http://arxiv.org/abs/2411.16730|
|265|Large Language Model with Region-guided Referring and Grounding for CT   Report Generation|Zhixuan Chen, Yequan Bie, Huanying Jin, Hao Chen|2024-11-23|IEEE Transactions on Medical Imaging|https://github.com/zhi-xuan-chen/Reg2RG.|https://doi.org/10.1109/TMI.2025.3559923|
|266|DRPruning: Efficient Large Language Model Pruning through   Distributionally Robust Optimization|Hexuan Deng, Wenxiang Jiao, Xuebo Liu, Jing Li, Min Zhang, Zhaopeng Tu|2024-11-21|OpenAlex|https://github.com/hexuandeng/DRPruning.|https://doi.org/10.18653/v1/2025.acl-long.1414|
|267|SemiKong: Curating, Training, and Evaluating A Semiconductor   Industry-Specific Large Language Model|Christopher Nguyen, William Nguyen, Atsushi Suzuki, Daisuke Oku, Hong An Phan, Dinh Viet Sang, Zooey Nguyen, Ha Cam Anh,...|2024-11-20|arXiv (Cornell University)|https://github.com/aitomatic/semikong|http://arxiv.org/abs/2411.13802|
|268|On the Consistency of Video Large Language Models in Temporal   Comprehension|Minjoon Jung, Junbin Xiao, Byoung‚ÄêTak Zhang, Angela Yao|2024-11-19|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/minjoong507/Consistency-of-Video-LLM.|https://openaccess.thecvf.com/content/CVPR2025/html/Jung_On_the_Consistency_of_Video_Large_Language_Models_in_Temporal_CVPR_2025_paper.html|
|269|FLAME: Frozen Large Language Models Enable Data-Efficient Language-Image   Pre-training|Anjia Cao, Xing Wei, Zhiheng Ma|2024-11-18|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/MIV-XJTU/FLAME|https://openaccess.thecvf.com/content/CVPR2025/html/Cao_FLAME_Frozen_Large_Language_Models_Enable_Data-Efficient_Language-Image_Pre-training_CVPR_2025_paper.html|
|270|BianCang: A Traditional Chinese Medicine Large Language Model|Sibo Wei, Xueping Peng, Yifei Wang, Jiasheng Si, Weiyu Zhang, Wenpeng L√º, Xiaoming Wu, Yinglong Wang|2024-11-17|arXiv (Cornell University)|https://github.com/QLU-NLP/BianCang.|http://arxiv.org/abs/2411.11027|
|271|TS-LLaVA: Constructing Visual Tokens through Thumbnail-and-Sampling for   Training-Free Video Large Language Models|Tingyu Qu, Mingxiao Li, Tinne Tuytelaars, Marie‚ÄêFrancine Moens|2024-11-17|arXiv (Cornell University)|https://github.com/tingyu215/TS-LLaVA.|http://arxiv.org/abs/2411.11066|
|272|Multilingual Large Language Models: A Systematic Survey|Shaolin Zhu, Supryadi, Shaoyang Xu, Haoran Sun, Leiyu Pan, Menglong Cui, Jiangcun Du, Renren Jin, Ant√≥nio Branco, Deyi X...|2024-11-17|arXiv (Cornell University)|https://github.com/tjunlp-lab/Awesome-Multilingual-LLMs-Papers.|http://arxiv.org/abs/2411.11072|
|273|Evaluating Creativity and Deception in Large Language Models: A   Simulation Framework for Multi-Agent Balderdash|Parsa Hejabi, Elnaz Rahmati, Alireza S. Ziabari, Preni Golazizian, Jesse Thomason, Morteza Dehghani|2024-11-15|arXiv (Cornell University)|https://github.com/ParsaHejabi/Simulation-Framework-for-Multi-Agent-Balderdash|http://arxiv.org/abs/2411.10422|
|274|Orca: Enhancing Role-Playing Abilities of Large Language Models by   Integrating Personality Traits|Yu-Chih Huang|2024-11-15|arXiv (Cornell University)|https://github.com/Aipura/Orca.|http://arxiv.org/abs/2411.10006|
|275|LHRS-Bot-Nova: Improved Multimodal Large Language Model for Remote   Sensing Vision-Language Interpretation|Zhenshi Li, Dilxat Muhtar, Feng Gu, Yibei He, Xueliang Zhang, Pengfeng Xiao, Guangjun He, Xiao Xiang Zhu|2024-11-14|ISPRS Journal of Photogrammetry and Remote Sensing|https://github.com/NJU-LHRS/LHRS-Bot.|https://doi.org/10.1016/j.isprsjprs.2025.06.003|
|276|DROJ: A Prompt-Driven Attack against Large Language Models|Longfei Hu, B. Wang|2024-11-13|arXiv (Cornell University)|https://github.com/Leon-Leyang/LLM-Safeguard.|http://arxiv.org/abs/2411.09125|
|277|Verbosity $\neq$ Veracity: Demystify Verbosity Compensation Behavior of   Large Language Models|Yusen Zhang, Sarkar Snigdha Sarathi Das, Rui Zhang|2024-11-12|arXiv (Cornell University)|https://github.com/psunlpgroup/VerbosityLLM.|http://arxiv.org/abs/2411.07858|
|278|Benchmarking Large Language Models for NL-to-SQL: A Comprehensive Evaluation of Accuracy, Cost and Throughput|Adithya Narasimhan, Amit Kumar Bhamboo, Abiram Devnathan, Jeyaraj Vellaisamy, Vineeth Vijayaraghavan|2024-11-10|OpenAlex|https://github.com/petavue/NL2SQL-Benchmark.|https://doi.org/10.36227/techrxiv.173121325.56335825/v1|
|279|Golden Touchstone: A Comprehensive Bilingual Benchmark for Evaluating   Financial Large Language Models|Xiaojun Wu, Junxi Liu, Hong Su, Zhouchi Lin, Yiyan Qi, Chengjin Xu, Jiajun Su, Jiajie Zhong, Fuwei Wang, Saizhuo Wang, F...|2024-11-09|arXiv (Cornell University)|https://github.com/IDEA-FinAI/Golden-Touchstone|http://arxiv.org/abs/2411.06272|
|280|TourSynbio-Search: A Large Language Model Driven Agent Framework for   Unified Search Method for Protein Engineering|Yungeng Liu, Zan Chen, Yu Guang Wang, Yiqing Shen|2024-11-08|2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)|https://github.com/tsynbio/Toursynbio-Search|https://doi.org/10.1109/bibm62325.2024.10822318|
|281|AutoProteinEngine: A Large Language Model Driven Agent Framework for   Multimodal AutoML in Protein Engineering|Yungeng Liu, Zan Chen, Yuguang Wang, Yiqing Shen|2024-11-07|COLING|https://github.com/tsynbio/AutoPE.|https://aclanthology.org/2025.coling-industry.36/|
|282|QUILL: Quotation Generation Enhancement of Large Language Models|Jin Xiao, Bowei Zhang, Qianyu He, Jiaqing Liang, Wei Feng, Jinglei Chen, Zujie Liang, Deqing Yang, Yanghua Xiao|2024-11-06|arXiv (Cornell University)|https://github.com/GraceXiaoo/QUILL.|http://arxiv.org/abs/2411.03675|
|283|Measuring short-form factuality in large language models|Jason Lee, Nguyen Karina, Hyung Won Chung, Yunxin Joy Jiao, Spencer Papay, Amelia Glaese, John Schulman, William Fedus|2024-11-06|arXiv (Cornell University)|https://github.com/openai/simple-evals.|http://arxiv.org/abs/2411.04368|
|284|SMoA: Improving Multi-agent Large Language Models with Sparse   Mixture-of-Agents|Dawei Li, Zhen Tan, Peijia Qian, Yifan Li, Kumar Satvik Chaudhary, Lijie Hu, Jiayi Shen|2024-11-05|Lecture notes in computer science|https://github.com/David-Li0406/SMoA.|https://doi.org/10.1007/978-981-96-8180-8_5|
|285|Leveraging Large Language Models in Code Question Answering: Baselines   and Issues|Georgy Andryushchenko, Vladimir Ivanov, Vladimir Makharev, Elizaveta Tukhtina, Aidar Valeev|2024-11-05|Communications in computer and information science|https://github.com/IU-AES-AI4Code/CodeQuestionAnswering.|https://doi.org/10.1007/978-3-031-97019-1_1|
|286|FlexCAD: Unified and Versatile Controllable CAD Generation with   Fine-tuned Large Language Models|Zhanwei Zhang, Shizhao Sun, Wenxiao Wang, Deng Cai, Jiang Bian|2024-11-05|ICLR|https://github.com/microsoft/CADGeneration|https://openreview.net/forum?id=Z0eiiV3Yyh|
|287|Evaluating Large Language Models: A Comprehensive Survey|Zishan Guo, Renren Jin, Chuang Liu, Yufei Huang, Dan Shi, Supryadi, Linhao Yu, Yan Liu, Jiaxuan Li, Bojian Xiong, Deyi X...|2024-11-05|International Journal of Latest Engineering and Management Research (IJLEMR)|https://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers.|https://doi.org/10.56581/ijlemr.9.10.05-16|
|288|DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for   Efficient Robot Execution|Yang Yue, Yulin Wang, Bingyi Kang, Yizeng Han, Shenzhi Wang, Shiji Song, Jiashi Feng, Gao Huang|2024-11-04|NeurIPS|https://github.com/yueyang130/DeeR-VLA.|http://papers.nips.cc/paper_files/paper/2024/hash/67b0e7c7c2a5780aeefe3b79caac106e-Abstract-Conference.html|
|289|SQL Injection Jailbreak: a structural disaster of large language models|Jiawei Zhao, Kejiang Chen, Weiming Zhang, Nenghai Yu|2024-11-03|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/weiyezhimeng/SQL-Injection-Jailbreak|https://doi.org/10.18653/v1/2025.findings-acl.358|
|290|Fish-Speech: Leveraging Large Language Models for Advanced Multilingual   Text-to-Speech Synthesis|Shijia Liao, Yuxuan Wang, Tianyu Li, Yifan Cheng, Ruoyi Zhang, Ran Zhou, Yun-Xuan Xing|2024-11-02|arXiv (Cornell University)|https://github.com/fishaudio/fish-speech|http://arxiv.org/abs/2411.01156|
|291|Rate, Explain and Cite (REC): Enhanced Explanation and Attribution in   Automatic Evaluation by Large Language Models|Aliyah R. Hsu, James Zhu, Zhichao Wang, Bin Bi, Shubham Mehrotra, Shiva Pentyala, Katherine Tan, Xiang-Bo Mao, Roshanak ...|2024-11-02|arXiv (Cornell University)|https://github.com/adelaidehsu/REC|http://arxiv.org/abs/2411.02448|
|292|MoD: A Distribution-Based Approach for Merging Large Language Models|Quy-Anh Dang, Chong‚ÄêWah Ngo|2024-11-01|arXiv (Cornell University)|https://github.com/knovel-eng/mod.|http://arxiv.org/abs/2411.00406|
|293|BitStack: Fine-Grained Size Control for Compressed Large Language Models   in Variable Memory Environments|Xinghao Wang, Pengyu Wang, Bo Wang, Dong Zhang, Yunhua Zhou, Xipeng Qiu|2024-10-31|arXiv (Cornell University)|https://github.com/xinghaow99/BitStack.|http://arxiv.org/abs/2410.23918|
|294|End-to-End Ontology Learning with Large Language Models|Andrea Lo, Albert Q. Jiang, Wenda Li, Mateja Jamnik|2024-10-30|NeurIPS|https://github.com/andylolu2/ollm.|http://papers.nips.cc/paper_files/paper/2024/hash/9e89f068a62f6858c661a8abecf5bb0a-Abstract-Conference.html|
|295|LLMCBench: Benchmarking Large Language Model Compression for Efficient   Deployment|Ge Yang, Changyi He, Jinyang Guo, Jianyu Wu, Yifu Ding, Aishan Liu, Haotong Qin, Pengliang Ji, Xianglong Liu|2024-10-28|NeurIPS|https://github.com/AboveParadise/LLMCBench.|http://papers.nips.cc/paper_files/paper/2024/hash/9f4cc62d0632911c63163ea3d9ec19bd-Abstract-Datasets_and_Benchmarks_Track.html|
|296|NewTerm: Benchmarking Real-Time New Terms for Large Language Models with   Annual Updates|Hexuan Deng, Wenxiang Jiao, Xuebo Liu, Zhang Min, Zhaopeng Tu|2024-10-28|NeurIPS|https://github.com/hexuandeng/NewTerm.|http://papers.nips.cc/paper_files/paper/2024/hash/3eec719ab86712d32b065c5977f94ad0-Abstract-Datasets_and_Benchmarks_Track.html|
|297|GCoder: Improving Large Language Model for Generalized Graph Problem   Solving|Qifan Zhang, Xiaobin Hong, Jianheng Tang, Nuo Chen, Yuhan Li, Wenzhong Li, Jing Tang, Jia Li|2024-10-24|arXiv (Cornell University)|https://github.com/Bklight999/WWW25-GCoder|http://arxiv.org/abs/2410.19084|
|298|Cross-model Control: Improving Multiple Large Language Models in   One-time Training|Jiayi Wu, Hao Sun, Hengyi Cai, Lixin Su, Shuaiqiang Wang, Dawei Yin, Xiang Li, Ming Gao|2024-10-23|NeurIPS|https://github.com/wujwyi/CMC.|http://papers.nips.cc/paper_files/paper/2024/hash/9856b5d30ac61ab744fdab6f67d874e4-Abstract-Conference.html|
|299|GraphTeam: Facilitating Large Language Model-based Graph Analysis via   Multi-Agent Collaboration|Xin Li, Qi Chu, Yubin Chen, Yang Liu, Yaoqi Liu, Zhi Yu, Weize Chen, Chen Qian, Chuan Shi, Cheng Yang|2024-10-23|arXiv (Cornell University)|https://github.com/BUPT-GAMMA/GraphTeam.|http://arxiv.org/abs/2410.18032|
|300|ETHIC: Evaluating Large Language Models on Long-Context Tasks with High   Information Coverage|Taewhoo Lee, Chanwoong Yoon, Kyochul Jang, Donghyeon Lee, Myung-Ha Song, Hyunjae Kim, Jaewoo Kang|2024-10-22|OpenAlex|https://github.com/dmis-lab/ETHIC.|https://doi.org/10.18653/v1/2025.naacl-long.283|
|301|Improving Causal Reasoning in Large Language Models: A Survey|Lu Yu, Delin Chen, Siheng Xiong, Qingyang Wu, Qingzhen Liu, Dawei Li, Zhikai Chen, Xiaoze Liu, Liangming Pan|2024-10-22|arXiv (Cornell University)|https://github.com/chendl02/Awesome-LLM-causal-reasoning.|http://arxiv.org/abs/2410.16676|
|302|DEAN: Deactivating the Coupled Neurons to Mitigate Fairness-Privacy   Conflicts in Large Language Models|Qian Chen, Dongrui Liu, Jie Zhang, Yong Liu, Jing Shao|2024-10-22|arXiv (Cornell University)|https://github.com/ChnQ/DEAN|http://arxiv.org/abs/2410.16672|
|303|Benchmarking Large Language Models for Image Classification of Marine   Mammals|Yijiashun Qi, Shuzhang Cai, Zunduo Zhao, Jiaming Li, Yanbin Lin, Zhiqiang Wang|2024-10-21|OpenAlex|https://github.com/yeyimilk/LLM-Vision-Marine-Animals.git.|https://doi.org/10.1109/ICKG63256.2024.00040|
|304|Boosting Jailbreak Transferability for Large Language Models|Hanqing Liu, Lifeng Zhou, Huanqian Yan|2024-10-21|arXiv (Cornell University)|https://github.com/HqingLiu/SI-GCG.|http://arxiv.org/abs/2410.15645|
|305|Comprehensive benchmarking of large language models for RNA secondary   structure prediction|Luciano I Zablocki, Leandro A. Bugnon, M. G√©rard, Leandro E. Di Persia, Georgina Stegmayer, Diego H. Milone|2024-10-21|Briefings in Bioinformatics|https://github.com/sinc-lab/rna-llm-folding|https://doi.org/10.1093/bib/bbaf137|
|306|LLaVA-KD: A Framework of Distilling Multimodal Large Language Models|Yuxuan Cai, Jiangning Zhang, Haoyang He, Xinwei He, Ao Tong, Zhenye Gan, Chengjie Wang, Xiang Bai|2024-10-21|arXiv (Cornell University)|https://github.com/Fantasyele/LLaVA-KD.|http://arxiv.org/abs/2410.16236|
|307|Advances in Citation Text Generation: Leveraging Multi-Source Seq2Seq Models and Large Language Models|Avinash Anand, Ashwin R. Nair, Kritarth Prasad, Vrinda Narayan, Naman Lal, Debanjan Mahata, Yaman Singla, Rajiv Ratn Sha...|2024-10-20|OpenAlex|https://github.com/midas-research/M-CTG|https://doi.org/10.1145/3627673.3679783|
|308|GlitchMiner: Mining Glitch Tokens in Large Language Models via   Gradient-based Discrete Optimization|Zihui Wu, Haichang Gao, Ping Wang, Shudong Zhang, Zhaoxiang Liu, Shiguo Lian|2024-10-19|arXiv (Cornell University)|https://github.com/wooozihui/GlitchMiner.|http://arxiv.org/abs/2410.15052|
|309|Evaluating Deep Unlearning in Large Language Models|Ruihan Wu, Chhavi Yadav, Russ R. Salakhutdinov, Kamalika Chaudhuri|2024-10-19|arXiv (Cornell University)|https://github.com/wrh14/deep_unlearning.|http://arxiv.org/abs/2410.15153|
|310|Explaining Graph Neural Networks with Large Language Models: A   Counterfactual Perspective for Molecular Property Prediction|Yinhan He, Zaiyi Zheng, Patrick Soga, Yuemin Zhu, Yushun Dong, Jundong Li|2024-10-19|arXiv (Cornell University)|https://github.com/YinhanHe123/new|http://arxiv.org/abs/2410.15165|
|311|CoMAL: Collaborative Multi-Agent Large Language Models for   Mixed-Autonomy Traffic|Huaiyuan Yao, Longchao Da, Vishnu Nandam, Justin Turnau, Zhiwei Liu, Linsey Pang, Hua Wei|2024-10-18|Society for Industrial and Applied Mathematics eBooks|https://github.com/Hyan-Yao/CoMAL.|https://doi.org/10.1137/1.9781611978520.43|
|312|Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges   in Large Language Models|Yu Yuan, Lili Zhao, Kai Zhang, Guangting Zheng, Qi Liu|2024-10-17|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/yyhappier/ShortcutSuite.git.|https://doi.org/10.18653/v1/2024.emnlp-main.679|
|313|Towards Faithful Natural Language Explanations: A Study Using Activation   Patching in Large Language Models|Wei Jie Yeo, Ranjan Satapathy, Erik Cambria|2024-10-17|arXiv|https://github.com/wj210/Causal-Faithfulness|https://doi.org/10.48550/arXiv.2410.14155|
|314|Automatically Interpreting Millions of Features in Large Language Models|Gon√ßalo Paulo, Alex Mallen, C. H. Juang, Nora Belrose|2024-10-17|arXiv (Cornell University)|https://github.com/EleutherAI/sae-auto-interp|http://arxiv.org/abs/2410.13928|
|315|Bridging the Language Gaps in Large Language Models with Inference-Time   Cross-Lingual Intervention|Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch|2024-10-16|OpenAlex|https://github.com/weixuan-wang123/INCLINE.|https://doi.org/10.18653/v1/2025.acl-long.270|
|316|Data Defenses Against Large Language Models|William S. Agnew, Harry H. Jiang, Cella Sum, Maarten Sap, Sauvik Das|2024-10-16|arXiv (Cornell University)|https://github.com/wagnew3/LLMDataDefenses|http://arxiv.org/abs/2410.13138|
|317|HerO at AVeriTeC: The Herd of Open Large Language Models for Verifying   Real-World Claims|Yejun Yoon, Jaeyoon Jung, Seunghyun Yoon, Kunwoo Park|2024-10-16|OpenAlex|https://github.com/ssu-humane/HerO.|https://doi.org/10.18653/v1/2024.fever-1.15|
|318|LLM4THP: a computing tool to identify tumor homing peptides by molecular and sequence representation of large language model based on two-layer ensemble model strategy|Sen Yang, Piao Xu|2024-10-15|Amino Acids|https://github.com/abcair/LLM4THP.|https://doi.org/10.1007/s00726-024-03422-5|
|319|Subspace Optimization for Large Language Models with Convergence   Guarantees|Yutong He, Peichao Li, Yinggang Hu, C.L. Philip Chen, Kun Yuan|2024-10-15|arXiv (Cornell University)|https://github.com/pkumelon/Golore.|http://arxiv.org/abs/2410.11289|
|320|Layer-wise Importance Matters: Less Memory for Better Performance in   Parameter-efficient Fine-tuning of Large Language Models|Kai Yao, Penglei Gao, Lichun Li, Yuan Zhao, Xiaofeng Wang, Wei Wang, Jianke Zhu|2024-10-15|OpenAlex|https://github.com/Kaiseem/IST.|https://doi.org/10.18653/v1/2024.findings-emnlp.109|
|321|Automatically Generating Visual Hallucination Test Cases for Multimodal   Large Language Models|Zhongye Liu, Hongbin Liu, Yuepeng Hu, Zedian Shao, Neil Zhenqiang Gong|2024-10-14|arXiv (Cornell University)|https://github.com/lycheeefish/VHExpansion.|http://arxiv.org/abs/2410.11242|
|322|Denial-of-Service Poisoning Attacks against Large Language Models|Kuofeng Gao, Tianyu Pang, Chao Du, Yong Yang, Shu-Tao Xia, Min Lin|2024-10-14|arXiv (Cornell University)|https://github.com/sail-sg/P-DoS.|http://arxiv.org/abs/2410.10760|
|323|Large Language Model Evaluation via Matrix Nuclear-Norm|Y. S. Li, Tingyu Xia, Yi Chang, Yuan Chieh Wu|2024-10-14|arXiv (Cornell University)|https://github.com/MLGroupJLU/MatrixNuclearNorm.|http://arxiv.org/abs/2410.10672|
|324|MentalGLM Series: Explainable Large Language Models for Mental Health   Analysis on Chinese Social Media|Wei Zhai, Nan Bai, Qing Zhao, Jianqiang Li, Fan Wang, Hongzhi Qi, Meng Jiang, Xiaoqin Wang, Bing Xiang Yang, Guanghui Fu|2024-10-14|arXiv (Cornell University)|https://github.com/zwzzzQAQ/MentalGLM.|http://arxiv.org/abs/2410.10323|
|325|One Language, Many Gaps: Evaluating Dialect Fairness and Robustness of   Large Language Models in Reasoning Tasks|Fangru Lin, Shaoguang Mao, Emanuele La Malfa, Valentin Hofmann, Adrian de Wynter, Jing Yao, Siqing Chen, Michael Wooldri...|2024-10-14|arXiv|https://github.com/fangru-lin/redial_dialect_robustness_fairness.git.|https://doi.org/10.48550/arXiv.2410.11005|
|326|Targeted Vaccine: Safety Alignment for Large Language Models against   Harmful Fine-Tuning via Layer-wise Perturbation|G. H. Liu, Weiwei Lin, Tiansheng Huang, Ruichao Mo, Qi Mu, Li Shen|2024-10-13|arXiv (Cornell University)|https://github.com/Lslland/T-Vaccine.|http://arxiv.org/abs/2410.09760|
|327|Benchmarking Cell Type Annotation by Large Language Models with AnnDictionary|George Crowley, Stephen R. Quake|2024-10-13|bioRxiv (Cold Spring Harbor Laboratory)|https://github.com/ggit12/anndictionary|https://doi.org/10.1101/2024.10.10.617605|
|328|AlphaPruning: Using Heavy-Tailed Self Regularization Theory for Improved   Layer-wise Pruning of Large Language Models|Haiquan Lu, Yefan Zhou, Shiwei Liu, Zhangyang Wang, Michael W. Mahoney, Yaoqing Yang|2024-10-13|NeurIPS|https://github.com/haiquanlu/AlphaPruning.|http://papers.nips.cc/paper_files/paper/2024/hash/10fc83943b4540a9524af6fc67a23fef-Abstract-Conference.html|
|329|Dual-AEB: Synergizing Rule-Based and Multimodal Large Language Models   for Effective Emergency Braking|Wei Zhang, Peng-Fei Li, Junli Wang, B. Sun, Jin Qian, Guozhang Bao, Shao‚ÄêShi Rui, Yu Yang, Wenchao Ding, Peng Li, Yilun ...|2024-10-11|ICRA|https://github.com/ChipsICU/Dual-AEB.|https://doi.org/10.1109/ICRA55743.2025.11128453|
|330|Extracting and Transferring Abilities For Building Multi-lingual   Ability-enhanced Large Language Models|Zhipeng Chen, Liang Song, Kun Zhou, Wayne Xin Zhao, Bingning Wang, Weipeng Chen, Ji-Rong Wen|2024-10-10|arXiv (Cornell University)|https://github.com/RUCAIBox/MAET|http://arxiv.org/abs/2410.07825|
|331|Key-Value Cache Quantization in Large Language Models: A Safety Benchmark|Timothy Liu|2024-10-10|International Journal of Computer Science and Information Technology|https://github.com/TimochiL/llm_benchmark.|https://doi.org/10.62051/ijcsit.v4n2.16|
|332|Teaching-Inspired Integrated Prompting Framework: A Novel Approach for   Enhancing Reasoning in Large Language Models|Wenting Tan, Dongxiao Chen, Jieting Xue, Zihao Wang, Tianqiao Chen|2024-10-10|COLING|https://github.com/SallyTan13/Teaching-Inspired-Prompting.|https://aclanthology.org/2025.coling-industry.69/|
|333|Understanding the Interplay between Parametric and Contextual Knowledge   for Large Language Models|Sitao Cheng, Liangming Pan, Xunjian Yin, Xinyi Wang, William Yang Wang|2024-10-10|arXiv (Cornell University)|https://github.com/sitaocheng/Knowledge_Interplay|http://arxiv.org/abs/2410.08414|
|334|Dissecting Fine-Tuning Unlearning in Large Language Models|Yihuai Hong, Yuelin Zou, Lijie Hu, Ziqian Zeng, Di Wang, Haiqin Yang|2024-10-09|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/yihuaihong/Dissecting-FT-Unlearning.|https://doi.org/10.18653/v1/2024.emnlp-main.228|
|335|Synthesizing Interpretable Control Policies through Large Language Model   Guided Search|Carlo Bosio, Mark W. Mueller|2024-10-07|2022 American Control Conference (ACC)|https://github.com/muellerlab/synthesizing_interpretable_control_policies.git|https://doi.org/10.23919/ACC63710.2025.11107729|
|336|MindScope: Exploring cognitive biases in large language models through   Multi-Agent Systems|Zhentao Xie, Jiabao Zhao, Yilei Wang, Jinxin Shi, Yanhong Bai, Xingjiao Wu, Liang He|2024-10-06|Frontiers in artificial intelligence and applications|https://github.com/2279072142/MindScope.|https://doi.org/10.3233/FAIA240879|
|337|Leveraging Large Language Models for Suicide Detection on Social Media   with Limited Labels|Vy Nguyen, Chau Pham|2024-10-06|2021 IEEE International Conference on Big Data (Big Data)|https://github.com/khanhvynguyen/Suicide_Detection_LLMs.|https://doi.org/10.1109/BigData62323.2024.10825313|
|338|On the Reliability of Large Language Models to Misinformed and   Demographically-Informed Prompts|Toluwani Aremu, Oluwakemi Akinwehinmi, Chukwuemeka Nwagu, Syed Ishtiaque Ahmed, Rita Orji, Pedro Arnau Del Amo, Abdulmot...|2024-10-06|Research Square (Research Square)|https://github.com/tolusophy/Edge|https://doi.org/10.21203/rs.3.rs-5258646/v1|
|339|CS4: Measuring the Creativity of Large Language Models Automatically by   Controlling the Number of Story-Writing Constraints|Anirudh Atmakuru, Jatin Nainani, Rohith Siddhartha Reddy Bheemreddy, Anirudh Lakkaraju, Zonghai Yao, Hamed Zamani, Haw-S...|2024-10-05|arXiv (Cornell University)|https://github.com/anirudhlakkaraju/cs4_benchmark.|http://arxiv.org/abs/2410.04197|
|340|Neuron-Level Sequential Editing for Large Language Models|Houcheng Jiang, Junfeng Fang, Tianyu Zhang, Baolong Bi, An Zhang, Ruipeng Wang, Tao Liang, Xiang Wang|2024-10-05|OpenAlex|https://github.com/jianghoucheng/NSE|https://doi.org/10.18653/v1/2025.acl-long.815|
|341|Output Scouting: Auditing Large Language Models for Catastrophic   Responses|Colin Bell, Jo√£o Eurico Fonseca|2024-10-04|arXiv (Cornell University)|https://github.com/joaopfonseca/outputscouting|http://arxiv.org/abs/2410.05305|
|342|CommonIT: Commonality-Aware Instruction Tuning for Large Language Models   via Data Partitions|Jun Rao, Xuebo Liu, Lian Lian, Shengjun Cheng, Yunjie Liao, Min Zhang|2024-10-03|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/raojay7/CommonIT|https://doi.org/10.18653/v1/2024.emnlp-main.561|
|343|POSIX: A Prompt Sensitivity Index For Large Language Models|Anwoy Chatterjee, H. S. V. N. S. Kowndinya Renduchintala, Sumit Bhatia, Tanmoy Chakraborty|2024-10-03|OpenAlex|https://github.com/kowndinya-renduchintala/POSIX.|https://doi.org/10.18653/v1/2024.findings-emnlp.852|
|344|CodeJudge: Evaluating Code Generation with Large Language Models|Weiwei Tong, Tianyi Zhang|2024-10-02|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/VichyTong/CodeJudge.|https://doi.org/10.18653/v1/2024.emnlp-main.1118|
|345|DLP-LoRA: Efficient Task-Specific LoRA Fusion with a Dynamic,   Lightweight Plugin for Large Language Models|Yuxuan Zhang, Ruizhe Li|2024-10-02|arXiv (Cornell University)|https://github.com/MeCuping/DLP-LoRA.|http://arxiv.org/abs/2410.01497|
|346|Basis Sharing: Cross-Layer Parameter Sharing for Large Language Model   Compression|Jingcun Wang, Yu-Guang Chen, Ing-Chao Lin, Bing Li, Grace Li Zhang|2024-10-02|ICLR|https://github.com/TUDa-HWAI/Basis_Sharing|https://openreview.net/forum?id=gp32jvUquq|
|347|AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge   Distillation for Large Language Models in Code Generation|Ziyang Luo, Xin Li, Hongzhan Lin, Jing Ma, Lidong Bing|2024-10-01|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/ChiYeungLaw/AMR-Evol.|https://doi.org/10.18653/v1/2024.emnlp-main.66|
|348|Do Influence Functions Work on Large Language Models?|Zhe Li, Wei Zhao, Yige Li, Jun Sun|2024-09-30|arXiv (Cornell University)|https://github.com/plumprc/Failures-of-Influence-Functions-in-LLMs.|http://arxiv.org/abs/2409.19998|
|349|Can Large Language Models Analyze Graphs like Professionals? A   Benchmark, Datasets and Models|Xin Li, Weize Chen, Qi Chu, Haopeng Li, Zhaojun Sun, Ran Li, Qian Chen, Yiwei Wei, Z. Liu, Chuan Shi, Maosong Sun, Cheng...|2024-09-29|NeurIPS|https://github.com/BUPT-GAMMA/ProGraph.|http://papers.nips.cc/paper_files/paper/2024/hash/ff417c3993894694e88ffc4d3f53d28b-Abstract-Datasets_and_Benchmarks_Track.html|
|350|Identifying Knowledge Editing Types in Large Language Models|Xiao Peng Li, Shangwen Wang, Shezheng Song, Bin Ji, Huijun Liu, Shasha Li, Jun Ma, Jie Yu|2024-09-29|OpenAlex|https://github.com/xpq-tech/KETI.|https://doi.org/10.1145/3711896.3737001|
|351|RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling   Large Language Models|Shuhao Chen, Weisen Jiang, Baijiong Lin, James T. Kwok, Yu Zhang|2024-09-29|NeurIPS|https://github.com/shuhao02/RouterDC.|http://papers.nips.cc/paper_files/paper/2024/hash/7a641b8ec86162fc875fb9f6456a542f-Abstract-Conference.html|
|352|OpenSep: Leveraging Large Language Models with Textual Inversion for   Open World Audio Separation|Tanvir Mahmud, Diana Marculescu|2024-09-28|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/tanvir-utexas/OpenSep.git|https://doi.org/10.18653/v1/2024.emnlp-main.735|
|353|Align$^2$LLaVA: Cascaded Human and Large Language Model Preference   Alignment for Multi-modal Instruction Curation|Hongzhe Huang, Zhewen Yu, Jiang Liu, Li Cai, Dian Jiao, Wenqiao Zhang, Siliang Tang, Juncheng Li, Hao Jiang, Haoyuan Li,...|2024-09-27|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/DCDmllm/Align2LLaVA.|https://doi.org/10.18653/v1/2025.findings-acl.458|
|354|Control Industrial Automation System with Large Language Models|Yuchen Xia, Nasser Jazdi, J. Zhang, C.L. Shah, Michael Weyrich|2024-09-26|arXiv (Cornell University)|https://github.com/YuchenXia/LLM4IAS|http://arxiv.org/abs/2409.18009|
|355|Harmful Fine-tuning Attacks and Defenses for Large Language Models: A   Survey|Tiansheng Huang, Sihao Hu, Fatih ƒ∞lhan, Selim Furkan Tekin, Ling Liu|2024-09-26|arXiv (Cornell University)|https://github.com/git-disl/awesome_LLM-harmful-fine-tuning-papers|http://arxiv.org/abs/2409.18169|
|356|CurricuLLM: Automatic Task Curricula Design for Learning Complex Robot   Skills using Large Language Models|Kanghyun Ryu, Qiayuan Liao, Zhongyu Li, Payam Delgosha, Koushil Sreenath, Negar Mehr|2024-09-26|ICRA|https://github.com/labicon/CurricuLLM|https://doi.org/10.1109/ICRA55743.2025.11128783|
|357|LLM-CARD: Towards a Description and Landscape of Large Language Models|Shengwei Tian, Lifeng Han, Erick Mendez Guzman, Goran Nenadiƒá|2024-09-25|arXiv (Cornell University)|https://github.com/shengwei-tian/dependency-parser-visualization|http://arxiv.org/abs/2409.17011|
|358|RED QUEEN: Safeguarding Large Language Models against Concealed   Multi-Turn Jailbreaking|Yifan Jiang, Kriti Aggarwal, Tanmay Laud, Kashif Munir, Jay Pujara, Subhabrata Mukherjee|2024-09-25|arXiv (Cornell University)|https://github.com/kriti-hippo/red_queen.|http://arxiv.org/abs/2409.17458|
|359|XTRUST: On the Multilingual Trustworthiness of Large Language Models|Y. S. Li, Yi Wang, Yi Chang, Guowu Yuan|2024-09-24|arXiv (Cornell University)|https://github.com/LluckyYH/XTRUST.|http://arxiv.org/abs/2409.15762|
|360|Pretraining Data Detection for Large Language Models: A Divergence-based   Calibration Method|Weichao Zhang, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Yixing Fan, Xueqi Cheng|2024-09-23|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/zhang-wei-chao/DC-PDD|https://doi.org/10.18653/v1/2024.emnlp-main.300|
|361|Interpreting Arithmetic Mechanism in Large Language Models through   Comparative Neuron Analysis|Zeping Yu, Sophia Ananiadou|2024-09-21|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/zepingyu0512/arithmetic-mechanism.|https://doi.org/10.18653/v1/2024.emnlp-main.193|
|362|StateAct: State Tracking and Reasoning for Acting and Planning with   Large Language Models|Nikolai Rozanov, Marek Rei|2024-09-21|arXiv (Cornell University)|https://github.com/ai-nikolai/StateAct|http://arxiv.org/abs/2410.02810|
|363|ShizishanGPT: An Agricultural Large Language Model Integrating Tools and   Resources|Shuting Yang, Zehui Liu, Wolfgang Mayer, Ningpei Ding, Ying Wang, Yu Huang, Pengfei Wu, Wanli Li, Li Lin, Hongyu Zhang, ...|2024-09-20|Lecture notes in computer science|https://github.com/Zaiwen/CropGPT.|https://doi.org/10.1007/978-981-96-0573-6_21|
|364|CLAIR-A: Leveraging Large Language Models to Judge Audio Captions|Tsung-Han Wu, Joseph E. Gonzalez, Trevor Darrell, David M. Chan|2024-09-19|arXiv (Cornell University)|https://github.com/DavidMChan/clair-a.|http://arxiv.org/abs/2409.12962|
|365|An adapted large language model facilitates multiple medical tasks in   diabetes care|Wei Lai, Zhen Ying, M. He, Yutong Chen, Qian Yang, Hong Ye, Jiaping Lu, Xiaoying Li, Weiran Huang, Ying Chen|2024-09-19|arXiv (Cornell University)|https://github.com/waltonfuture/Diabetica.|http://arxiv.org/abs/2409.13191|
|366|From Linguistic Giants to Sensory Maestros: A Survey on Cross-Modal   Reasoning with Large Language Models|Shengsheng Qian, Zuyi Zhou, Dizhan Xue, Bing Wang, Changsheng Xu|2024-09-18|arXiv (Cornell University)|https://github.com/ZuyiZhou/Awesome-Cross-modal-Reasoning-with-LLMs|http://arxiv.org/abs/2409.18996|
|367|Do Large Language Models Need a Content Delivery Network?|Yihua Cheng, Kuntai Du, Jiayi Yao, Junchen Jiang|2024-09-16|arXiv (Cornell University)|https://github.com/LMCache/LMCache.|http://arxiv.org/abs/2409.13761|
|368|Fit and Prune: Fast and Training-free Visual Token Pruning for   Multi-modal Large Language Models|Weihao Ye, Qiong Wu, Wenhao Lin, Yiyi Zhou|2024-09-16|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/ywh187/FitPrune.|https://doi.org/10.1609/aaai.v39i21.34366|
|369|The Two Word Test as a semantic benchmark for large language models|Nicholas Riccardi, Xuan Yang, Rutvik H Desai|2024-09-16|Scientific Reports|https://github.com/NickRiccardi/two-word-test|https://doi.org/10.1038/s41598-024-72528-3|
|370|Benchmarking Large Language Model Uncertainty for Prompt Optimization|Pei-Fu Guo, Yun-Da Tsai, Shou-De Lin|2024-09-16|arXiv (Cornell University)|https://github.com/0Frett/PO-Uncertainty-Benchmarking.|http://arxiv.org/abs/2409.10044|
|371|Can Large Language Models Grasp Event Signals? Exploring Pure Zero-Shot   Event-based Recognition|Zongyou Yu, Qiang Qu, Xiaoming Chen, Chen Wang|2024-09-15|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|https://github.com/ChrisYu-Zz/Pure-event-based-recognition-based-LLM|https://doi.org/10.1109/ICASSP49660.2025.10887714|
|372|Towards Data Contamination Detection for Modern Large Language Models:   Limitations, Inconsistencies, and Oracle Challenges|Vinay Samuel, Yue Zhou, Henry Peng Zou|2024-09-15|COLING|https://github.com/vsamuel2003/data-contamination.|https://aclanthology.org/2025.coling-main.338/|
|373|DrLLM: Prompt-Enhanced Distributed Denial-of-Service Resistance Method   with Large Language Models|Zhenyu Yin, Shang Liu, Guangyuan Xu|2024-09-11|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|https://github.com/liuup/DrLLM.|https://doi.org/10.1109/ICASSP49660.2025.10889735|
|374|Benchmarking Chinese Knowledge Rectification in Large Language Models|Tianhe Lu, J. Fang, Yunzhi Yao, Xin Xu, Ningyu Zhang, Huajun Chen|2024-09-09|arXiv (Cornell University)|https://github.com/zjunlp/EasyEdit.|http://arxiv.org/abs/2409.05806|
|375|FLoRA: Federated Fine-Tuning Large Language Models with Heterogeneous   Low-Rank Adaptations|Ziyao Wang, Zheyu Shen, Yexiao He, Guoheng Sun, Hongyi Wang, Lingjuan Lyu, Ang Li|2024-09-09|NeurIPS|https://github.com/ATP-1010/FederatedLLM.|http://papers.nips.cc/paper_files/paper/2024/hash/28312c9491d60ed0c77f7fff4ad86dd1-Abstract-Conference.html|
|376|Towards Democratizing Multilingual Large Language Models For Medicine   Through A Two-Stage Instruction Fine-tuning Approach|Meng Zhou, Surajsinh Parmar, Anubhav Bhatti|2024-09-09|arXiv (Cornell University)|https://github.com/SpassMed/Med-Llama3|http://arxiv.org/abs/2409.05732|
|377|Large Language Model-Based Agents for Software Engineering: A Survey|Junwei Liu, Kaixin Wang, Yixuan Chen, Xin Peng, Zhenpeng Chen, Lingming Zhang, Yiling Lou|2024-09-04|arXiv (Cornell University)|https://github.com/FudanSELab/Agent4SE-Paper-List.|http://arxiv.org/abs/2409.02977|
|378|Exploiting the Vulnerability of Large Language Models via Defense-Aware   Architectural Backdoor|Abdullah Arafat Miah, Yu Bi|2024-09-03|arXiv (Cornell University)|https://github.com/SiSL-URI/Arch_Backdoor_LLM.|http://arxiv.org/abs/2409.01952|
|379|Foundations of Large Language Model Compression -- Part 1: Weight   Quantization|Sean I. Young|2024-09-03|arXiv (Cornell University)|https://github.com/seannz/cvxq.|http://arxiv.org/abs/2409.02026|
|380|Booster: Tackling Harmful Fine-tuning for Large Language Models via   Attenuating Harmful Perturbation|Tiansheng Huang, Sihao Hu, Fatih ƒ∞lhan, Selim Furkan Tekin, Ling Liu|2024-09-02|ICLR|https://github.com/git-disl/Booster|https://openreview.net/forum?id=tTPHgb0EtV|
|381|FlashFlex: Accommodating Large Language Model Training over   Heterogeneous Environment|Ran Yan, Youhe Jiang, Wangcheng Tao, Xiaonan Nie, Bin Cui, Binhang Yuan|2024-09-02|arXiv (Cornell University)|https://github.com/Relaxed-System-Lab/FlashFlex.|http://arxiv.org/abs/2409.01143|
|382|Automatic Pseudo-Harmful Prompt Generation for Evaluating False Refusals   in Large Language Models|Bang An, Sicheng Zhu, Ruiyi Zhang, Michael-Andrei Panaitescu-Liess, Yuancheng Xu, Furong Huang|2024-08-31|arXiv (Cornell University)|https://github.com/umd-huang-lab/FalseRefusal|http://arxiv.org/abs/2409.00598|
|383|AgentMove: Predicting Human Mobility Anywhere Using Large Language Model   based Agentic Framework|Jie Feng, Yuwei Du, Jie Zhao, Yong Li|2024-08-25|arXiv (Cornell University)|https://github.com/tsinghua-fib-lab/AgentMove.|http://arxiv.org/abs/2408.13986|
|384|DesignQA: Benchmarking Multimodal Large Language Models on Questions Grounded in Engineering Documentation|Anna C. Doris, Daniele Grandi, Ryan Tomich, Md Ferdous Alam, Hyunmin Cheong, Faez Ahmed|2024-08-25|OpenAlex|https://github.com/anniedoris/design_qa|https://doi.org/10.1115/detc2024-139024|
|385|AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web   Navigating Agent|Hanyu Lai, Xiao Liu, Iat Long Iong, Shuntian Yao, Yuxuan Chen, Pengbo Shen, Hao Yu, H. H. Zhang, Xiaohan Zhang, Yuxiao D...|2024-08-24|Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining|https://github.com/THUDM/AutoWebGLM.|https://doi.org/10.48550/arXiv.2404.03648|
|386|LIMP: Large Language Model Enhanced Intent-aware Mobility Prediction|Songwei Li, Jie Feng, Jiawei Chi, Xinyuan Hu, Xiaomeng Zhao, Fengli Xu|2024-08-23|arXiv (Cornell University)|https://github.com/tsinghua-fib-lab/LIMP|http://arxiv.org/abs/2408.12832|
|387|CLLMFS: A Contrastive Learning enhanced Large Language Model Framework   for Few-Shot Named Entity Recognition|Yafeng Zhang, Zilan Yu, Yuang Huang, Jing Tang|2024-08-23|Frontiers in artificial intelligence and applications|https://github.com/yuzilan/CLLMFS|https://doi.org/10.3233/FAIA240714|
|388|IAA: Inner-Adaptor Architecture Empowers Frozen Large Language Model   with Multimodal Capabilities|Bin Wang, Chunyu Xie, Dawei Leng, Yuhui Yin|2024-08-23|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/360CVGroup/Inner-Adaptor-Architecture.|https://doi.org/10.1609/aaai.v39i20.35400|
|389|GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender   Bias in Large Language Models|Kunsheng Tang, Wenbo Zhou, Jie Zhang, Aishan Liu, Gelei Deng, Shuai Li, Pengyu Qi, Weiming Zhang, Tianwei Zhang, Nenghai...|2024-08-22|OpenAlex|https://github.com/kstanghere/GenderCARE-ccs24.|https://doi.org/10.1145/3658644.3670284|
|390|Geolocation Representation from Large Language Models are Generic   Enhancers for Spatio-Temporal Learning|Junlin He, Tong Nie, Wei Ma|2024-08-22|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/Umaruchain/LLMGeovec|https://doi.org/10.1609/aaai.v39i16.33879|
|391|Towards Evaluating and Building Versatile Large Language Models for   Medicine|Chaoyi Wu, Pengcheng Qiu, Jinxin Liu, Hongfei Gu, Na Li, Ya Zhang, Yanfeng Wang, Weidi Xie|2024-08-22|npj Digital Medicine|https://github.com/MAGIC-AI4Med/MedS-Ins.|https://doi.org/10.1038/s41746-024-01390-4|
|392|Enhanced Fine-Tuning of Lightweight Domain-Specific Q&amp;A Model Based on Large Language Models|Shenglin Zhang, Pengtian Zhu, Minghua Ma, Jia‚ÄêGang Wang, Yongqian Sun, Dongwen Li, Jingyu Wang, Qianying Guo, Xiaolei Hu...|2024-08-22|OpenAlex|https://github.com/Zero-Pointer/Self-Evolution.|https://doi.org/10.1109/ISSREW63542.2024.00048|
|393|Controllable Text Generation for Large Language Models: A Survey|Xun Liang, Hanyu Wang, Yezhaohui Wang, Shichao Song, Jiawei Yang, Simin Niu, Jie Hu, Dan Liu, Shunyu Yao, Feiyu Xiong, Z...|2024-08-22|arXiv (Cornell University)|https://github.com/IAAR-Shanghai/CTGSurvey.|http://arxiv.org/abs/2408.12599|
|394|MoE-LPR: Multilingual Extension of Large Language Models through   Mixture-of-Experts with Language Priors Routing|Hao Zhou, Zhijun Wang, Shujian Huang, Xin Huang, Xue Han, Junlan Feng, Chao Deng, Weihua Luo, Jiajun Chen|2024-08-21|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/zjwang21/MoE-LPR.git.|https://doi.org/10.48550/arXiv.2408.11396|
|395|Personality Alignment of Large Language Models|Minjun Zhu, Yixuan Weng, Linyi Yang, Yue Zhang|2024-08-21|ICLR|https://github.com/zhu-minjun/PAlign|https://openreview.net/forum?id=0DZEs8NpUH|
|396|SORSA: Singular Values and Orthonormal Regularized Singular Vectors   Adaptation of Large Language Models|Yang Cao|2024-08-21|arXiv (Cornell University)|https://github.com/Gunale0926/SORSA.|http://arxiv.org/abs/2409.00055|
|397|CodeJudge-Eval: Can Large Language Models be Good Judges in Code   Understanding?|Yuwei Zhao, Ziyang Luo, Yuchen Tian, Hongzhan Lin, Weixiang Yan, Annan Li, Jing Ma|2024-08-20|COLING|https://github.com/CodeLLM-Research/CodeJudge-Eval|https://aclanthology.org/2025.coling-main.7/|
|398|LLM-Barber: Block-Aware Rebuilder for Sparsity Mask in One-Shot for   Large Language Models|Yupeng Su, Ziyi Guan, Xiaoqun Liu, Tianlai Jin, Dongkuan Wu, Graziano Chesi, Ngai Wong, Hao Yu|2024-08-20|arXiv (Cornell University)|https://github.com/YupengSu/LLM-Barber.|http://arxiv.org/abs/2408.10631|
|399|Large Language Models for Multimodal Deformable Image Registration|Mingrui Ma, Weijie Wang, Jie Ning, Jianfeng He, Nicu Sebe, Bruno Lepri|2024-08-20|arXiv (Cornell University)|https://github.com/ninjannn/LLM-Morph.|http://arxiv.org/abs/2408.10703|
|400|Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion   for Efficient Inference Intervention in Large Language Model|Chenhan Yuan, Fei Huang, Ru Peng, Keming Lu, Bowen Yu, Chang Zhou, Jingren Zhou|2024-08-20|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/chenhan97/Otter|https://doi.org/10.18653/v1/2024.emnlp-main.316|
|401|SysBench: Can Large Language Models Follow System Messages?|Yanzhao Qin, Tao Zhang, Tao Zhang, Yanjun Shen, Wenjing Luo, Haoze Sun, Yan Zhang, Yujing Qiao, Weipeng Chen, Zenan Zhou...|2024-08-20|arXiv (Cornell University)|https://github.com/PKU-Baichuan-MLSystemLab/SysBench.|http://arxiv.org/abs/2408.10943|
|402|R2GenCSR: Retrieving Context Samples for Large Language Model based   X-ray Medical Report Generation|Xiao Wang, Yuehang Li, Fuling Wang, Shiao Wang, Chuanfu Li, Bo Jiang|2024-08-19|arXiv (Cornell University)|https://github.com/Event-AHU/Medical_Image_Analysis|http://arxiv.org/abs/2408.09743|
